{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 환경 설정"
      ],
      "metadata": {
        "id": "ClYw-nv7qHpf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ecaSGKKdxL_"
      },
      "outputs": [],
      "source": [
        "# !pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0j0ZSDpb3ZGZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, recall_score, f1_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import log_loss\n",
        "# from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from lightgbm import early_stopping\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "from hyperopt import fmin, tpe, Trials\n",
        "from hyperopt import STATUS_OK\n",
        "from sklearn.svm import SVC\n",
        "from hyperopt import hp\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리"
      ],
      "metadata": {
        "id": "EMQ9e83vqLQK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTqa8b35pnoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b121b04-5238-47db-9e8c-d140ff69a6ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmsGfF3Cpxir"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/iitp_mid_flight/data/train_prep.csv\", index_col = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvon7QgIqhe-"
      },
      "outputs": [],
      "source": [
        "train = train.drop(columns=['ID', 'Cancelled'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnXzX9tt1d3W"
      },
      "outputs": [],
      "source": [
        "obj_col = ['Origin_Airport', 'Origin_State', 'Destination_Airport', 'Destination_State', 'Airline']\n",
        "\n",
        "for i in obj_col:\n",
        "    le = LabelEncoder()\n",
        "    le.fit(train[i].astype(str))\n",
        "    train[i] = le.transform(train[i].astype(str))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkiyurxUqwzp"
      },
      "outputs": [],
      "source": [
        "train = train.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-PLSQiR8yfC"
      },
      "outputs": [],
      "source": [
        "train['Delay'] = train['Delay'].map(lambda x : 0 if x=='Not_Delayed' else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvyEayggAaUj"
      },
      "outputs": [],
      "source": [
        "def get_clf_eval(y_test, pred):\n",
        "    confusion= confusion_matrix(y_test, pred)\n",
        "    accuracy = accuracy_score(y_test, pred)\n",
        "    precision = precision_score(y_test, pred)\n",
        "    recall = recall_score(y_test, pred)\n",
        "    f1 = f1_score(y_test, pred)\n",
        "    print('오차 행렬')\n",
        "    print(confusion)\n",
        "    print(f'정확도 : {accuracy:.4f}, 정밀도 : {precision:.4f}, 재현율 : {recall:.4f}, F1 : {f1:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnKJbxTO3ekZ"
      },
      "outputs": [],
      "source": [
        "X = train.iloc[:,:-1]\n",
        "y = train.iloc[:,-1]\n",
        "\n",
        "X_train, X_valid , y_train, y_valid = train_test_split(X, y, test_size = 0.2, stratify = y, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jE1kOUy2h_v6"
      },
      "outputs": [],
      "source": [
        "numeric_cols = X_train.select_dtypes(exclude=['object']).columns\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
        "X_valid[numeric_cols] = scaler.transform(X_valid[numeric_cols])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "bdcor3Xr6yLw",
        "outputId": "ef9990c3-d141-4724-c438-ebeefcdb9e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Month  Day_of_Month  Estimated_Departure_Time  \\\n",
              "88102   1.163079      0.480879                  0.982644   \n",
              "879962 -0.565354      1.616872                  0.414826   \n",
              "630138  0.875007      0.594479                 -1.025095   \n",
              "524484  0.010790     -0.314315                 -0.076583   \n",
              "329528  0.875007      0.594479                 -0.973373   \n",
              "\n",
              "        Estimated_Arrival_Time  Diverted  Origin_Airport  Origin_Airport_ID  \\\n",
              "88102                 0.792988       0.0       -1.102284          -1.087320   \n",
              "879962                0.402083       0.0       -0.653838          -0.718214   \n",
              "630138               -0.839509       0.0        0.631708           0.714785   \n",
              "524484                0.151191       0.0       -1.700213          -1.613674   \n",
              "329528               -0.759095       0.0        0.083607           0.118031   \n",
              "\n",
              "        Origin_State  Destination_Airport  Destination_Airport_ID  \\\n",
              "88102       0.597358            -0.371864               -0.455931   \n",
              "879962      0.403150             0.725103                0.817842   \n",
              "630138     -1.150509             0.874690                0.934418   \n",
              "524484      0.532622            -1.608446               -1.509066   \n",
              "329528      0.273679            -1.807894               -1.678331   \n",
              "\n",
              "        Destination_State  Distance   Airline  \n",
              "88102            1.096892 -1.196906 -1.183142  \n",
              "879962          -0.714639 -0.102464  1.227133  \n",
              "630138          -1.296917 -0.226523  0.865591  \n",
              "524484          -0.908732  0.125262 -0.580573  \n",
              "329528           0.449917 -0.498435  0.865591  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54101471-7979-48b6-9d51-550db9efade4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Month</th>\n",
              "      <th>Day_of_Month</th>\n",
              "      <th>Estimated_Departure_Time</th>\n",
              "      <th>Estimated_Arrival_Time</th>\n",
              "      <th>Diverted</th>\n",
              "      <th>Origin_Airport</th>\n",
              "      <th>Origin_Airport_ID</th>\n",
              "      <th>Origin_State</th>\n",
              "      <th>Destination_Airport</th>\n",
              "      <th>Destination_Airport_ID</th>\n",
              "      <th>Destination_State</th>\n",
              "      <th>Distance</th>\n",
              "      <th>Airline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>88102</th>\n",
              "      <td>1.163079</td>\n",
              "      <td>0.480879</td>\n",
              "      <td>0.982644</td>\n",
              "      <td>0.792988</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.102284</td>\n",
              "      <td>-1.087320</td>\n",
              "      <td>0.597358</td>\n",
              "      <td>-0.371864</td>\n",
              "      <td>-0.455931</td>\n",
              "      <td>1.096892</td>\n",
              "      <td>-1.196906</td>\n",
              "      <td>-1.183142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>879962</th>\n",
              "      <td>-0.565354</td>\n",
              "      <td>1.616872</td>\n",
              "      <td>0.414826</td>\n",
              "      <td>0.402083</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.653838</td>\n",
              "      <td>-0.718214</td>\n",
              "      <td>0.403150</td>\n",
              "      <td>0.725103</td>\n",
              "      <td>0.817842</td>\n",
              "      <td>-0.714639</td>\n",
              "      <td>-0.102464</td>\n",
              "      <td>1.227133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630138</th>\n",
              "      <td>0.875007</td>\n",
              "      <td>0.594479</td>\n",
              "      <td>-1.025095</td>\n",
              "      <td>-0.839509</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.631708</td>\n",
              "      <td>0.714785</td>\n",
              "      <td>-1.150509</td>\n",
              "      <td>0.874690</td>\n",
              "      <td>0.934418</td>\n",
              "      <td>-1.296917</td>\n",
              "      <td>-0.226523</td>\n",
              "      <td>0.865591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524484</th>\n",
              "      <td>0.010790</td>\n",
              "      <td>-0.314315</td>\n",
              "      <td>-0.076583</td>\n",
              "      <td>0.151191</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.700213</td>\n",
              "      <td>-1.613674</td>\n",
              "      <td>0.532622</td>\n",
              "      <td>-1.608446</td>\n",
              "      <td>-1.509066</td>\n",
              "      <td>-0.908732</td>\n",
              "      <td>0.125262</td>\n",
              "      <td>-0.580573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329528</th>\n",
              "      <td>0.875007</td>\n",
              "      <td>0.594479</td>\n",
              "      <td>-0.973373</td>\n",
              "      <td>-0.759095</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.083607</td>\n",
              "      <td>0.118031</td>\n",
              "      <td>0.273679</td>\n",
              "      <td>-1.807894</td>\n",
              "      <td>-1.678331</td>\n",
              "      <td>0.449917</td>\n",
              "      <td>-0.498435</td>\n",
              "      <td>0.865591</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54101471-7979-48b6-9d51-550db9efade4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-54101471-7979-48b6-9d51-550db9efade4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-54101471-7979-48b6-9d51-550db9efade4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6014ecfe-d999-4c80-8b8d-b05c776a8253\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6014ecfe-d999-4c80-8b8d-b05c776a8253')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6014ecfe-d999-4c80-8b8d-b05c776a8253 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6siunzgnN8Ee",
        "outputId": "1c27dcba-f261-4b89-bd2e-7fb870e3cc5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(174600, 13) (174600,)\n",
            "(43650, 13) (43650,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape, y_train.shape)\n",
        "print(X_valid.shape, y_valid.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RandomForest"
      ],
      "metadata": {
        "id": "fnCXYBDy3w5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier(n_estimators=5, max_depth=8, n_jobs=-1, random_state=42)\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "qLv95TgR3zVe",
        "outputId": "3def2805-fee9-4317-ac17-0249ebecee72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=8, n_estimators=5, n_jobs=-1, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=8, n_estimators=5, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=8, n_estimators=5, n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rf_model.predict(X_valid)\n",
        "get_clf_eval(y_valid, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTDeRUOh4a1V",
        "outputId": "4dc469e8-3c91-4a6f-9cfa-c20d609db026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차 행렬\n",
            "[[35942     2]\n",
            " [ 7706     0]]\n",
            "정확도 : 0.8234, 정밀도 : 0.0000, 재현율 : 0.0000, F1 : 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_report = metrics.classification_report(y_valid, y_pred, zero_division=1)\n",
        "print(rf_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xllVE81-4d2L",
        "outputId": "54eff3aa-6fd7-467b-9523-8ba4d3fbb41d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     35944\n",
            "           1       0.00      0.00      0.00      7706\n",
            "\n",
            "    accuracy                           0.82     43650\n",
            "   macro avg       0.41      0.50      0.45     43650\n",
            "weighted avg       0.68      0.82      0.74     43650\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwHlnbAua_JZ"
      },
      "source": [
        "# XGB Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSncr6FW5ptV"
      },
      "outputs": [],
      "source": [
        "xgb_model = XGBClassifier(learning_rate=0.01,\n",
        "                          n_estimators=1000,\n",
        "                          max_depth=8,\n",
        "                          random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UXBC_DpdEKCf",
        "outputId": "56c37c18-221e-4b6c-fc45-235fabd1c73c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-logloss:0.47026\tvalidation_1-logloss:0.47033\n",
            "[1]\tvalidation_0-logloss:0.46979\tvalidation_1-logloss:0.46992\n",
            "[2]\tvalidation_0-logloss:0.46933\tvalidation_1-logloss:0.46953\n",
            "[3]\tvalidation_0-logloss:0.46887\tvalidation_1-logloss:0.46914\n",
            "[4]\tvalidation_0-logloss:0.46843\tvalidation_1-logloss:0.46876\n",
            "[5]\tvalidation_0-logloss:0.46799\tvalidation_1-logloss:0.46838\n",
            "[6]\tvalidation_0-logloss:0.46755\tvalidation_1-logloss:0.46800\n",
            "[7]\tvalidation_0-logloss:0.46712\tvalidation_1-logloss:0.46763\n",
            "[8]\tvalidation_0-logloss:0.46670\tvalidation_1-logloss:0.46727\n",
            "[9]\tvalidation_0-logloss:0.46628\tvalidation_1-logloss:0.46692\n",
            "[10]\tvalidation_0-logloss:0.46588\tvalidation_1-logloss:0.46657\n",
            "[11]\tvalidation_0-logloss:0.46547\tvalidation_1-logloss:0.46623\n",
            "[12]\tvalidation_0-logloss:0.46508\tvalidation_1-logloss:0.46589\n",
            "[13]\tvalidation_0-logloss:0.46469\tvalidation_1-logloss:0.46556\n",
            "[14]\tvalidation_0-logloss:0.46430\tvalidation_1-logloss:0.46524\n",
            "[15]\tvalidation_0-logloss:0.46393\tvalidation_1-logloss:0.46492\n",
            "[16]\tvalidation_0-logloss:0.46356\tvalidation_1-logloss:0.46462\n",
            "[17]\tvalidation_0-logloss:0.46319\tvalidation_1-logloss:0.46431\n",
            "[18]\tvalidation_0-logloss:0.46283\tvalidation_1-logloss:0.46401\n",
            "[19]\tvalidation_0-logloss:0.46248\tvalidation_1-logloss:0.46372\n",
            "[20]\tvalidation_0-logloss:0.46213\tvalidation_1-logloss:0.46343\n",
            "[21]\tvalidation_0-logloss:0.46178\tvalidation_1-logloss:0.46315\n",
            "[22]\tvalidation_0-logloss:0.46145\tvalidation_1-logloss:0.46287\n",
            "[23]\tvalidation_0-logloss:0.46112\tvalidation_1-logloss:0.46260\n",
            "[24]\tvalidation_0-logloss:0.46079\tvalidation_1-logloss:0.46233\n",
            "[25]\tvalidation_0-logloss:0.46047\tvalidation_1-logloss:0.46207\n",
            "[26]\tvalidation_0-logloss:0.46015\tvalidation_1-logloss:0.46181\n",
            "[27]\tvalidation_0-logloss:0.45984\tvalidation_1-logloss:0.46156\n",
            "[28]\tvalidation_0-logloss:0.45953\tvalidation_1-logloss:0.46131\n",
            "[29]\tvalidation_0-logloss:0.45923\tvalidation_1-logloss:0.46106\n",
            "[30]\tvalidation_0-logloss:0.45893\tvalidation_1-logloss:0.46082\n",
            "[31]\tvalidation_0-logloss:0.45863\tvalidation_1-logloss:0.46058\n",
            "[32]\tvalidation_0-logloss:0.45834\tvalidation_1-logloss:0.46034\n",
            "[33]\tvalidation_0-logloss:0.45805\tvalidation_1-logloss:0.46011\n",
            "[34]\tvalidation_0-logloss:0.45776\tvalidation_1-logloss:0.45988\n",
            "[35]\tvalidation_0-logloss:0.45745\tvalidation_1-logloss:0.45964\n",
            "[36]\tvalidation_0-logloss:0.45718\tvalidation_1-logloss:0.45942\n",
            "[37]\tvalidation_0-logloss:0.45691\tvalidation_1-logloss:0.45920\n",
            "[38]\tvalidation_0-logloss:0.45661\tvalidation_1-logloss:0.45896\n",
            "[39]\tvalidation_0-logloss:0.45635\tvalidation_1-logloss:0.45875\n",
            "[40]\tvalidation_0-logloss:0.45606\tvalidation_1-logloss:0.45853\n",
            "[41]\tvalidation_0-logloss:0.45580\tvalidation_1-logloss:0.45831\n",
            "[42]\tvalidation_0-logloss:0.45552\tvalidation_1-logloss:0.45810\n",
            "[43]\tvalidation_0-logloss:0.45524\tvalidation_1-logloss:0.45789\n",
            "[44]\tvalidation_0-logloss:0.45497\tvalidation_1-logloss:0.45768\n",
            "[45]\tvalidation_0-logloss:0.45471\tvalidation_1-logloss:0.45747\n",
            "[46]\tvalidation_0-logloss:0.45445\tvalidation_1-logloss:0.45727\n",
            "[47]\tvalidation_0-logloss:0.45419\tvalidation_1-logloss:0.45706\n",
            "[48]\tvalidation_0-logloss:0.45393\tvalidation_1-logloss:0.45687\n",
            "[49]\tvalidation_0-logloss:0.45368\tvalidation_1-logloss:0.45668\n",
            "[50]\tvalidation_0-logloss:0.45343\tvalidation_1-logloss:0.45649\n",
            "[51]\tvalidation_0-logloss:0.45319\tvalidation_1-logloss:0.45631\n",
            "[52]\tvalidation_0-logloss:0.45296\tvalidation_1-logloss:0.45613\n",
            "[53]\tvalidation_0-logloss:0.45272\tvalidation_1-logloss:0.45595\n",
            "[54]\tvalidation_0-logloss:0.45249\tvalidation_1-logloss:0.45578\n",
            "[55]\tvalidation_0-logloss:0.45226\tvalidation_1-logloss:0.45561\n",
            "[56]\tvalidation_0-logloss:0.45204\tvalidation_1-logloss:0.45544\n",
            "[57]\tvalidation_0-logloss:0.45182\tvalidation_1-logloss:0.45528\n",
            "[58]\tvalidation_0-logloss:0.45160\tvalidation_1-logloss:0.45512\n",
            "[59]\tvalidation_0-logloss:0.45139\tvalidation_1-logloss:0.45496\n",
            "[60]\tvalidation_0-logloss:0.45117\tvalidation_1-logloss:0.45480\n",
            "[61]\tvalidation_0-logloss:0.45096\tvalidation_1-logloss:0.45465\n",
            "[62]\tvalidation_0-logloss:0.45075\tvalidation_1-logloss:0.45450\n",
            "[63]\tvalidation_0-logloss:0.45054\tvalidation_1-logloss:0.45436\n",
            "[64]\tvalidation_0-logloss:0.45034\tvalidation_1-logloss:0.45422\n",
            "[65]\tvalidation_0-logloss:0.45015\tvalidation_1-logloss:0.45408\n",
            "[66]\tvalidation_0-logloss:0.44995\tvalidation_1-logloss:0.45394\n",
            "[67]\tvalidation_0-logloss:0.44976\tvalidation_1-logloss:0.45382\n",
            "[68]\tvalidation_0-logloss:0.44956\tvalidation_1-logloss:0.45368\n",
            "[69]\tvalidation_0-logloss:0.44937\tvalidation_1-logloss:0.45354\n",
            "[70]\tvalidation_0-logloss:0.44919\tvalidation_1-logloss:0.45343\n",
            "[71]\tvalidation_0-logloss:0.44900\tvalidation_1-logloss:0.45329\n",
            "[72]\tvalidation_0-logloss:0.44881\tvalidation_1-logloss:0.45316\n",
            "[73]\tvalidation_0-logloss:0.44862\tvalidation_1-logloss:0.45303\n",
            "[74]\tvalidation_0-logloss:0.44843\tvalidation_1-logloss:0.45290\n",
            "[75]\tvalidation_0-logloss:0.44825\tvalidation_1-logloss:0.45277\n",
            "[76]\tvalidation_0-logloss:0.44808\tvalidation_1-logloss:0.45266\n",
            "[77]\tvalidation_0-logloss:0.44791\tvalidation_1-logloss:0.45254\n",
            "[78]\tvalidation_0-logloss:0.44773\tvalidation_1-logloss:0.45242\n",
            "[79]\tvalidation_0-logloss:0.44756\tvalidation_1-logloss:0.45230\n",
            "[80]\tvalidation_0-logloss:0.44738\tvalidation_1-logloss:0.45217\n",
            "[81]\tvalidation_0-logloss:0.44721\tvalidation_1-logloss:0.45207\n",
            "[82]\tvalidation_0-logloss:0.44704\tvalidation_1-logloss:0.45195\n",
            "[83]\tvalidation_0-logloss:0.44688\tvalidation_1-logloss:0.45184\n",
            "[84]\tvalidation_0-logloss:0.44671\tvalidation_1-logloss:0.45173\n",
            "[85]\tvalidation_0-logloss:0.44655\tvalidation_1-logloss:0.45163\n",
            "[86]\tvalidation_0-logloss:0.44639\tvalidation_1-logloss:0.45153\n",
            "[87]\tvalidation_0-logloss:0.44623\tvalidation_1-logloss:0.45142\n",
            "[88]\tvalidation_0-logloss:0.44607\tvalidation_1-logloss:0.45133\n",
            "[89]\tvalidation_0-logloss:0.44591\tvalidation_1-logloss:0.45122\n",
            "[90]\tvalidation_0-logloss:0.44575\tvalidation_1-logloss:0.45112\n",
            "[91]\tvalidation_0-logloss:0.44559\tvalidation_1-logloss:0.45102\n",
            "[92]\tvalidation_0-logloss:0.44544\tvalidation_1-logloss:0.45092\n",
            "[93]\tvalidation_0-logloss:0.44530\tvalidation_1-logloss:0.45083\n",
            "[94]\tvalidation_0-logloss:0.44514\tvalidation_1-logloss:0.45073\n",
            "[95]\tvalidation_0-logloss:0.44499\tvalidation_1-logloss:0.45063\n",
            "[96]\tvalidation_0-logloss:0.44483\tvalidation_1-logloss:0.45053\n",
            "[97]\tvalidation_0-logloss:0.44469\tvalidation_1-logloss:0.45044\n",
            "[98]\tvalidation_0-logloss:0.44454\tvalidation_1-logloss:0.45033\n",
            "[99]\tvalidation_0-logloss:0.44440\tvalidation_1-logloss:0.45025\n",
            "[100]\tvalidation_0-logloss:0.44425\tvalidation_1-logloss:0.45016\n",
            "[101]\tvalidation_0-logloss:0.44411\tvalidation_1-logloss:0.45007\n",
            "[102]\tvalidation_0-logloss:0.44396\tvalidation_1-logloss:0.44997\n",
            "[103]\tvalidation_0-logloss:0.44382\tvalidation_1-logloss:0.44990\n",
            "[104]\tvalidation_0-logloss:0.44368\tvalidation_1-logloss:0.44981\n",
            "[105]\tvalidation_0-logloss:0.44353\tvalidation_1-logloss:0.44972\n",
            "[106]\tvalidation_0-logloss:0.44340\tvalidation_1-logloss:0.44964\n",
            "[107]\tvalidation_0-logloss:0.44326\tvalidation_1-logloss:0.44956\n",
            "[108]\tvalidation_0-logloss:0.44313\tvalidation_1-logloss:0.44948\n",
            "[109]\tvalidation_0-logloss:0.44300\tvalidation_1-logloss:0.44940\n",
            "[110]\tvalidation_0-logloss:0.44287\tvalidation_1-logloss:0.44933\n",
            "[111]\tvalidation_0-logloss:0.44274\tvalidation_1-logloss:0.44927\n",
            "[112]\tvalidation_0-logloss:0.44261\tvalidation_1-logloss:0.44920\n",
            "[113]\tvalidation_0-logloss:0.44248\tvalidation_1-logloss:0.44912\n",
            "[114]\tvalidation_0-logloss:0.44234\tvalidation_1-logloss:0.44906\n",
            "[115]\tvalidation_0-logloss:0.44221\tvalidation_1-logloss:0.44899\n",
            "[116]\tvalidation_0-logloss:0.44208\tvalidation_1-logloss:0.44892\n",
            "[117]\tvalidation_0-logloss:0.44195\tvalidation_1-logloss:0.44885\n",
            "[118]\tvalidation_0-logloss:0.44182\tvalidation_1-logloss:0.44879\n",
            "[119]\tvalidation_0-logloss:0.44171\tvalidation_1-logloss:0.44872\n",
            "[120]\tvalidation_0-logloss:0.44158\tvalidation_1-logloss:0.44866\n",
            "[121]\tvalidation_0-logloss:0.44144\tvalidation_1-logloss:0.44860\n",
            "[122]\tvalidation_0-logloss:0.44133\tvalidation_1-logloss:0.44854\n",
            "[123]\tvalidation_0-logloss:0.44120\tvalidation_1-logloss:0.44848\n",
            "[124]\tvalidation_0-logloss:0.44109\tvalidation_1-logloss:0.44842\n",
            "[125]\tvalidation_0-logloss:0.44096\tvalidation_1-logloss:0.44837\n",
            "[126]\tvalidation_0-logloss:0.44084\tvalidation_1-logloss:0.44831\n",
            "[127]\tvalidation_0-logloss:0.44073\tvalidation_1-logloss:0.44826\n",
            "[128]\tvalidation_0-logloss:0.44060\tvalidation_1-logloss:0.44820\n",
            "[129]\tvalidation_0-logloss:0.44050\tvalidation_1-logloss:0.44815\n",
            "[130]\tvalidation_0-logloss:0.44038\tvalidation_1-logloss:0.44810\n",
            "[131]\tvalidation_0-logloss:0.44025\tvalidation_1-logloss:0.44804\n",
            "[132]\tvalidation_0-logloss:0.44015\tvalidation_1-logloss:0.44799\n",
            "[133]\tvalidation_0-logloss:0.44004\tvalidation_1-logloss:0.44793\n",
            "[134]\tvalidation_0-logloss:0.43993\tvalidation_1-logloss:0.44787\n",
            "[135]\tvalidation_0-logloss:0.43980\tvalidation_1-logloss:0.44781\n",
            "[136]\tvalidation_0-logloss:0.43969\tvalidation_1-logloss:0.44776\n",
            "[137]\tvalidation_0-logloss:0.43958\tvalidation_1-logloss:0.44770\n",
            "[138]\tvalidation_0-logloss:0.43946\tvalidation_1-logloss:0.44764\n",
            "[139]\tvalidation_0-logloss:0.43936\tvalidation_1-logloss:0.44759\n",
            "[140]\tvalidation_0-logloss:0.43924\tvalidation_1-logloss:0.44752\n",
            "[141]\tvalidation_0-logloss:0.43913\tvalidation_1-logloss:0.44747\n",
            "[142]\tvalidation_0-logloss:0.43903\tvalidation_1-logloss:0.44742\n",
            "[143]\tvalidation_0-logloss:0.43892\tvalidation_1-logloss:0.44736\n",
            "[144]\tvalidation_0-logloss:0.43883\tvalidation_1-logloss:0.44732\n",
            "[145]\tvalidation_0-logloss:0.43872\tvalidation_1-logloss:0.44726\n",
            "[146]\tvalidation_0-logloss:0.43862\tvalidation_1-logloss:0.44722\n",
            "[147]\tvalidation_0-logloss:0.43852\tvalidation_1-logloss:0.44716\n",
            "[148]\tvalidation_0-logloss:0.43843\tvalidation_1-logloss:0.44712\n",
            "[149]\tvalidation_0-logloss:0.43832\tvalidation_1-logloss:0.44706\n",
            "[150]\tvalidation_0-logloss:0.43823\tvalidation_1-logloss:0.44702\n",
            "[151]\tvalidation_0-logloss:0.43813\tvalidation_1-logloss:0.44697\n",
            "[152]\tvalidation_0-logloss:0.43804\tvalidation_1-logloss:0.44693\n",
            "[153]\tvalidation_0-logloss:0.43794\tvalidation_1-logloss:0.44688\n",
            "[154]\tvalidation_0-logloss:0.43784\tvalidation_1-logloss:0.44684\n",
            "[155]\tvalidation_0-logloss:0.43775\tvalidation_1-logloss:0.44680\n",
            "[156]\tvalidation_0-logloss:0.43765\tvalidation_1-logloss:0.44675\n",
            "[157]\tvalidation_0-logloss:0.43756\tvalidation_1-logloss:0.44671\n",
            "[158]\tvalidation_0-logloss:0.43746\tvalidation_1-logloss:0.44667\n",
            "[159]\tvalidation_0-logloss:0.43737\tvalidation_1-logloss:0.44663\n",
            "[160]\tvalidation_0-logloss:0.43727\tvalidation_1-logloss:0.44658\n",
            "[161]\tvalidation_0-logloss:0.43718\tvalidation_1-logloss:0.44654\n",
            "[162]\tvalidation_0-logloss:0.43707\tvalidation_1-logloss:0.44649\n",
            "[163]\tvalidation_0-logloss:0.43697\tvalidation_1-logloss:0.44644\n",
            "[164]\tvalidation_0-logloss:0.43689\tvalidation_1-logloss:0.44640\n",
            "[165]\tvalidation_0-logloss:0.43679\tvalidation_1-logloss:0.44636\n",
            "[166]\tvalidation_0-logloss:0.43670\tvalidation_1-logloss:0.44633\n",
            "[167]\tvalidation_0-logloss:0.43659\tvalidation_1-logloss:0.44628\n",
            "[168]\tvalidation_0-logloss:0.43651\tvalidation_1-logloss:0.44625\n",
            "[169]\tvalidation_0-logloss:0.43643\tvalidation_1-logloss:0.44621\n",
            "[170]\tvalidation_0-logloss:0.43634\tvalidation_1-logloss:0.44617\n",
            "[171]\tvalidation_0-logloss:0.43624\tvalidation_1-logloss:0.44613\n",
            "[172]\tvalidation_0-logloss:0.43614\tvalidation_1-logloss:0.44608\n",
            "[173]\tvalidation_0-logloss:0.43603\tvalidation_1-logloss:0.44603\n",
            "[174]\tvalidation_0-logloss:0.43594\tvalidation_1-logloss:0.44600\n",
            "[175]\tvalidation_0-logloss:0.43586\tvalidation_1-logloss:0.44595\n",
            "[176]\tvalidation_0-logloss:0.43577\tvalidation_1-logloss:0.44592\n",
            "[177]\tvalidation_0-logloss:0.43570\tvalidation_1-logloss:0.44589\n",
            "[178]\tvalidation_0-logloss:0.43560\tvalidation_1-logloss:0.44585\n",
            "[179]\tvalidation_0-logloss:0.43552\tvalidation_1-logloss:0.44582\n",
            "[180]\tvalidation_0-logloss:0.43542\tvalidation_1-logloss:0.44577\n",
            "[181]\tvalidation_0-logloss:0.43533\tvalidation_1-logloss:0.44574\n",
            "[182]\tvalidation_0-logloss:0.43524\tvalidation_1-logloss:0.44571\n",
            "[183]\tvalidation_0-logloss:0.43516\tvalidation_1-logloss:0.44568\n",
            "[184]\tvalidation_0-logloss:0.43507\tvalidation_1-logloss:0.44564\n",
            "[185]\tvalidation_0-logloss:0.43498\tvalidation_1-logloss:0.44560\n",
            "[186]\tvalidation_0-logloss:0.43489\tvalidation_1-logloss:0.44556\n",
            "[187]\tvalidation_0-logloss:0.43481\tvalidation_1-logloss:0.44553\n",
            "[188]\tvalidation_0-logloss:0.43472\tvalidation_1-logloss:0.44550\n",
            "[189]\tvalidation_0-logloss:0.43464\tvalidation_1-logloss:0.44547\n",
            "[190]\tvalidation_0-logloss:0.43455\tvalidation_1-logloss:0.44544\n",
            "[191]\tvalidation_0-logloss:0.43446\tvalidation_1-logloss:0.44541\n",
            "[192]\tvalidation_0-logloss:0.43437\tvalidation_1-logloss:0.44538\n",
            "[193]\tvalidation_0-logloss:0.43428\tvalidation_1-logloss:0.44534\n",
            "[194]\tvalidation_0-logloss:0.43420\tvalidation_1-logloss:0.44532\n",
            "[195]\tvalidation_0-logloss:0.43411\tvalidation_1-logloss:0.44528\n",
            "[196]\tvalidation_0-logloss:0.43401\tvalidation_1-logloss:0.44524\n",
            "[197]\tvalidation_0-logloss:0.43392\tvalidation_1-logloss:0.44521\n",
            "[198]\tvalidation_0-logloss:0.43384\tvalidation_1-logloss:0.44518\n",
            "[199]\tvalidation_0-logloss:0.43376\tvalidation_1-logloss:0.44516\n",
            "[200]\tvalidation_0-logloss:0.43367\tvalidation_1-logloss:0.44512\n",
            "[201]\tvalidation_0-logloss:0.43358\tvalidation_1-logloss:0.44509\n",
            "[202]\tvalidation_0-logloss:0.43350\tvalidation_1-logloss:0.44507\n",
            "[203]\tvalidation_0-logloss:0.43340\tvalidation_1-logloss:0.44503\n",
            "[204]\tvalidation_0-logloss:0.43332\tvalidation_1-logloss:0.44500\n",
            "[205]\tvalidation_0-logloss:0.43323\tvalidation_1-logloss:0.44497\n",
            "[206]\tvalidation_0-logloss:0.43315\tvalidation_1-logloss:0.44494\n",
            "[207]\tvalidation_0-logloss:0.43307\tvalidation_1-logloss:0.44493\n",
            "[208]\tvalidation_0-logloss:0.43298\tvalidation_1-logloss:0.44490\n",
            "[209]\tvalidation_0-logloss:0.43289\tvalidation_1-logloss:0.44486\n",
            "[210]\tvalidation_0-logloss:0.43281\tvalidation_1-logloss:0.44484\n",
            "[211]\tvalidation_0-logloss:0.43272\tvalidation_1-logloss:0.44481\n",
            "[212]\tvalidation_0-logloss:0.43265\tvalidation_1-logloss:0.44479\n",
            "[213]\tvalidation_0-logloss:0.43257\tvalidation_1-logloss:0.44478\n",
            "[214]\tvalidation_0-logloss:0.43248\tvalidation_1-logloss:0.44475\n",
            "[215]\tvalidation_0-logloss:0.43239\tvalidation_1-logloss:0.44471\n",
            "[216]\tvalidation_0-logloss:0.43230\tvalidation_1-logloss:0.44468\n",
            "[217]\tvalidation_0-logloss:0.43220\tvalidation_1-logloss:0.44465\n",
            "[218]\tvalidation_0-logloss:0.43212\tvalidation_1-logloss:0.44462\n",
            "[219]\tvalidation_0-logloss:0.43204\tvalidation_1-logloss:0.44460\n",
            "[220]\tvalidation_0-logloss:0.43195\tvalidation_1-logloss:0.44457\n",
            "[221]\tvalidation_0-logloss:0.43186\tvalidation_1-logloss:0.44454\n",
            "[222]\tvalidation_0-logloss:0.43178\tvalidation_1-logloss:0.44452\n",
            "[223]\tvalidation_0-logloss:0.43168\tvalidation_1-logloss:0.44448\n",
            "[224]\tvalidation_0-logloss:0.43160\tvalidation_1-logloss:0.44446\n",
            "[225]\tvalidation_0-logloss:0.43152\tvalidation_1-logloss:0.44443\n",
            "[226]\tvalidation_0-logloss:0.43142\tvalidation_1-logloss:0.44440\n",
            "[227]\tvalidation_0-logloss:0.43134\tvalidation_1-logloss:0.44437\n",
            "[228]\tvalidation_0-logloss:0.43124\tvalidation_1-logloss:0.44434\n",
            "[229]\tvalidation_0-logloss:0.43116\tvalidation_1-logloss:0.44431\n",
            "[230]\tvalidation_0-logloss:0.43108\tvalidation_1-logloss:0.44429\n",
            "[231]\tvalidation_0-logloss:0.43100\tvalidation_1-logloss:0.44426\n",
            "[232]\tvalidation_0-logloss:0.43091\tvalidation_1-logloss:0.44423\n",
            "[233]\tvalidation_0-logloss:0.43083\tvalidation_1-logloss:0.44421\n",
            "[234]\tvalidation_0-logloss:0.43074\tvalidation_1-logloss:0.44418\n",
            "[235]\tvalidation_0-logloss:0.43066\tvalidation_1-logloss:0.44415\n",
            "[236]\tvalidation_0-logloss:0.43058\tvalidation_1-logloss:0.44413\n",
            "[237]\tvalidation_0-logloss:0.43049\tvalidation_1-logloss:0.44410\n",
            "[238]\tvalidation_0-logloss:0.43041\tvalidation_1-logloss:0.44408\n",
            "[239]\tvalidation_0-logloss:0.43033\tvalidation_1-logloss:0.44405\n",
            "[240]\tvalidation_0-logloss:0.43023\tvalidation_1-logloss:0.44403\n",
            "[241]\tvalidation_0-logloss:0.43015\tvalidation_1-logloss:0.44401\n",
            "[242]\tvalidation_0-logloss:0.43008\tvalidation_1-logloss:0.44399\n",
            "[243]\tvalidation_0-logloss:0.43000\tvalidation_1-logloss:0.44396\n",
            "[244]\tvalidation_0-logloss:0.42992\tvalidation_1-logloss:0.44393\n",
            "[245]\tvalidation_0-logloss:0.42984\tvalidation_1-logloss:0.44391\n",
            "[246]\tvalidation_0-logloss:0.42978\tvalidation_1-logloss:0.44389\n",
            "[247]\tvalidation_0-logloss:0.42970\tvalidation_1-logloss:0.44387\n",
            "[248]\tvalidation_0-logloss:0.42962\tvalidation_1-logloss:0.44384\n",
            "[249]\tvalidation_0-logloss:0.42954\tvalidation_1-logloss:0.44382\n",
            "[250]\tvalidation_0-logloss:0.42946\tvalidation_1-logloss:0.44379\n",
            "[251]\tvalidation_0-logloss:0.42938\tvalidation_1-logloss:0.44377\n",
            "[252]\tvalidation_0-logloss:0.42929\tvalidation_1-logloss:0.44374\n",
            "[253]\tvalidation_0-logloss:0.42922\tvalidation_1-logloss:0.44372\n",
            "[254]\tvalidation_0-logloss:0.42914\tvalidation_1-logloss:0.44369\n",
            "[255]\tvalidation_0-logloss:0.42905\tvalidation_1-logloss:0.44366\n",
            "[256]\tvalidation_0-logloss:0.42897\tvalidation_1-logloss:0.44363\n",
            "[257]\tvalidation_0-logloss:0.42889\tvalidation_1-logloss:0.44360\n",
            "[258]\tvalidation_0-logloss:0.42881\tvalidation_1-logloss:0.44357\n",
            "[259]\tvalidation_0-logloss:0.42873\tvalidation_1-logloss:0.44355\n",
            "[260]\tvalidation_0-logloss:0.42866\tvalidation_1-logloss:0.44352\n",
            "[261]\tvalidation_0-logloss:0.42858\tvalidation_1-logloss:0.44350\n",
            "[262]\tvalidation_0-logloss:0.42850\tvalidation_1-logloss:0.44347\n",
            "[263]\tvalidation_0-logloss:0.42843\tvalidation_1-logloss:0.44345\n",
            "[264]\tvalidation_0-logloss:0.42835\tvalidation_1-logloss:0.44342\n",
            "[265]\tvalidation_0-logloss:0.42827\tvalidation_1-logloss:0.44340\n",
            "[266]\tvalidation_0-logloss:0.42820\tvalidation_1-logloss:0.44337\n",
            "[267]\tvalidation_0-logloss:0.42812\tvalidation_1-logloss:0.44335\n",
            "[268]\tvalidation_0-logloss:0.42805\tvalidation_1-logloss:0.44332\n",
            "[269]\tvalidation_0-logloss:0.42797\tvalidation_1-logloss:0.44330\n",
            "[270]\tvalidation_0-logloss:0.42790\tvalidation_1-logloss:0.44328\n",
            "[271]\tvalidation_0-logloss:0.42782\tvalidation_1-logloss:0.44326\n",
            "[272]\tvalidation_0-logloss:0.42775\tvalidation_1-logloss:0.44324\n",
            "[273]\tvalidation_0-logloss:0.42768\tvalidation_1-logloss:0.44322\n",
            "[274]\tvalidation_0-logloss:0.42761\tvalidation_1-logloss:0.44320\n",
            "[275]\tvalidation_0-logloss:0.42754\tvalidation_1-logloss:0.44317\n",
            "[276]\tvalidation_0-logloss:0.42747\tvalidation_1-logloss:0.44315\n",
            "[277]\tvalidation_0-logloss:0.42740\tvalidation_1-logloss:0.44312\n",
            "[278]\tvalidation_0-logloss:0.42733\tvalidation_1-logloss:0.44310\n",
            "[279]\tvalidation_0-logloss:0.42727\tvalidation_1-logloss:0.44308\n",
            "[280]\tvalidation_0-logloss:0.42720\tvalidation_1-logloss:0.44306\n",
            "[281]\tvalidation_0-logloss:0.42712\tvalidation_1-logloss:0.44304\n",
            "[282]\tvalidation_0-logloss:0.42704\tvalidation_1-logloss:0.44301\n",
            "[283]\tvalidation_0-logloss:0.42698\tvalidation_1-logloss:0.44299\n",
            "[284]\tvalidation_0-logloss:0.42690\tvalidation_1-logloss:0.44297\n",
            "[285]\tvalidation_0-logloss:0.42683\tvalidation_1-logloss:0.44295\n",
            "[286]\tvalidation_0-logloss:0.42675\tvalidation_1-logloss:0.44292\n",
            "[287]\tvalidation_0-logloss:0.42669\tvalidation_1-logloss:0.44291\n",
            "[288]\tvalidation_0-logloss:0.42664\tvalidation_1-logloss:0.44289\n",
            "[289]\tvalidation_0-logloss:0.42656\tvalidation_1-logloss:0.44287\n",
            "[290]\tvalidation_0-logloss:0.42649\tvalidation_1-logloss:0.44285\n",
            "[291]\tvalidation_0-logloss:0.42642\tvalidation_1-logloss:0.44283\n",
            "[292]\tvalidation_0-logloss:0.42635\tvalidation_1-logloss:0.44281\n",
            "[293]\tvalidation_0-logloss:0.42628\tvalidation_1-logloss:0.44279\n",
            "[294]\tvalidation_0-logloss:0.42620\tvalidation_1-logloss:0.44276\n",
            "[295]\tvalidation_0-logloss:0.42614\tvalidation_1-logloss:0.44275\n",
            "[296]\tvalidation_0-logloss:0.42607\tvalidation_1-logloss:0.44273\n",
            "[297]\tvalidation_0-logloss:0.42599\tvalidation_1-logloss:0.44271\n",
            "[298]\tvalidation_0-logloss:0.42593\tvalidation_1-logloss:0.44269\n",
            "[299]\tvalidation_0-logloss:0.42586\tvalidation_1-logloss:0.44267\n",
            "[300]\tvalidation_0-logloss:0.42580\tvalidation_1-logloss:0.44266\n",
            "[301]\tvalidation_0-logloss:0.42573\tvalidation_1-logloss:0.44264\n",
            "[302]\tvalidation_0-logloss:0.42566\tvalidation_1-logloss:0.44262\n",
            "[303]\tvalidation_0-logloss:0.42559\tvalidation_1-logloss:0.44260\n",
            "[304]\tvalidation_0-logloss:0.42553\tvalidation_1-logloss:0.44259\n",
            "[305]\tvalidation_0-logloss:0.42545\tvalidation_1-logloss:0.44257\n",
            "[306]\tvalidation_0-logloss:0.42538\tvalidation_1-logloss:0.44255\n",
            "[307]\tvalidation_0-logloss:0.42531\tvalidation_1-logloss:0.44253\n",
            "[308]\tvalidation_0-logloss:0.42526\tvalidation_1-logloss:0.44252\n",
            "[309]\tvalidation_0-logloss:0.42520\tvalidation_1-logloss:0.44252\n",
            "[310]\tvalidation_0-logloss:0.42513\tvalidation_1-logloss:0.44251\n",
            "[311]\tvalidation_0-logloss:0.42507\tvalidation_1-logloss:0.44250\n",
            "[312]\tvalidation_0-logloss:0.42500\tvalidation_1-logloss:0.44248\n",
            "[313]\tvalidation_0-logloss:0.42493\tvalidation_1-logloss:0.44246\n",
            "[314]\tvalidation_0-logloss:0.42485\tvalidation_1-logloss:0.44245\n",
            "[315]\tvalidation_0-logloss:0.42479\tvalidation_1-logloss:0.44243\n",
            "[316]\tvalidation_0-logloss:0.42471\tvalidation_1-logloss:0.44241\n",
            "[317]\tvalidation_0-logloss:0.42466\tvalidation_1-logloss:0.44240\n",
            "[318]\tvalidation_0-logloss:0.42459\tvalidation_1-logloss:0.44239\n",
            "[319]\tvalidation_0-logloss:0.42453\tvalidation_1-logloss:0.44239\n",
            "[320]\tvalidation_0-logloss:0.42446\tvalidation_1-logloss:0.44237\n",
            "[321]\tvalidation_0-logloss:0.42440\tvalidation_1-logloss:0.44235\n",
            "[322]\tvalidation_0-logloss:0.42435\tvalidation_1-logloss:0.44234\n",
            "[323]\tvalidation_0-logloss:0.42427\tvalidation_1-logloss:0.44232\n",
            "[324]\tvalidation_0-logloss:0.42420\tvalidation_1-logloss:0.44231\n",
            "[325]\tvalidation_0-logloss:0.42414\tvalidation_1-logloss:0.44230\n",
            "[326]\tvalidation_0-logloss:0.42408\tvalidation_1-logloss:0.44229\n",
            "[327]\tvalidation_0-logloss:0.42401\tvalidation_1-logloss:0.44227\n",
            "[328]\tvalidation_0-logloss:0.42396\tvalidation_1-logloss:0.44227\n",
            "[329]\tvalidation_0-logloss:0.42388\tvalidation_1-logloss:0.44225\n",
            "[330]\tvalidation_0-logloss:0.42381\tvalidation_1-logloss:0.44223\n",
            "[331]\tvalidation_0-logloss:0.42374\tvalidation_1-logloss:0.44221\n",
            "[332]\tvalidation_0-logloss:0.42367\tvalidation_1-logloss:0.44219\n",
            "[333]\tvalidation_0-logloss:0.42360\tvalidation_1-logloss:0.44218\n",
            "[334]\tvalidation_0-logloss:0.42354\tvalidation_1-logloss:0.44217\n",
            "[335]\tvalidation_0-logloss:0.42347\tvalidation_1-logloss:0.44215\n",
            "[336]\tvalidation_0-logloss:0.42339\tvalidation_1-logloss:0.44214\n",
            "[337]\tvalidation_0-logloss:0.42334\tvalidation_1-logloss:0.44213\n",
            "[338]\tvalidation_0-logloss:0.42329\tvalidation_1-logloss:0.44212\n",
            "[339]\tvalidation_0-logloss:0.42323\tvalidation_1-logloss:0.44210\n",
            "[340]\tvalidation_0-logloss:0.42316\tvalidation_1-logloss:0.44208\n",
            "[341]\tvalidation_0-logloss:0.42310\tvalidation_1-logloss:0.44206\n",
            "[342]\tvalidation_0-logloss:0.42302\tvalidation_1-logloss:0.44205\n",
            "[343]\tvalidation_0-logloss:0.42296\tvalidation_1-logloss:0.44204\n",
            "[344]\tvalidation_0-logloss:0.42290\tvalidation_1-logloss:0.44202\n",
            "[345]\tvalidation_0-logloss:0.42284\tvalidation_1-logloss:0.44201\n",
            "[346]\tvalidation_0-logloss:0.42278\tvalidation_1-logloss:0.44200\n",
            "[347]\tvalidation_0-logloss:0.42272\tvalidation_1-logloss:0.44198\n",
            "[348]\tvalidation_0-logloss:0.42267\tvalidation_1-logloss:0.44197\n",
            "[349]\tvalidation_0-logloss:0.42257\tvalidation_1-logloss:0.44193\n",
            "[350]\tvalidation_0-logloss:0.42251\tvalidation_1-logloss:0.44191\n",
            "[351]\tvalidation_0-logloss:0.42242\tvalidation_1-logloss:0.44188\n",
            "[352]\tvalidation_0-logloss:0.42232\tvalidation_1-logloss:0.44184\n",
            "[353]\tvalidation_0-logloss:0.42227\tvalidation_1-logloss:0.44183\n",
            "[354]\tvalidation_0-logloss:0.42218\tvalidation_1-logloss:0.44179\n",
            "[355]\tvalidation_0-logloss:0.42209\tvalidation_1-logloss:0.44177\n",
            "[356]\tvalidation_0-logloss:0.42204\tvalidation_1-logloss:0.44177\n",
            "[357]\tvalidation_0-logloss:0.42195\tvalidation_1-logloss:0.44174\n",
            "[358]\tvalidation_0-logloss:0.42188\tvalidation_1-logloss:0.44172\n",
            "[359]\tvalidation_0-logloss:0.42179\tvalidation_1-logloss:0.44169\n",
            "[360]\tvalidation_0-logloss:0.42172\tvalidation_1-logloss:0.44168\n",
            "[361]\tvalidation_0-logloss:0.42164\tvalidation_1-logloss:0.44165\n",
            "[362]\tvalidation_0-logloss:0.42156\tvalidation_1-logloss:0.44164\n",
            "[363]\tvalidation_0-logloss:0.42150\tvalidation_1-logloss:0.44162\n",
            "[364]\tvalidation_0-logloss:0.42143\tvalidation_1-logloss:0.44161\n",
            "[365]\tvalidation_0-logloss:0.42135\tvalidation_1-logloss:0.44158\n",
            "[366]\tvalidation_0-logloss:0.42128\tvalidation_1-logloss:0.44157\n",
            "[367]\tvalidation_0-logloss:0.42120\tvalidation_1-logloss:0.44154\n",
            "[368]\tvalidation_0-logloss:0.42113\tvalidation_1-logloss:0.44152\n",
            "[369]\tvalidation_0-logloss:0.42109\tvalidation_1-logloss:0.44152\n",
            "[370]\tvalidation_0-logloss:0.42105\tvalidation_1-logloss:0.44151\n",
            "[371]\tvalidation_0-logloss:0.42098\tvalidation_1-logloss:0.44150\n",
            "[372]\tvalidation_0-logloss:0.42090\tvalidation_1-logloss:0.44148\n",
            "[373]\tvalidation_0-logloss:0.42086\tvalidation_1-logloss:0.44147\n",
            "[374]\tvalidation_0-logloss:0.42079\tvalidation_1-logloss:0.44145\n",
            "[375]\tvalidation_0-logloss:0.42071\tvalidation_1-logloss:0.44142\n",
            "[376]\tvalidation_0-logloss:0.42065\tvalidation_1-logloss:0.44141\n",
            "[377]\tvalidation_0-logloss:0.42060\tvalidation_1-logloss:0.44139\n",
            "[378]\tvalidation_0-logloss:0.42052\tvalidation_1-logloss:0.44136\n",
            "[379]\tvalidation_0-logloss:0.42046\tvalidation_1-logloss:0.44135\n",
            "[380]\tvalidation_0-logloss:0.42040\tvalidation_1-logloss:0.44134\n",
            "[381]\tvalidation_0-logloss:0.42035\tvalidation_1-logloss:0.44132\n",
            "[382]\tvalidation_0-logloss:0.42027\tvalidation_1-logloss:0.44130\n",
            "[383]\tvalidation_0-logloss:0.42022\tvalidation_1-logloss:0.44128\n",
            "[384]\tvalidation_0-logloss:0.42016\tvalidation_1-logloss:0.44127\n",
            "[385]\tvalidation_0-logloss:0.42011\tvalidation_1-logloss:0.44126\n",
            "[386]\tvalidation_0-logloss:0.42002\tvalidation_1-logloss:0.44123\n",
            "[387]\tvalidation_0-logloss:0.41998\tvalidation_1-logloss:0.44122\n",
            "[388]\tvalidation_0-logloss:0.41991\tvalidation_1-logloss:0.44121\n",
            "[389]\tvalidation_0-logloss:0.41987\tvalidation_1-logloss:0.44120\n",
            "[390]\tvalidation_0-logloss:0.41979\tvalidation_1-logloss:0.44118\n",
            "[391]\tvalidation_0-logloss:0.41973\tvalidation_1-logloss:0.44117\n",
            "[392]\tvalidation_0-logloss:0.41969\tvalidation_1-logloss:0.44116\n",
            "[393]\tvalidation_0-logloss:0.41964\tvalidation_1-logloss:0.44115\n",
            "[394]\tvalidation_0-logloss:0.41956\tvalidation_1-logloss:0.44113\n",
            "[395]\tvalidation_0-logloss:0.41950\tvalidation_1-logloss:0.44112\n",
            "[396]\tvalidation_0-logloss:0.41945\tvalidation_1-logloss:0.44111\n",
            "[397]\tvalidation_0-logloss:0.41938\tvalidation_1-logloss:0.44109\n",
            "[398]\tvalidation_0-logloss:0.41932\tvalidation_1-logloss:0.44108\n",
            "[399]\tvalidation_0-logloss:0.41927\tvalidation_1-logloss:0.44108\n",
            "[400]\tvalidation_0-logloss:0.41924\tvalidation_1-logloss:0.44107\n",
            "[401]\tvalidation_0-logloss:0.41917\tvalidation_1-logloss:0.44106\n",
            "[402]\tvalidation_0-logloss:0.41913\tvalidation_1-logloss:0.44106\n",
            "[403]\tvalidation_0-logloss:0.41905\tvalidation_1-logloss:0.44103\n",
            "[404]\tvalidation_0-logloss:0.41901\tvalidation_1-logloss:0.44103\n",
            "[405]\tvalidation_0-logloss:0.41896\tvalidation_1-logloss:0.44103\n",
            "[406]\tvalidation_0-logloss:0.41888\tvalidation_1-logloss:0.44101\n",
            "[407]\tvalidation_0-logloss:0.41885\tvalidation_1-logloss:0.44100\n",
            "[408]\tvalidation_0-logloss:0.41880\tvalidation_1-logloss:0.44100\n",
            "[409]\tvalidation_0-logloss:0.41872\tvalidation_1-logloss:0.44098\n",
            "[410]\tvalidation_0-logloss:0.41867\tvalidation_1-logloss:0.44097\n",
            "[411]\tvalidation_0-logloss:0.41862\tvalidation_1-logloss:0.44097\n",
            "[412]\tvalidation_0-logloss:0.41854\tvalidation_1-logloss:0.44095\n",
            "[413]\tvalidation_0-logloss:0.41848\tvalidation_1-logloss:0.44094\n",
            "[414]\tvalidation_0-logloss:0.41843\tvalidation_1-logloss:0.44094\n",
            "[415]\tvalidation_0-logloss:0.41838\tvalidation_1-logloss:0.44093\n",
            "[416]\tvalidation_0-logloss:0.41833\tvalidation_1-logloss:0.44092\n",
            "[417]\tvalidation_0-logloss:0.41828\tvalidation_1-logloss:0.44092\n",
            "[418]\tvalidation_0-logloss:0.41820\tvalidation_1-logloss:0.44089\n",
            "[419]\tvalidation_0-logloss:0.41815\tvalidation_1-logloss:0.44089\n",
            "[420]\tvalidation_0-logloss:0.41806\tvalidation_1-logloss:0.44088\n",
            "[421]\tvalidation_0-logloss:0.41802\tvalidation_1-logloss:0.44087\n",
            "[422]\tvalidation_0-logloss:0.41797\tvalidation_1-logloss:0.44086\n",
            "[423]\tvalidation_0-logloss:0.41791\tvalidation_1-logloss:0.44085\n",
            "[424]\tvalidation_0-logloss:0.41784\tvalidation_1-logloss:0.44084\n",
            "[425]\tvalidation_0-logloss:0.41779\tvalidation_1-logloss:0.44084\n",
            "[426]\tvalidation_0-logloss:0.41774\tvalidation_1-logloss:0.44083\n",
            "[427]\tvalidation_0-logloss:0.41769\tvalidation_1-logloss:0.44082\n",
            "[428]\tvalidation_0-logloss:0.41763\tvalidation_1-logloss:0.44081\n",
            "[429]\tvalidation_0-logloss:0.41759\tvalidation_1-logloss:0.44080\n",
            "[430]\tvalidation_0-logloss:0.41753\tvalidation_1-logloss:0.44079\n",
            "[431]\tvalidation_0-logloss:0.41748\tvalidation_1-logloss:0.44079\n",
            "[432]\tvalidation_0-logloss:0.41745\tvalidation_1-logloss:0.44078\n",
            "[433]\tvalidation_0-logloss:0.41738\tvalidation_1-logloss:0.44077\n",
            "[434]\tvalidation_0-logloss:0.41734\tvalidation_1-logloss:0.44077\n",
            "[435]\tvalidation_0-logloss:0.41729\tvalidation_1-logloss:0.44075\n",
            "[436]\tvalidation_0-logloss:0.41724\tvalidation_1-logloss:0.44075\n",
            "[437]\tvalidation_0-logloss:0.41721\tvalidation_1-logloss:0.44074\n",
            "[438]\tvalidation_0-logloss:0.41713\tvalidation_1-logloss:0.44072\n",
            "[439]\tvalidation_0-logloss:0.41710\tvalidation_1-logloss:0.44072\n",
            "[440]\tvalidation_0-logloss:0.41703\tvalidation_1-logloss:0.44071\n",
            "[441]\tvalidation_0-logloss:0.41698\tvalidation_1-logloss:0.44070\n",
            "[442]\tvalidation_0-logloss:0.41693\tvalidation_1-logloss:0.44069\n",
            "[443]\tvalidation_0-logloss:0.41690\tvalidation_1-logloss:0.44068\n",
            "[444]\tvalidation_0-logloss:0.41686\tvalidation_1-logloss:0.44067\n",
            "[445]\tvalidation_0-logloss:0.41682\tvalidation_1-logloss:0.44066\n",
            "[446]\tvalidation_0-logloss:0.41678\tvalidation_1-logloss:0.44066\n",
            "[447]\tvalidation_0-logloss:0.41674\tvalidation_1-logloss:0.44066\n",
            "[448]\tvalidation_0-logloss:0.41669\tvalidation_1-logloss:0.44065\n",
            "[449]\tvalidation_0-logloss:0.41666\tvalidation_1-logloss:0.44064\n",
            "[450]\tvalidation_0-logloss:0.41662\tvalidation_1-logloss:0.44063\n",
            "[451]\tvalidation_0-logloss:0.41656\tvalidation_1-logloss:0.44063\n",
            "[452]\tvalidation_0-logloss:0.41650\tvalidation_1-logloss:0.44062\n",
            "[453]\tvalidation_0-logloss:0.41644\tvalidation_1-logloss:0.44060\n",
            "[454]\tvalidation_0-logloss:0.41640\tvalidation_1-logloss:0.44060\n",
            "[455]\tvalidation_0-logloss:0.41636\tvalidation_1-logloss:0.44059\n",
            "[456]\tvalidation_0-logloss:0.41633\tvalidation_1-logloss:0.44058\n",
            "[457]\tvalidation_0-logloss:0.41628\tvalidation_1-logloss:0.44058\n",
            "[458]\tvalidation_0-logloss:0.41625\tvalidation_1-logloss:0.44057\n",
            "[459]\tvalidation_0-logloss:0.41618\tvalidation_1-logloss:0.44055\n",
            "[460]\tvalidation_0-logloss:0.41615\tvalidation_1-logloss:0.44055\n",
            "[461]\tvalidation_0-logloss:0.41611\tvalidation_1-logloss:0.44054\n",
            "[462]\tvalidation_0-logloss:0.41607\tvalidation_1-logloss:0.44054\n",
            "[463]\tvalidation_0-logloss:0.41602\tvalidation_1-logloss:0.44053\n",
            "[464]\tvalidation_0-logloss:0.41597\tvalidation_1-logloss:0.44052\n",
            "[465]\tvalidation_0-logloss:0.41592\tvalidation_1-logloss:0.44051\n",
            "[466]\tvalidation_0-logloss:0.41589\tvalidation_1-logloss:0.44051\n",
            "[467]\tvalidation_0-logloss:0.41582\tvalidation_1-logloss:0.44049\n",
            "[468]\tvalidation_0-logloss:0.41577\tvalidation_1-logloss:0.44048\n",
            "[469]\tvalidation_0-logloss:0.41574\tvalidation_1-logloss:0.44047\n",
            "[470]\tvalidation_0-logloss:0.41569\tvalidation_1-logloss:0.44046\n",
            "[471]\tvalidation_0-logloss:0.41565\tvalidation_1-logloss:0.44046\n",
            "[472]\tvalidation_0-logloss:0.41558\tvalidation_1-logloss:0.44044\n",
            "[473]\tvalidation_0-logloss:0.41554\tvalidation_1-logloss:0.44044\n",
            "[474]\tvalidation_0-logloss:0.41551\tvalidation_1-logloss:0.44043\n",
            "[475]\tvalidation_0-logloss:0.41546\tvalidation_1-logloss:0.44042\n",
            "[476]\tvalidation_0-logloss:0.41542\tvalidation_1-logloss:0.44042\n",
            "[477]\tvalidation_0-logloss:0.41538\tvalidation_1-logloss:0.44042\n",
            "[478]\tvalidation_0-logloss:0.41533\tvalidation_1-logloss:0.44041\n",
            "[479]\tvalidation_0-logloss:0.41527\tvalidation_1-logloss:0.44040\n",
            "[480]\tvalidation_0-logloss:0.41523\tvalidation_1-logloss:0.44040\n",
            "[481]\tvalidation_0-logloss:0.41519\tvalidation_1-logloss:0.44039\n",
            "[482]\tvalidation_0-logloss:0.41515\tvalidation_1-logloss:0.44039\n",
            "[483]\tvalidation_0-logloss:0.41509\tvalidation_1-logloss:0.44037\n",
            "[484]\tvalidation_0-logloss:0.41503\tvalidation_1-logloss:0.44036\n",
            "[485]\tvalidation_0-logloss:0.41500\tvalidation_1-logloss:0.44036\n",
            "[486]\tvalidation_0-logloss:0.41494\tvalidation_1-logloss:0.44034\n",
            "[487]\tvalidation_0-logloss:0.41489\tvalidation_1-logloss:0.44034\n",
            "[488]\tvalidation_0-logloss:0.41486\tvalidation_1-logloss:0.44034\n",
            "[489]\tvalidation_0-logloss:0.41480\tvalidation_1-logloss:0.44032\n",
            "[490]\tvalidation_0-logloss:0.41475\tvalidation_1-logloss:0.44031\n",
            "[491]\tvalidation_0-logloss:0.41471\tvalidation_1-logloss:0.44030\n",
            "[492]\tvalidation_0-logloss:0.41468\tvalidation_1-logloss:0.44029\n",
            "[493]\tvalidation_0-logloss:0.41465\tvalidation_1-logloss:0.44029\n",
            "[494]\tvalidation_0-logloss:0.41459\tvalidation_1-logloss:0.44028\n",
            "[495]\tvalidation_0-logloss:0.41456\tvalidation_1-logloss:0.44028\n",
            "[496]\tvalidation_0-logloss:0.41451\tvalidation_1-logloss:0.44027\n",
            "[497]\tvalidation_0-logloss:0.41447\tvalidation_1-logloss:0.44026\n",
            "[498]\tvalidation_0-logloss:0.41443\tvalidation_1-logloss:0.44026\n",
            "[499]\tvalidation_0-logloss:0.41440\tvalidation_1-logloss:0.44026\n",
            "[500]\tvalidation_0-logloss:0.41435\tvalidation_1-logloss:0.44024\n",
            "[501]\tvalidation_0-logloss:0.41429\tvalidation_1-logloss:0.44023\n",
            "[502]\tvalidation_0-logloss:0.41426\tvalidation_1-logloss:0.44023\n",
            "[503]\tvalidation_0-logloss:0.41423\tvalidation_1-logloss:0.44022\n",
            "[504]\tvalidation_0-logloss:0.41420\tvalidation_1-logloss:0.44022\n",
            "[505]\tvalidation_0-logloss:0.41416\tvalidation_1-logloss:0.44021\n",
            "[506]\tvalidation_0-logloss:0.41414\tvalidation_1-logloss:0.44021\n",
            "[507]\tvalidation_0-logloss:0.41410\tvalidation_1-logloss:0.44021\n",
            "[508]\tvalidation_0-logloss:0.41406\tvalidation_1-logloss:0.44020\n",
            "[509]\tvalidation_0-logloss:0.41402\tvalidation_1-logloss:0.44020\n",
            "[510]\tvalidation_0-logloss:0.41399\tvalidation_1-logloss:0.44020\n",
            "[511]\tvalidation_0-logloss:0.41396\tvalidation_1-logloss:0.44020\n",
            "[512]\tvalidation_0-logloss:0.41392\tvalidation_1-logloss:0.44020\n",
            "[513]\tvalidation_0-logloss:0.41387\tvalidation_1-logloss:0.44018\n",
            "[514]\tvalidation_0-logloss:0.41382\tvalidation_1-logloss:0.44018\n",
            "[515]\tvalidation_0-logloss:0.41379\tvalidation_1-logloss:0.44018\n",
            "[516]\tvalidation_0-logloss:0.41376\tvalidation_1-logloss:0.44017\n",
            "[517]\tvalidation_0-logloss:0.41374\tvalidation_1-logloss:0.44017\n",
            "[518]\tvalidation_0-logloss:0.41369\tvalidation_1-logloss:0.44016\n",
            "[519]\tvalidation_0-logloss:0.41363\tvalidation_1-logloss:0.44014\n",
            "[520]\tvalidation_0-logloss:0.41360\tvalidation_1-logloss:0.44014\n",
            "[521]\tvalidation_0-logloss:0.41357\tvalidation_1-logloss:0.44014\n",
            "[522]\tvalidation_0-logloss:0.41353\tvalidation_1-logloss:0.44014\n",
            "[523]\tvalidation_0-logloss:0.41350\tvalidation_1-logloss:0.44014\n",
            "[524]\tvalidation_0-logloss:0.41344\tvalidation_1-logloss:0.44012\n",
            "[525]\tvalidation_0-logloss:0.41339\tvalidation_1-logloss:0.44011\n",
            "[526]\tvalidation_0-logloss:0.41336\tvalidation_1-logloss:0.44011\n",
            "[527]\tvalidation_0-logloss:0.41330\tvalidation_1-logloss:0.44009\n",
            "[528]\tvalidation_0-logloss:0.41326\tvalidation_1-logloss:0.44009\n",
            "[529]\tvalidation_0-logloss:0.41323\tvalidation_1-logloss:0.44009\n",
            "[530]\tvalidation_0-logloss:0.41316\tvalidation_1-logloss:0.44008\n",
            "[531]\tvalidation_0-logloss:0.41311\tvalidation_1-logloss:0.44007\n",
            "[532]\tvalidation_0-logloss:0.41307\tvalidation_1-logloss:0.44007\n",
            "[533]\tvalidation_0-logloss:0.41304\tvalidation_1-logloss:0.44007\n",
            "[534]\tvalidation_0-logloss:0.41300\tvalidation_1-logloss:0.44007\n",
            "[535]\tvalidation_0-logloss:0.41295\tvalidation_1-logloss:0.44006\n",
            "[536]\tvalidation_0-logloss:0.41292\tvalidation_1-logloss:0.44006\n",
            "[537]\tvalidation_0-logloss:0.41287\tvalidation_1-logloss:0.44005\n",
            "[538]\tvalidation_0-logloss:0.41284\tvalidation_1-logloss:0.44005\n",
            "[539]\tvalidation_0-logloss:0.41281\tvalidation_1-logloss:0.44005\n",
            "[540]\tvalidation_0-logloss:0.41277\tvalidation_1-logloss:0.44004\n",
            "[541]\tvalidation_0-logloss:0.41273\tvalidation_1-logloss:0.44004\n",
            "[542]\tvalidation_0-logloss:0.41271\tvalidation_1-logloss:0.44003\n",
            "[543]\tvalidation_0-logloss:0.41268\tvalidation_1-logloss:0.44003\n",
            "[544]\tvalidation_0-logloss:0.41265\tvalidation_1-logloss:0.44002\n",
            "[545]\tvalidation_0-logloss:0.41262\tvalidation_1-logloss:0.44002\n",
            "[546]\tvalidation_0-logloss:0.41258\tvalidation_1-logloss:0.44001\n",
            "[547]\tvalidation_0-logloss:0.41255\tvalidation_1-logloss:0.44001\n",
            "[548]\tvalidation_0-logloss:0.41248\tvalidation_1-logloss:0.43999\n",
            "[549]\tvalidation_0-logloss:0.41245\tvalidation_1-logloss:0.43999\n",
            "[550]\tvalidation_0-logloss:0.41239\tvalidation_1-logloss:0.43998\n",
            "[551]\tvalidation_0-logloss:0.41236\tvalidation_1-logloss:0.43997\n",
            "[552]\tvalidation_0-logloss:0.41232\tvalidation_1-logloss:0.43996\n",
            "[553]\tvalidation_0-logloss:0.41229\tvalidation_1-logloss:0.43996\n",
            "[554]\tvalidation_0-logloss:0.41223\tvalidation_1-logloss:0.43996\n",
            "[555]\tvalidation_0-logloss:0.41216\tvalidation_1-logloss:0.43994\n",
            "[556]\tvalidation_0-logloss:0.41213\tvalidation_1-logloss:0.43994\n",
            "[557]\tvalidation_0-logloss:0.41206\tvalidation_1-logloss:0.43993\n",
            "[558]\tvalidation_0-logloss:0.41200\tvalidation_1-logloss:0.43991\n",
            "[559]\tvalidation_0-logloss:0.41196\tvalidation_1-logloss:0.43991\n",
            "[560]\tvalidation_0-logloss:0.41193\tvalidation_1-logloss:0.43991\n",
            "[561]\tvalidation_0-logloss:0.41188\tvalidation_1-logloss:0.43990\n",
            "[562]\tvalidation_0-logloss:0.41182\tvalidation_1-logloss:0.43989\n",
            "[563]\tvalidation_0-logloss:0.41177\tvalidation_1-logloss:0.43988\n",
            "[564]\tvalidation_0-logloss:0.41171\tvalidation_1-logloss:0.43987\n",
            "[565]\tvalidation_0-logloss:0.41165\tvalidation_1-logloss:0.43986\n",
            "[566]\tvalidation_0-logloss:0.41159\tvalidation_1-logloss:0.43984\n",
            "[567]\tvalidation_0-logloss:0.41154\tvalidation_1-logloss:0.43984\n",
            "[568]\tvalidation_0-logloss:0.41148\tvalidation_1-logloss:0.43983\n",
            "[569]\tvalidation_0-logloss:0.41144\tvalidation_1-logloss:0.43982\n",
            "[570]\tvalidation_0-logloss:0.41142\tvalidation_1-logloss:0.43982\n",
            "[571]\tvalidation_0-logloss:0.41139\tvalidation_1-logloss:0.43982\n",
            "[572]\tvalidation_0-logloss:0.41135\tvalidation_1-logloss:0.43982\n",
            "[573]\tvalidation_0-logloss:0.41132\tvalidation_1-logloss:0.43982\n",
            "[574]\tvalidation_0-logloss:0.41127\tvalidation_1-logloss:0.43981\n",
            "[575]\tvalidation_0-logloss:0.41124\tvalidation_1-logloss:0.43981\n",
            "[576]\tvalidation_0-logloss:0.41122\tvalidation_1-logloss:0.43981\n",
            "[577]\tvalidation_0-logloss:0.41116\tvalidation_1-logloss:0.43980\n",
            "[578]\tvalidation_0-logloss:0.41111\tvalidation_1-logloss:0.43980\n",
            "[579]\tvalidation_0-logloss:0.41109\tvalidation_1-logloss:0.43980\n",
            "[580]\tvalidation_0-logloss:0.41103\tvalidation_1-logloss:0.43979\n",
            "[581]\tvalidation_0-logloss:0.41101\tvalidation_1-logloss:0.43979\n",
            "[582]\tvalidation_0-logloss:0.41095\tvalidation_1-logloss:0.43978\n",
            "[583]\tvalidation_0-logloss:0.41089\tvalidation_1-logloss:0.43977\n",
            "[584]\tvalidation_0-logloss:0.41085\tvalidation_1-logloss:0.43976\n",
            "[585]\tvalidation_0-logloss:0.41084\tvalidation_1-logloss:0.43976\n",
            "[586]\tvalidation_0-logloss:0.41078\tvalidation_1-logloss:0.43976\n",
            "[587]\tvalidation_0-logloss:0.41071\tvalidation_1-logloss:0.43974\n",
            "[588]\tvalidation_0-logloss:0.41068\tvalidation_1-logloss:0.43974\n",
            "[589]\tvalidation_0-logloss:0.41064\tvalidation_1-logloss:0.43974\n",
            "[590]\tvalidation_0-logloss:0.41061\tvalidation_1-logloss:0.43974\n",
            "[591]\tvalidation_0-logloss:0.41055\tvalidation_1-logloss:0.43973\n",
            "[592]\tvalidation_0-logloss:0.41053\tvalidation_1-logloss:0.43972\n",
            "[593]\tvalidation_0-logloss:0.41050\tvalidation_1-logloss:0.43972\n",
            "[594]\tvalidation_0-logloss:0.41046\tvalidation_1-logloss:0.43972\n",
            "[595]\tvalidation_0-logloss:0.41042\tvalidation_1-logloss:0.43972\n",
            "[596]\tvalidation_0-logloss:0.41040\tvalidation_1-logloss:0.43972\n",
            "[597]\tvalidation_0-logloss:0.41033\tvalidation_1-logloss:0.43970\n",
            "[598]\tvalidation_0-logloss:0.41028\tvalidation_1-logloss:0.43970\n",
            "[599]\tvalidation_0-logloss:0.41026\tvalidation_1-logloss:0.43970\n",
            "[600]\tvalidation_0-logloss:0.41021\tvalidation_1-logloss:0.43970\n",
            "[601]\tvalidation_0-logloss:0.41016\tvalidation_1-logloss:0.43970\n",
            "[602]\tvalidation_0-logloss:0.41014\tvalidation_1-logloss:0.43970\n",
            "[603]\tvalidation_0-logloss:0.41009\tvalidation_1-logloss:0.43969\n",
            "[604]\tvalidation_0-logloss:0.41006\tvalidation_1-logloss:0.43969\n",
            "[605]\tvalidation_0-logloss:0.41003\tvalidation_1-logloss:0.43969\n",
            "[606]\tvalidation_0-logloss:0.40998\tvalidation_1-logloss:0.43968\n",
            "[607]\tvalidation_0-logloss:0.40993\tvalidation_1-logloss:0.43968\n",
            "[608]\tvalidation_0-logloss:0.40991\tvalidation_1-logloss:0.43968\n",
            "[609]\tvalidation_0-logloss:0.40989\tvalidation_1-logloss:0.43968\n",
            "[610]\tvalidation_0-logloss:0.40986\tvalidation_1-logloss:0.43968\n",
            "[611]\tvalidation_0-logloss:0.40980\tvalidation_1-logloss:0.43967\n",
            "[612]\tvalidation_0-logloss:0.40976\tvalidation_1-logloss:0.43967\n",
            "[613]\tvalidation_0-logloss:0.40974\tvalidation_1-logloss:0.43968\n",
            "[614]\tvalidation_0-logloss:0.40969\tvalidation_1-logloss:0.43967\n",
            "[615]\tvalidation_0-logloss:0.40967\tvalidation_1-logloss:0.43967\n",
            "[616]\tvalidation_0-logloss:0.40962\tvalidation_1-logloss:0.43966\n",
            "[617]\tvalidation_0-logloss:0.40958\tvalidation_1-logloss:0.43966\n",
            "[618]\tvalidation_0-logloss:0.40955\tvalidation_1-logloss:0.43966\n",
            "[619]\tvalidation_0-logloss:0.40952\tvalidation_1-logloss:0.43966\n",
            "[620]\tvalidation_0-logloss:0.40950\tvalidation_1-logloss:0.43966\n",
            "[621]\tvalidation_0-logloss:0.40945\tvalidation_1-logloss:0.43966\n",
            "[622]\tvalidation_0-logloss:0.40941\tvalidation_1-logloss:0.43966\n",
            "[623]\tvalidation_0-logloss:0.40938\tvalidation_1-logloss:0.43966\n",
            "[624]\tvalidation_0-logloss:0.40934\tvalidation_1-logloss:0.43966\n",
            "[625]\tvalidation_0-logloss:0.40929\tvalidation_1-logloss:0.43966\n",
            "[626]\tvalidation_0-logloss:0.40926\tvalidation_1-logloss:0.43966\n",
            "[627]\tvalidation_0-logloss:0.40922\tvalidation_1-logloss:0.43965\n",
            "[628]\tvalidation_0-logloss:0.40917\tvalidation_1-logloss:0.43965\n",
            "[629]\tvalidation_0-logloss:0.40912\tvalidation_1-logloss:0.43965\n",
            "[630]\tvalidation_0-logloss:0.40909\tvalidation_1-logloss:0.43966\n",
            "[631]\tvalidation_0-logloss:0.40906\tvalidation_1-logloss:0.43965\n",
            "[632]\tvalidation_0-logloss:0.40904\tvalidation_1-logloss:0.43965\n",
            "[633]\tvalidation_0-logloss:0.40901\tvalidation_1-logloss:0.43965\n",
            "[634]\tvalidation_0-logloss:0.40898\tvalidation_1-logloss:0.43965\n",
            "[635]\tvalidation_0-logloss:0.40895\tvalidation_1-logloss:0.43965\n",
            "[636]\tvalidation_0-logloss:0.40892\tvalidation_1-logloss:0.43966\n",
            "[637]\tvalidation_0-logloss:0.40889\tvalidation_1-logloss:0.43965\n",
            "[638]\tvalidation_0-logloss:0.40886\tvalidation_1-logloss:0.43965\n",
            "[639]\tvalidation_0-logloss:0.40881\tvalidation_1-logloss:0.43964\n",
            "[640]\tvalidation_0-logloss:0.40879\tvalidation_1-logloss:0.43964\n",
            "[641]\tvalidation_0-logloss:0.40876\tvalidation_1-logloss:0.43964\n",
            "[642]\tvalidation_0-logloss:0.40871\tvalidation_1-logloss:0.43965\n",
            "[643]\tvalidation_0-logloss:0.40868\tvalidation_1-logloss:0.43964\n",
            "[644]\tvalidation_0-logloss:0.40866\tvalidation_1-logloss:0.43965\n",
            "[645]\tvalidation_0-logloss:0.40863\tvalidation_1-logloss:0.43965\n",
            "[646]\tvalidation_0-logloss:0.40858\tvalidation_1-logloss:0.43964\n",
            "[647]\tvalidation_0-logloss:0.40853\tvalidation_1-logloss:0.43963\n",
            "[648]\tvalidation_0-logloss:0.40850\tvalidation_1-logloss:0.43964\n",
            "[649]\tvalidation_0-logloss:0.40848\tvalidation_1-logloss:0.43964\n",
            "[650]\tvalidation_0-logloss:0.40843\tvalidation_1-logloss:0.43963\n",
            "[651]\tvalidation_0-logloss:0.40840\tvalidation_1-logloss:0.43963\n",
            "[652]\tvalidation_0-logloss:0.40837\tvalidation_1-logloss:0.43963\n",
            "[653]\tvalidation_0-logloss:0.40832\tvalidation_1-logloss:0.43963\n",
            "[654]\tvalidation_0-logloss:0.40830\tvalidation_1-logloss:0.43963\n",
            "[655]\tvalidation_0-logloss:0.40826\tvalidation_1-logloss:0.43963\n",
            "[656]\tvalidation_0-logloss:0.40823\tvalidation_1-logloss:0.43962\n",
            "[657]\tvalidation_0-logloss:0.40821\tvalidation_1-logloss:0.43963\n",
            "[658]\tvalidation_0-logloss:0.40818\tvalidation_1-logloss:0.43963\n",
            "[659]\tvalidation_0-logloss:0.40815\tvalidation_1-logloss:0.43962\n",
            "[660]\tvalidation_0-logloss:0.40810\tvalidation_1-logloss:0.43962\n",
            "[661]\tvalidation_0-logloss:0.40806\tvalidation_1-logloss:0.43961\n",
            "[662]\tvalidation_0-logloss:0.40803\tvalidation_1-logloss:0.43961\n",
            "[663]\tvalidation_0-logloss:0.40801\tvalidation_1-logloss:0.43962\n",
            "[664]\tvalidation_0-logloss:0.40795\tvalidation_1-logloss:0.43960\n",
            "[665]\tvalidation_0-logloss:0.40793\tvalidation_1-logloss:0.43961\n",
            "[666]\tvalidation_0-logloss:0.40789\tvalidation_1-logloss:0.43961\n",
            "[667]\tvalidation_0-logloss:0.40783\tvalidation_1-logloss:0.43960\n",
            "[668]\tvalidation_0-logloss:0.40781\tvalidation_1-logloss:0.43961\n",
            "[669]\tvalidation_0-logloss:0.40779\tvalidation_1-logloss:0.43961\n",
            "[670]\tvalidation_0-logloss:0.40773\tvalidation_1-logloss:0.43960\n",
            "[671]\tvalidation_0-logloss:0.40771\tvalidation_1-logloss:0.43960\n",
            "[672]\tvalidation_0-logloss:0.40766\tvalidation_1-logloss:0.43960\n",
            "[673]\tvalidation_0-logloss:0.40762\tvalidation_1-logloss:0.43959\n",
            "[674]\tvalidation_0-logloss:0.40760\tvalidation_1-logloss:0.43960\n",
            "[675]\tvalidation_0-logloss:0.40757\tvalidation_1-logloss:0.43960\n",
            "[676]\tvalidation_0-logloss:0.40752\tvalidation_1-logloss:0.43959\n",
            "[677]\tvalidation_0-logloss:0.40747\tvalidation_1-logloss:0.43958\n",
            "[678]\tvalidation_0-logloss:0.40742\tvalidation_1-logloss:0.43958\n",
            "[679]\tvalidation_0-logloss:0.40737\tvalidation_1-logloss:0.43957\n",
            "[680]\tvalidation_0-logloss:0.40734\tvalidation_1-logloss:0.43957\n",
            "[681]\tvalidation_0-logloss:0.40732\tvalidation_1-logloss:0.43957\n",
            "[682]\tvalidation_0-logloss:0.40730\tvalidation_1-logloss:0.43958\n",
            "[683]\tvalidation_0-logloss:0.40725\tvalidation_1-logloss:0.43957\n",
            "[684]\tvalidation_0-logloss:0.40721\tvalidation_1-logloss:0.43956\n",
            "[685]\tvalidation_0-logloss:0.40718\tvalidation_1-logloss:0.43956\n",
            "[686]\tvalidation_0-logloss:0.40716\tvalidation_1-logloss:0.43956\n",
            "[687]\tvalidation_0-logloss:0.40711\tvalidation_1-logloss:0.43956\n",
            "[688]\tvalidation_0-logloss:0.40707\tvalidation_1-logloss:0.43955\n",
            "[689]\tvalidation_0-logloss:0.40704\tvalidation_1-logloss:0.43955\n",
            "[690]\tvalidation_0-logloss:0.40702\tvalidation_1-logloss:0.43955\n",
            "[691]\tvalidation_0-logloss:0.40698\tvalidation_1-logloss:0.43955\n",
            "[692]\tvalidation_0-logloss:0.40695\tvalidation_1-logloss:0.43955\n",
            "[693]\tvalidation_0-logloss:0.40693\tvalidation_1-logloss:0.43954\n",
            "[694]\tvalidation_0-logloss:0.40691\tvalidation_1-logloss:0.43955\n",
            "[695]\tvalidation_0-logloss:0.40689\tvalidation_1-logloss:0.43955\n",
            "[696]\tvalidation_0-logloss:0.40686\tvalidation_1-logloss:0.43954\n",
            "[697]\tvalidation_0-logloss:0.40683\tvalidation_1-logloss:0.43954\n",
            "[698]\tvalidation_0-logloss:0.40680\tvalidation_1-logloss:0.43954\n",
            "[699]\tvalidation_0-logloss:0.40677\tvalidation_1-logloss:0.43954\n",
            "[700]\tvalidation_0-logloss:0.40674\tvalidation_1-logloss:0.43954\n",
            "[701]\tvalidation_0-logloss:0.40671\tvalidation_1-logloss:0.43954\n",
            "[702]\tvalidation_0-logloss:0.40667\tvalidation_1-logloss:0.43954\n",
            "[703]\tvalidation_0-logloss:0.40664\tvalidation_1-logloss:0.43954\n",
            "[704]\tvalidation_0-logloss:0.40661\tvalidation_1-logloss:0.43954\n",
            "[705]\tvalidation_0-logloss:0.40658\tvalidation_1-logloss:0.43954\n",
            "[706]\tvalidation_0-logloss:0.40655\tvalidation_1-logloss:0.43954\n",
            "[707]\tvalidation_0-logloss:0.40653\tvalidation_1-logloss:0.43954\n",
            "[708]\tvalidation_0-logloss:0.40649\tvalidation_1-logloss:0.43954\n",
            "[709]\tvalidation_0-logloss:0.40646\tvalidation_1-logloss:0.43954\n",
            "[710]\tvalidation_0-logloss:0.40643\tvalidation_1-logloss:0.43954\n",
            "[711]\tvalidation_0-logloss:0.40639\tvalidation_1-logloss:0.43954\n",
            "[712]\tvalidation_0-logloss:0.40636\tvalidation_1-logloss:0.43953\n",
            "[713]\tvalidation_0-logloss:0.40634\tvalidation_1-logloss:0.43954\n",
            "[714]\tvalidation_0-logloss:0.40630\tvalidation_1-logloss:0.43953\n",
            "[715]\tvalidation_0-logloss:0.40627\tvalidation_1-logloss:0.43953\n",
            "[716]\tvalidation_0-logloss:0.40625\tvalidation_1-logloss:0.43953\n",
            "[717]\tvalidation_0-logloss:0.40623\tvalidation_1-logloss:0.43953\n",
            "[718]\tvalidation_0-logloss:0.40620\tvalidation_1-logloss:0.43953\n",
            "[719]\tvalidation_0-logloss:0.40617\tvalidation_1-logloss:0.43953\n",
            "[720]\tvalidation_0-logloss:0.40613\tvalidation_1-logloss:0.43952\n",
            "[721]\tvalidation_0-logloss:0.40610\tvalidation_1-logloss:0.43952\n",
            "[722]\tvalidation_0-logloss:0.40608\tvalidation_1-logloss:0.43952\n",
            "[723]\tvalidation_0-logloss:0.40605\tvalidation_1-logloss:0.43952\n",
            "[724]\tvalidation_0-logloss:0.40601\tvalidation_1-logloss:0.43952\n",
            "[725]\tvalidation_0-logloss:0.40599\tvalidation_1-logloss:0.43952\n",
            "[726]\tvalidation_0-logloss:0.40596\tvalidation_1-logloss:0.43952\n",
            "[727]\tvalidation_0-logloss:0.40592\tvalidation_1-logloss:0.43952\n",
            "[728]\tvalidation_0-logloss:0.40589\tvalidation_1-logloss:0.43952\n",
            "[729]\tvalidation_0-logloss:0.40586\tvalidation_1-logloss:0.43951\n",
            "[730]\tvalidation_0-logloss:0.40584\tvalidation_1-logloss:0.43951\n",
            "[731]\tvalidation_0-logloss:0.40582\tvalidation_1-logloss:0.43951\n",
            "[732]\tvalidation_0-logloss:0.40578\tvalidation_1-logloss:0.43951\n",
            "[733]\tvalidation_0-logloss:0.40575\tvalidation_1-logloss:0.43951\n",
            "[734]\tvalidation_0-logloss:0.40573\tvalidation_1-logloss:0.43951\n",
            "[735]\tvalidation_0-logloss:0.40571\tvalidation_1-logloss:0.43951\n",
            "[736]\tvalidation_0-logloss:0.40567\tvalidation_1-logloss:0.43951\n",
            "[737]\tvalidation_0-logloss:0.40565\tvalidation_1-logloss:0.43951\n",
            "[738]\tvalidation_0-logloss:0.40561\tvalidation_1-logloss:0.43951\n",
            "[739]\tvalidation_0-logloss:0.40559\tvalidation_1-logloss:0.43951\n",
            "[740]\tvalidation_0-logloss:0.40556\tvalidation_1-logloss:0.43951\n",
            "[741]\tvalidation_0-logloss:0.40553\tvalidation_1-logloss:0.43951\n",
            "[742]\tvalidation_0-logloss:0.40551\tvalidation_1-logloss:0.43951\n",
            "[743]\tvalidation_0-logloss:0.40548\tvalidation_1-logloss:0.43951\n",
            "[744]\tvalidation_0-logloss:0.40545\tvalidation_1-logloss:0.43951\n",
            "[745]\tvalidation_0-logloss:0.40543\tvalidation_1-logloss:0.43951\n",
            "[746]\tvalidation_0-logloss:0.40539\tvalidation_1-logloss:0.43951\n",
            "[747]\tvalidation_0-logloss:0.40536\tvalidation_1-logloss:0.43951\n",
            "[748]\tvalidation_0-logloss:0.40533\tvalidation_1-logloss:0.43951\n",
            "[749]\tvalidation_0-logloss:0.40531\tvalidation_1-logloss:0.43952\n",
            "[750]\tvalidation_0-logloss:0.40529\tvalidation_1-logloss:0.43952\n",
            "[751]\tvalidation_0-logloss:0.40524\tvalidation_1-logloss:0.43952\n",
            "[752]\tvalidation_0-logloss:0.40522\tvalidation_1-logloss:0.43952\n",
            "[753]\tvalidation_0-logloss:0.40518\tvalidation_1-logloss:0.43952\n",
            "[754]\tvalidation_0-logloss:0.40516\tvalidation_1-logloss:0.43953\n",
            "[755]\tvalidation_0-logloss:0.40513\tvalidation_1-logloss:0.43953\n",
            "[756]\tvalidation_0-logloss:0.40510\tvalidation_1-logloss:0.43952\n",
            "[757]\tvalidation_0-logloss:0.40508\tvalidation_1-logloss:0.43953\n",
            "[758]\tvalidation_0-logloss:0.40505\tvalidation_1-logloss:0.43953\n",
            "[759]\tvalidation_0-logloss:0.40502\tvalidation_1-logloss:0.43953\n",
            "[760]\tvalidation_0-logloss:0.40499\tvalidation_1-logloss:0.43953\n",
            "[761]\tvalidation_0-logloss:0.40497\tvalidation_1-logloss:0.43953\n",
            "[762]\tvalidation_0-logloss:0.40494\tvalidation_1-logloss:0.43953\n",
            "[763]\tvalidation_0-logloss:0.40492\tvalidation_1-logloss:0.43954\n",
            "[764]\tvalidation_0-logloss:0.40488\tvalidation_1-logloss:0.43953\n",
            "[765]\tvalidation_0-logloss:0.40485\tvalidation_1-logloss:0.43953\n",
            "[766]\tvalidation_0-logloss:0.40482\tvalidation_1-logloss:0.43954\n",
            "[767]\tvalidation_0-logloss:0.40479\tvalidation_1-logloss:0.43954\n",
            "[768]\tvalidation_0-logloss:0.40476\tvalidation_1-logloss:0.43954\n",
            "[769]\tvalidation_0-logloss:0.40474\tvalidation_1-logloss:0.43954\n",
            "[770]\tvalidation_0-logloss:0.40470\tvalidation_1-logloss:0.43954\n",
            "[771]\tvalidation_0-logloss:0.40467\tvalidation_1-logloss:0.43955\n",
            "[772]\tvalidation_0-logloss:0.40464\tvalidation_1-logloss:0.43955\n",
            "[773]\tvalidation_0-logloss:0.40462\tvalidation_1-logloss:0.43954\n",
            "[774]\tvalidation_0-logloss:0.40459\tvalidation_1-logloss:0.43955\n",
            "[775]\tvalidation_0-logloss:0.40454\tvalidation_1-logloss:0.43954\n",
            "[776]\tvalidation_0-logloss:0.40452\tvalidation_1-logloss:0.43955\n",
            "[777]\tvalidation_0-logloss:0.40448\tvalidation_1-logloss:0.43955\n",
            "[778]\tvalidation_0-logloss:0.40445\tvalidation_1-logloss:0.43955\n",
            "[779]\tvalidation_0-logloss:0.40443\tvalidation_1-logloss:0.43955\n",
            "[780]\tvalidation_0-logloss:0.40438\tvalidation_1-logloss:0.43955\n",
            "[781]\tvalidation_0-logloss:0.40435\tvalidation_1-logloss:0.43955\n",
            "[782]\tvalidation_0-logloss:0.40433\tvalidation_1-logloss:0.43954\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=42, ...)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xgb_model.fit(X_train, y_train, early_stopping_rounds=50,\n",
        "              eval_metric=['logloss'], eval_set=[(X_train, y_train), (X_valid, y_valid)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfypRTL0KXdn",
        "outputId": "0a01ddbe-89a5-4075-cbc3-2f76026e9bd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "오차 행렬\n",
            "[[35875    69]\n",
            " [ 7608    98]]\n",
            "정확도 : 0.8241, 정밀도 : 0.5868, 재현율 : 0.0127, F1 : 0.0249\n"
          ]
        }
      ],
      "source": [
        "y_pred = xgb_model.predict(X_valid)\n",
        "get_clf_eval(y_valid, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMUbCy8jZFb7",
        "outputId": "bcb5aabc-dfbd-47d5-e8a0-58db1ce56ff8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.90     35944\n",
            "           1       0.59      0.01      0.02      7706\n",
            "\n",
            "    accuracy                           0.82     43650\n",
            "   macro avg       0.71      0.51      0.46     43650\n",
            "weighted avg       0.78      0.82      0.75     43650\n",
            "\n"
          ]
        }
      ],
      "source": [
        "xgb_report = metrics.classification_report(y_valid, y_pred, zero_division=1)\n",
        "print(xgb_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JkREoZVc4nJ"
      },
      "source": [
        "- Label 불균형의 영향으로 다른 평가지표에 비해 정확도만 높은 예측 모델이 되었다   \n",
        "- 항공편의 실제 지연 여부를 제대로 예측해야 하므로 재현율 개선이 필요하다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVKAgwEp_ino",
        "outputId": "665b295b-3ab4-4e3a-ce91-eaf52f0e501a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.08793497, 0.06394368, 0.17046417, 0.07126297, 0.        ,\n",
              "       0.05963052, 0.09186201, 0.07927898, 0.06368655, 0.08364222,\n",
              "       0.07810441, 0.06170309, 0.08848649], dtype=float32)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xgb_model.feature_importances_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "b4szs2WX-w8w",
        "outputId": "34c241c9-2c6b-4a96-c2f3-1b2d14c93ddb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-f2423103d5c9>:7: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=ftr_top20, y = ftr_top20.index, palette='pastel')\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ftr_importances_values = xgb_model.feature_importances_\n",
        "ftr_importances = pd.Series(ftr_importances_values, index=X_train.columns)\n",
        "ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.title('Feature importances Top 20')\n",
        "sns.barplot(x=ftr_top20, y = ftr_top20.index, palette='pastel')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv-FD965c1CT"
      },
      "source": [
        "# LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NltGFfGckJA",
        "outputId": "c8176ce9-9b66-4103-925a-725f4f1fb28a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(174600, 13) (174600,)\n",
            "(43650, 13) (43650,)\n"
          ]
        }
      ],
      "source": [
        "X = train.iloc[:,:-1]\n",
        "y = train.iloc[:,-1]\n",
        "\n",
        "X_train, X_valid , y_train, y_valid = train_test_split(X, y, test_size = 0.2, stratify = y, random_state=42)\n",
        "\n",
        "numeric_cols = X_train.select_dtypes(exclude=['object']).columns\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
        "X_valid[numeric_cols] = scaler.transform(X_valid[numeric_cols])\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_valid.shape, y_valid.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yRiAVHyYriM"
      },
      "outputs": [],
      "source": [
        "lgbm_model = LGBMClassifier(n_estimators=1000, num_leaves=64,\n",
        "                          n_jobs=-1, boost_from_average=False, force_col_wise=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "woCP9vuWeJSm",
        "outputId": "ad2d2861-6b62-447b-a7a8-ca2848647cee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 30823, number of negative: 143777\n",
            "[LightGBM] [Info] Total Bins 1805\n",
            "[LightGBM] [Info] Number of data points in the train set: 174600, number of used features: 12\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[103]\ttraining's binary_logloss: 0.417391\tvalid_1's binary_logloss: 0.438999\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(boost_from_average=False, force_col_wise=True, n_estimators=1000,\n",
              "               n_jobs=-1, num_leaves=64)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(boost_from_average=False, force_col_wise=True, n_estimators=1000,\n",
              "               n_jobs=-1, num_leaves=64)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LGBMClassifier(boost_from_average=False, force_col_wise=True, n_estimators=1000,\n",
              "               n_jobs=-1, num_leaves=64)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lgbm_model.fit(X_train, y_train, callbacks=[early_stopping(stopping_rounds=50)],\n",
        "              eval_metric=['logloss'], eval_set=[(X_train, y_train), (X_valid, y_valid)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPs90GaJeQI7",
        "outputId": "05a57eac-8dad-408a-a7cb-6dafb8368c42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "오차 행렬\n",
            "[[35866    78]\n",
            " [ 7597   109]]\n",
            "정확도 : 0.8242, 정밀도 : 0.5829, 재현율 : 0.0141, F1 : 0.0276\n"
          ]
        }
      ],
      "source": [
        "y_pred = lgbm_model.predict(X_valid)\n",
        "get_clf_eval(y_valid, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLeYNYN4WzaE",
        "outputId": "50b948d7-8956-4ce4-f3c9-4b2a2cfe4f11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.90     35944\n",
            "           1       0.58      0.01      0.03      7706\n",
            "\n",
            "    accuracy                           0.82     43650\n",
            "   macro avg       0.70      0.51      0.47     43650\n",
            "weighted avg       0.78      0.82      0.75     43650\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lgbm_report = metrics.classification_report(y_valid, y_pred, zero_division=1)\n",
        "print(lgbm_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_x8ZtoPe5oi"
      },
      "source": [
        "-> label 불균형으로 delay를 거의 예측하지 못한다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yd8axqJc535"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPv5CK5XcgUp",
        "outputId": "e49846f8-8a4b-471a-8d17-430fb2ed2b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(174600, 13) (174600,)\n",
            "(43650, 13) (43650,)\n"
          ]
        }
      ],
      "source": [
        "X = train.iloc[:,:-1]\n",
        "y = train.iloc[:,-1]\n",
        "\n",
        "X_train, X_valid , y_train, y_valid = train_test_split(X, y, test_size = 0.2, stratify = y, random_state=42)\n",
        "\n",
        "numeric_cols = X_train.select_dtypes(exclude=['object']).columns\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
        "X_valid[numeric_cols] = scaler.transform(X_valid[numeric_cols])\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_valid.shape, y_valid.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4TVO2OMT5En",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "9d78f614-37ec-4492-cba6-8dc598f13bda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "lr_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = lr_model.predict(X_valid)\n",
        "get_clf_eval(y_valid, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3Imo1nXuRhd",
        "outputId": "e965845b-7d9e-4501-d463-d998971fda6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차 행렬\n",
            "[[35944     0]\n",
            " [ 7706     0]]\n",
            "정확도 : 0.8235, 정밀도 : 0.0000, 재현율 : 0.0000, F1 : 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_report = metrics.classification_report(y_valid, y_pred, zero_division=1)\n",
        "print(lr_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJdlFa1XwRyQ",
        "outputId": "aa33783d-6588-4941-c1d1-582cad63a469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     35944\n",
            "           1       1.00      0.00      0.00      7706\n",
            "\n",
            "    accuracy                           0.82     43650\n",
            "   macro avg       0.91      0.50      0.45     43650\n",
            "weighted avg       0.85      0.82      0.74     43650\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2AB33-HWMsh",
        "outputId": "aa68d28e-83c0-4083-e7f3-a811cf221d73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.90     35944\n",
            "           1       0.58      0.01      0.03      7706\n",
            "\n",
            "    accuracy                           0.82     43650\n",
            "   macro avg       0.70      0.51      0.47     43650\n",
            "weighted avg       0.78      0.82      0.75     43650\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lr_report = metrics.classification_report(y_valid, y_pred, zero_division=1)\n",
        "print(lr_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duqc8HoVXMrH"
      },
      "source": [
        "# label 불균형 해결 1 : Over Sampling(SMOTE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2GRIxR_dGfb",
        "outputId": "4c3c35b2-c743-4fb6-83c2-1e6ef4908b10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(157140, 13) (157140,)\n",
            "(17460, 13) (17460,)\n",
            "(43650, 13) (43650,)\n"
          ]
        }
      ],
      "source": [
        "X = train.iloc[:,:-1]\n",
        "y = train.iloc[:,-1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.1, random_state=42)\n",
        "\n",
        "numeric_cols = X_train.select_dtypes(exclude=['object']).columns\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
        "X_valid[numeric_cols] = scaler.transform(X_valid[numeric_cols])\n",
        "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_valid.shape, y_valid.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HSA9z83Xqdr"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_train_over, y_train_over = smote.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAlkKAF6oKFM",
        "outputId": "7c59dc81-154b-4565-a41d-7e3401d5f090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SMOTE 적용 전 학습용 피처/레이블 데이터 세트 :  (157140, 13) (157140,)\n",
            "SMOTE 적용 후 학습용 피처/레이블 데이터 세트 :  (258784, 13) (258784,)\n",
            "SMOTE 적용 후 레이블 분포 : \n",
            " Delay\n",
            "1    129392\n",
            "0    129392\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트 : ', X_train.shape, y_train.shape)\n",
        "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트 : ', X_train_over.shape, y_train_over.shape)\n",
        "print('SMOTE 적용 후 레이블 분포 : \\n', pd.Series(y_train_over).value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LogisticRegression"
      ],
      "metadata": {
        "id": "sy7a75dFdSMP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDOW9x3BXuJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5f11af4-72e8-4fb0-fc93-77d8652e2eb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        }
      ],
      "source": [
        "lr_model = LogisticRegression(random_state=42, max_iter=1000, verbose=True,\n",
        "                              penalty='l2', n_jobs=-1)\n",
        "\n",
        "lr_model.fit(X_train_over, y_train_over)\n",
        "y_pred = lr_model.predict(X_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5AgBXiJkI1k",
        "outputId": "27b37145-5325-478d-c3c9-91d879b946af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차 행렬\n",
            "[[8120 6265]\n",
            " [1189 1886]]\n",
            "정확도 : 0.5731, 정밀도 : 0.2314, 재현율 : 0.6133, F1 : 0.3360\n"
          ]
        }
      ],
      "source": [
        "get_clf_eval(y_valid, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08-v1uFQXyQh",
        "outputId": "a6e70b83-3a8d-40c7-8833-b4612ff483ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.56      0.69     14385\n",
            "           1       0.23      0.61      0.34      3075\n",
            "\n",
            "    accuracy                           0.57     17460\n",
            "   macro avg       0.55      0.59      0.51     17460\n",
            "weighted avg       0.76      0.57      0.62     17460\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lr_report_over = metrics.classification_report(y_valid, y_pred, zero_division=1)\n",
        "print(lr_report_over)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHAfezwqkNh7"
      },
      "source": [
        "-> 정확도는 하락했지만 재현율이 상당히 개선되었다"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBM"
      ],
      "metadata": {
        "id": "OoqdqCJi9U_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_over_model = LGBMClassifier(n_estimators=1000, num_leaves=64,\n",
        "                          n_jobs=-1, boost_from_average=False, force_col_wise=True)"
      ],
      "metadata": {
        "id": "WZsVN4Jg9Xy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_over_model.fit(X_train, y_train, callbacks=[early_stopping(stopping_rounds=50)],\n",
        "              eval_metric=['logloss'], eval_set=[(X_train, y_train), (X_valid, y_valid)])\n",
        "\n",
        "y_pred = lgbm_over_model.predict(X_test)\n",
        "get_clf_eval(y_test, y_pred)\n",
        "\n",
        "lgbm_under_report = metrics.classification_report(y_test, y_pred, zero_division=1)\n",
        "print(lgbm_under_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfS35AME9Xv3",
        "outputId": "3f10cad9-d16d-44aa-cf45-e0388c62c1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 27748, number of negative: 129392\n",
            "[LightGBM] [Info] Total Bins 1804\n",
            "[LightGBM] [Info] Number of data points in the train set: 157140, number of used features: 12\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[67]\ttraining's binary_logloss: 0.42386\tvalid_1's binary_logloss: 0.440567\n",
            "오차 행렬\n",
            "[[35894    50]\n",
            " [ 7630    76]]\n",
            "정확도 : 0.8241, 정밀도 : 0.6032, 재현율 : 0.0099, F1 : 0.0194\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     35944\n",
            "           1       0.60      0.01      0.02      7706\n",
            "\n",
            "    accuracy                           0.82     43650\n",
            "   macro avg       0.71      0.50      0.46     43650\n",
            "weighted avg       0.79      0.82      0.75     43650\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVW2TkEzdkH8"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "vnJfPgsXgLSz",
        "outputId": "63af9f0c-5a3d-4721-a359-ecc73c602299"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
              "             param_grid={&#x27;n_neighbors&#x27;: [5, 7, 9, 12]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
              "             param_grid={&#x27;n_neighbors&#x27;: [5, 7, 9, 12]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
              "             param_grid={'n_neighbors': [5, 7, 9, 12]})"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "knn = KNeighborsClassifier()\n",
        "\n",
        "parameters = {'n_neighbors' : [5, 7, 9, 12]}\n",
        "knn_grid = GridSearchCV(knn, param_grid=parameters, cv=3, refit=True)\n",
        "knn_grid.fit(X_train_over, y_train_over)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "Xy4R6xW9ZNU4",
        "outputId": "72e8e45f-7ad4-49d8-8732-cffd353ee755"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"           'split1_test_score', 'split2_test_score']]\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"params\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_test_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01774957594568814,\n        \"min\": 0.7299012412552623,\n        \"max\": 0.7704674908945975,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7520361879581575,\n          0.7299012412552623,\n          0.7704674908945975\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rank_test_score\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split0_test_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.023055876610250825,\n        \"min\": 0.7083733255435463,\n        \"max\": 0.7615907857947669,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7380440679380712,\n          0.7083733255435463,\n          0.7615907857947669\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split1_test_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01568291738767046,\n        \"min\": 0.7392932781087312,\n        \"max\": 0.7752136127948587,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.759188740858207,\n          0.7392932781087312,\n          0.7752136127948587\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split2_test_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014550706082721599,\n        \"min\": 0.7420371201135095,\n        \"max\": 0.774598074094167,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7588757550781943,\n          0.7420371201135095,\n          0.774598074094167\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1682dae2-37aa-424a-9211-3669337a17d4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'n_neighbors': 5}</td>\n",
              "      <td>0.770467</td>\n",
              "      <td>1</td>\n",
              "      <td>0.761591</td>\n",
              "      <td>0.775214</td>\n",
              "      <td>0.774598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'n_neighbors': 7}</td>\n",
              "      <td>0.752036</td>\n",
              "      <td>2</td>\n",
              "      <td>0.738044</td>\n",
              "      <td>0.759189</td>\n",
              "      <td>0.758876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'n_neighbors': 9}</td>\n",
              "      <td>0.738150</td>\n",
              "      <td>3</td>\n",
              "      <td>0.720840</td>\n",
              "      <td>0.746930</td>\n",
              "      <td>0.746680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'n_neighbors': 12}</td>\n",
              "      <td>0.729901</td>\n",
              "      <td>4</td>\n",
              "      <td>0.708373</td>\n",
              "      <td>0.739293</td>\n",
              "      <td>0.742037</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1682dae2-37aa-424a-9211-3669337a17d4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1682dae2-37aa-424a-9211-3669337a17d4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1682dae2-37aa-424a-9211-3669337a17d4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-64ca4dff-f155-409b-9136-cba9a800c196\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-64ca4dff-f155-409b-9136-cba9a800c196')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-64ca4dff-f155-409b-9136-cba9a800c196 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                params  mean_test_score  rank_test_score  split0_test_score  \\\n",
              "0   {'n_neighbors': 5}         0.770467                1           0.761591   \n",
              "1   {'n_neighbors': 7}         0.752036                2           0.738044   \n",
              "2   {'n_neighbors': 9}         0.738150                3           0.720840   \n",
              "3  {'n_neighbors': 12}         0.729901                4           0.708373   \n",
              "\n",
              "   split1_test_score  split2_test_score  \n",
              "0           0.775214           0.774598  \n",
              "1           0.759189           0.758876  \n",
              "2           0.746930           0.746680  \n",
              "3           0.739293           0.742037  "
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores_df = pd.DataFrame(knn_grid.cv_results_)\n",
        "scores_df[['params', 'mean_test_score',\n",
        "           'rank_test_score', 'split0_test_score',\n",
        "           'split1_test_score', 'split2_test_score']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtIzLDZDe3UO"
      },
      "outputs": [],
      "source": [
        "y_pred = knn_grid.predict(X_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw1H4Q4vgnqL",
        "outputId": "ef80adc2-16a6-4293-ae38-31c62cb23bf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "오차 행렬\n",
            "[[22728 13216]\n",
            " [ 4231  3475]]\n",
            "정확도 : 0.6003, 정밀도 : 0.2082, 재현율 : 0.4509, F1 : 0.2849\n"
          ]
        }
      ],
      "source": [
        "get_clf_eval(y_valid, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdCyZxGHfkKn",
        "outputId": "37177724-285c-4286-d870-709eaff361ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.63      0.72     35944\n",
            "           1       0.21      0.45      0.28      7706\n",
            "\n",
            "    accuracy                           0.60     43650\n",
            "   macro avg       0.53      0.54      0.50     43650\n",
            "weighted avg       0.73      0.60      0.65     43650\n",
            "\n"
          ]
        }
      ],
      "source": [
        "knn_report = metrics.classification_report(y_valid, y_pred, zero_division=1)\n",
        "print(knn_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfbYPVc7kXoj"
      },
      "source": [
        "-> over sampling을 했지만 여전히 Delay 데이터가 적어서 재현율이 크게 개선되지 않았다"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "i9fY9VrZdah_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_over_model = XGBClassifier(learning_rate=0.01,\n",
        "                          n_estimators=1000,\n",
        "                          max_depth=8,\n",
        "                          random_state=42)"
      ],
      "metadata": {
        "id": "XF15uo9kc179"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_over_model.fit(X_train_over, y_train_over, early_stopping_rounds=50,\n",
        "              eval_metric=['logloss'], eval_set=[(X_train, y_train), (X_valid, y_valid)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oi-G-Evuc-Vu",
        "outputId": "c8ac56c9-f7b9-47cc-cf40-dccaf19dd8b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-logloss:0.69155\tvalidation_1-logloss:0.69157\n",
            "[1]\tvalidation_0-logloss:0.68997\tvalidation_1-logloss:0.69003\n",
            "[2]\tvalidation_0-logloss:0.68843\tvalidation_1-logloss:0.68851\n",
            "[3]\tvalidation_0-logloss:0.68691\tvalidation_1-logloss:0.68702\n",
            "[4]\tvalidation_0-logloss:0.68531\tvalidation_1-logloss:0.68545\n",
            "[5]\tvalidation_0-logloss:0.68374\tvalidation_1-logloss:0.68390\n",
            "[6]\tvalidation_0-logloss:0.68228\tvalidation_1-logloss:0.68246\n",
            "[7]\tvalidation_0-logloss:0.68085\tvalidation_1-logloss:0.68107\n",
            "[8]\tvalidation_0-logloss:0.67942\tvalidation_1-logloss:0.67966\n",
            "[9]\tvalidation_0-logloss:0.67794\tvalidation_1-logloss:0.67821\n",
            "[10]\tvalidation_0-logloss:0.67648\tvalidation_1-logloss:0.67677\n",
            "[11]\tvalidation_0-logloss:0.67516\tvalidation_1-logloss:0.67548\n",
            "[12]\tvalidation_0-logloss:0.67374\tvalidation_1-logloss:0.67408\n",
            "[13]\tvalidation_0-logloss:0.67246\tvalidation_1-logloss:0.67284\n",
            "[14]\tvalidation_0-logloss:0.67117\tvalidation_1-logloss:0.67156\n",
            "[15]\tvalidation_0-logloss:0.66994\tvalidation_1-logloss:0.67036\n",
            "[16]\tvalidation_0-logloss:0.66869\tvalidation_1-logloss:0.66914\n",
            "[17]\tvalidation_0-logloss:0.66742\tvalidation_1-logloss:0.66789\n",
            "[18]\tvalidation_0-logloss:0.66612\tvalidation_1-logloss:0.66663\n",
            "[19]\tvalidation_0-logloss:0.66495\tvalidation_1-logloss:0.66549\n",
            "[20]\tvalidation_0-logloss:0.66377\tvalidation_1-logloss:0.66434\n",
            "[21]\tvalidation_0-logloss:0.66253\tvalidation_1-logloss:0.66312\n",
            "[22]\tvalidation_0-logloss:0.66131\tvalidation_1-logloss:0.66193\n",
            "[23]\tvalidation_0-logloss:0.66013\tvalidation_1-logloss:0.66078\n",
            "[24]\tvalidation_0-logloss:0.65902\tvalidation_1-logloss:0.65970\n",
            "[25]\tvalidation_0-logloss:0.65772\tvalidation_1-logloss:0.65842\n",
            "[26]\tvalidation_0-logloss:0.65642\tvalidation_1-logloss:0.65714\n",
            "[27]\tvalidation_0-logloss:0.65528\tvalidation_1-logloss:0.65603\n",
            "[28]\tvalidation_0-logloss:0.65402\tvalidation_1-logloss:0.65479\n",
            "[29]\tvalidation_0-logloss:0.65291\tvalidation_1-logloss:0.65370\n",
            "[30]\tvalidation_0-logloss:0.65179\tvalidation_1-logloss:0.65261\n",
            "[31]\tvalidation_0-logloss:0.65071\tvalidation_1-logloss:0.65155\n",
            "[32]\tvalidation_0-logloss:0.64949\tvalidation_1-logloss:0.65035\n",
            "[33]\tvalidation_0-logloss:0.64843\tvalidation_1-logloss:0.64930\n",
            "[34]\tvalidation_0-logloss:0.64724\tvalidation_1-logloss:0.64813\n",
            "[35]\tvalidation_0-logloss:0.64617\tvalidation_1-logloss:0.64710\n",
            "[36]\tvalidation_0-logloss:0.64502\tvalidation_1-logloss:0.64598\n",
            "[37]\tvalidation_0-logloss:0.64396\tvalidation_1-logloss:0.64495\n",
            "[38]\tvalidation_0-logloss:0.64303\tvalidation_1-logloss:0.64407\n",
            "[39]\tvalidation_0-logloss:0.64200\tvalidation_1-logloss:0.64307\n",
            "[40]\tvalidation_0-logloss:0.64098\tvalidation_1-logloss:0.64208\n",
            "[41]\tvalidation_0-logloss:0.64007\tvalidation_1-logloss:0.64120\n",
            "[42]\tvalidation_0-logloss:0.63907\tvalidation_1-logloss:0.64024\n",
            "[43]\tvalidation_0-logloss:0.63818\tvalidation_1-logloss:0.63938\n",
            "[44]\tvalidation_0-logloss:0.63731\tvalidation_1-logloss:0.63855\n",
            "[45]\tvalidation_0-logloss:0.63641\tvalidation_1-logloss:0.63767\n",
            "[46]\tvalidation_0-logloss:0.63572\tvalidation_1-logloss:0.63702\n",
            "[47]\tvalidation_0-logloss:0.63487\tvalidation_1-logloss:0.63622\n",
            "[48]\tvalidation_0-logloss:0.63395\tvalidation_1-logloss:0.63532\n",
            "[49]\tvalidation_0-logloss:0.63313\tvalidation_1-logloss:0.63455\n",
            "[50]\tvalidation_0-logloss:0.63242\tvalidation_1-logloss:0.63387\n",
            "[51]\tvalidation_0-logloss:0.63165\tvalidation_1-logloss:0.63315\n",
            "[52]\tvalidation_0-logloss:0.63067\tvalidation_1-logloss:0.63220\n",
            "[53]\tvalidation_0-logloss:0.62989\tvalidation_1-logloss:0.63146\n",
            "[54]\tvalidation_0-logloss:0.62901\tvalidation_1-logloss:0.63060\n",
            "[55]\tvalidation_0-logloss:0.62816\tvalidation_1-logloss:0.62978\n",
            "[56]\tvalidation_0-logloss:0.62740\tvalidation_1-logloss:0.62906\n",
            "[57]\tvalidation_0-logloss:0.62676\tvalidation_1-logloss:0.62845\n",
            "[58]\tvalidation_0-logloss:0.62594\tvalidation_1-logloss:0.62765\n",
            "[59]\tvalidation_0-logloss:0.62522\tvalidation_1-logloss:0.62698\n",
            "[60]\tvalidation_0-logloss:0.62459\tvalidation_1-logloss:0.62637\n",
            "[61]\tvalidation_0-logloss:0.62390\tvalidation_1-logloss:0.62573\n",
            "[62]\tvalidation_0-logloss:0.62317\tvalidation_1-logloss:0.62503\n",
            "[63]\tvalidation_0-logloss:0.62249\tvalidation_1-logloss:0.62438\n",
            "[64]\tvalidation_0-logloss:0.62189\tvalidation_1-logloss:0.62382\n",
            "[65]\tvalidation_0-logloss:0.62126\tvalidation_1-logloss:0.62322\n",
            "[66]\tvalidation_0-logloss:0.62061\tvalidation_1-logloss:0.62261\n",
            "[67]\tvalidation_0-logloss:0.61988\tvalidation_1-logloss:0.62192\n",
            "[68]\tvalidation_0-logloss:0.61905\tvalidation_1-logloss:0.62112\n",
            "[69]\tvalidation_0-logloss:0.61846\tvalidation_1-logloss:0.62057\n",
            "[70]\tvalidation_0-logloss:0.61790\tvalidation_1-logloss:0.62005\n",
            "[71]\tvalidation_0-logloss:0.61706\tvalidation_1-logloss:0.61925\n",
            "[72]\tvalidation_0-logloss:0.61636\tvalidation_1-logloss:0.61858\n",
            "[73]\tvalidation_0-logloss:0.61580\tvalidation_1-logloss:0.61804\n",
            "[74]\tvalidation_0-logloss:0.61521\tvalidation_1-logloss:0.61748\n",
            "[75]\tvalidation_0-logloss:0.61455\tvalidation_1-logloss:0.61686\n",
            "[76]\tvalidation_0-logloss:0.61405\tvalidation_1-logloss:0.61640\n",
            "[77]\tvalidation_0-logloss:0.61332\tvalidation_1-logloss:0.61569\n",
            "[78]\tvalidation_0-logloss:0.61279\tvalidation_1-logloss:0.61521\n",
            "[79]\tvalidation_0-logloss:0.61226\tvalidation_1-logloss:0.61471\n",
            "[80]\tvalidation_0-logloss:0.61156\tvalidation_1-logloss:0.61404\n",
            "[81]\tvalidation_0-logloss:0.61092\tvalidation_1-logloss:0.61343\n",
            "[82]\tvalidation_0-logloss:0.61045\tvalidation_1-logloss:0.61299\n",
            "[83]\tvalidation_0-logloss:0.60988\tvalidation_1-logloss:0.61246\n",
            "[84]\tvalidation_0-logloss:0.60915\tvalidation_1-logloss:0.61175\n",
            "[85]\tvalidation_0-logloss:0.60868\tvalidation_1-logloss:0.61131\n",
            "[86]\tvalidation_0-logloss:0.60830\tvalidation_1-logloss:0.61098\n",
            "[87]\tvalidation_0-logloss:0.60768\tvalidation_1-logloss:0.61038\n",
            "[88]\tvalidation_0-logloss:0.60717\tvalidation_1-logloss:0.60990\n",
            "[89]\tvalidation_0-logloss:0.60663\tvalidation_1-logloss:0.60940\n",
            "[90]\tvalidation_0-logloss:0.60603\tvalidation_1-logloss:0.60884\n",
            "[91]\tvalidation_0-logloss:0.60563\tvalidation_1-logloss:0.60847\n",
            "[92]\tvalidation_0-logloss:0.60492\tvalidation_1-logloss:0.60780\n",
            "[93]\tvalidation_0-logloss:0.60419\tvalidation_1-logloss:0.60711\n",
            "[94]\tvalidation_0-logloss:0.60363\tvalidation_1-logloss:0.60659\n",
            "[95]\tvalidation_0-logloss:0.60329\tvalidation_1-logloss:0.60629\n",
            "[96]\tvalidation_0-logloss:0.60260\tvalidation_1-logloss:0.60563\n",
            "[97]\tvalidation_0-logloss:0.60198\tvalidation_1-logloss:0.60504\n",
            "[98]\tvalidation_0-logloss:0.60142\tvalidation_1-logloss:0.60452\n",
            "[99]\tvalidation_0-logloss:0.60073\tvalidation_1-logloss:0.60385\n",
            "[100]\tvalidation_0-logloss:0.60042\tvalidation_1-logloss:0.60357\n",
            "[101]\tvalidation_0-logloss:0.59978\tvalidation_1-logloss:0.60295\n",
            "[102]\tvalidation_0-logloss:0.59928\tvalidation_1-logloss:0.60250\n",
            "[103]\tvalidation_0-logloss:0.59892\tvalidation_1-logloss:0.60217\n",
            "[104]\tvalidation_0-logloss:0.59838\tvalidation_1-logloss:0.60164\n",
            "[105]\tvalidation_0-logloss:0.59775\tvalidation_1-logloss:0.60105\n",
            "[106]\tvalidation_0-logloss:0.59736\tvalidation_1-logloss:0.60070\n",
            "[107]\tvalidation_0-logloss:0.59680\tvalidation_1-logloss:0.60016\n",
            "[108]\tvalidation_0-logloss:0.59627\tvalidation_1-logloss:0.59966\n",
            "[109]\tvalidation_0-logloss:0.59589\tvalidation_1-logloss:0.59932\n",
            "[110]\tvalidation_0-logloss:0.59539\tvalidation_1-logloss:0.59886\n",
            "[111]\tvalidation_0-logloss:0.59486\tvalidation_1-logloss:0.59835\n",
            "[112]\tvalidation_0-logloss:0.59458\tvalidation_1-logloss:0.59810\n",
            "[113]\tvalidation_0-logloss:0.59403\tvalidation_1-logloss:0.59757\n",
            "[114]\tvalidation_0-logloss:0.59362\tvalidation_1-logloss:0.59719\n",
            "[115]\tvalidation_0-logloss:0.59329\tvalidation_1-logloss:0.59689\n",
            "[116]\tvalidation_0-logloss:0.59289\tvalidation_1-logloss:0.59652\n",
            "[117]\tvalidation_0-logloss:0.59252\tvalidation_1-logloss:0.59618\n",
            "[118]\tvalidation_0-logloss:0.59199\tvalidation_1-logloss:0.59569\n",
            "[119]\tvalidation_0-logloss:0.59168\tvalidation_1-logloss:0.59541\n",
            "[120]\tvalidation_0-logloss:0.59118\tvalidation_1-logloss:0.59493\n",
            "[121]\tvalidation_0-logloss:0.59072\tvalidation_1-logloss:0.59450\n",
            "[122]\tvalidation_0-logloss:0.59041\tvalidation_1-logloss:0.59421\n",
            "[123]\tvalidation_0-logloss:0.58995\tvalidation_1-logloss:0.59379\n",
            "[124]\tvalidation_0-logloss:0.58956\tvalidation_1-logloss:0.59342\n",
            "[125]\tvalidation_0-logloss:0.58930\tvalidation_1-logloss:0.59320\n",
            "[126]\tvalidation_0-logloss:0.58893\tvalidation_1-logloss:0.59286\n",
            "[127]\tvalidation_0-logloss:0.58854\tvalidation_1-logloss:0.59248\n",
            "[128]\tvalidation_0-logloss:0.58818\tvalidation_1-logloss:0.59214\n",
            "[129]\tvalidation_0-logloss:0.58779\tvalidation_1-logloss:0.59178\n",
            "[130]\tvalidation_0-logloss:0.58748\tvalidation_1-logloss:0.59151\n",
            "[131]\tvalidation_0-logloss:0.58704\tvalidation_1-logloss:0.59110\n",
            "[132]\tvalidation_0-logloss:0.58672\tvalidation_1-logloss:0.59082\n",
            "[133]\tvalidation_0-logloss:0.58632\tvalidation_1-logloss:0.59044\n",
            "[134]\tvalidation_0-logloss:0.58604\tvalidation_1-logloss:0.59020\n",
            "[135]\tvalidation_0-logloss:0.58564\tvalidation_1-logloss:0.58982\n",
            "[136]\tvalidation_0-logloss:0.58528\tvalidation_1-logloss:0.58950\n",
            "[137]\tvalidation_0-logloss:0.58494\tvalidation_1-logloss:0.58918\n",
            "[138]\tvalidation_0-logloss:0.58457\tvalidation_1-logloss:0.58884\n",
            "[139]\tvalidation_0-logloss:0.58400\tvalidation_1-logloss:0.58828\n",
            "[140]\tvalidation_0-logloss:0.58378\tvalidation_1-logloss:0.58810\n",
            "[141]\tvalidation_0-logloss:0.58343\tvalidation_1-logloss:0.58778\n",
            "[142]\tvalidation_0-logloss:0.58313\tvalidation_1-logloss:0.58751\n",
            "[143]\tvalidation_0-logloss:0.58274\tvalidation_1-logloss:0.58715\n",
            "[144]\tvalidation_0-logloss:0.58240\tvalidation_1-logloss:0.58684\n",
            "[145]\tvalidation_0-logloss:0.58202\tvalidation_1-logloss:0.58649\n",
            "[146]\tvalidation_0-logloss:0.58180\tvalidation_1-logloss:0.58629\n",
            "[147]\tvalidation_0-logloss:0.58147\tvalidation_1-logloss:0.58599\n",
            "[148]\tvalidation_0-logloss:0.58104\tvalidation_1-logloss:0.58559\n",
            "[149]\tvalidation_0-logloss:0.58083\tvalidation_1-logloss:0.58540\n",
            "[150]\tvalidation_0-logloss:0.58051\tvalidation_1-logloss:0.58510\n",
            "[151]\tvalidation_0-logloss:0.58030\tvalidation_1-logloss:0.58493\n",
            "[152]\tvalidation_0-logloss:0.57984\tvalidation_1-logloss:0.58448\n",
            "[153]\tvalidation_0-logloss:0.57944\tvalidation_1-logloss:0.58411\n",
            "[154]\tvalidation_0-logloss:0.57903\tvalidation_1-logloss:0.58373\n",
            "[155]\tvalidation_0-logloss:0.57858\tvalidation_1-logloss:0.58330\n",
            "[156]\tvalidation_0-logloss:0.57815\tvalidation_1-logloss:0.58290\n",
            "[157]\tvalidation_0-logloss:0.57795\tvalidation_1-logloss:0.58273\n",
            "[158]\tvalidation_0-logloss:0.57749\tvalidation_1-logloss:0.58228\n",
            "[159]\tvalidation_0-logloss:0.57710\tvalidation_1-logloss:0.58192\n",
            "[160]\tvalidation_0-logloss:0.57690\tvalidation_1-logloss:0.58175\n",
            "[161]\tvalidation_0-logloss:0.57657\tvalidation_1-logloss:0.58146\n",
            "[162]\tvalidation_0-logloss:0.57633\tvalidation_1-logloss:0.58124\n",
            "[163]\tvalidation_0-logloss:0.57601\tvalidation_1-logloss:0.58095\n",
            "[164]\tvalidation_0-logloss:0.57566\tvalidation_1-logloss:0.58062\n",
            "[165]\tvalidation_0-logloss:0.57528\tvalidation_1-logloss:0.58027\n",
            "[166]\tvalidation_0-logloss:0.57509\tvalidation_1-logloss:0.58011\n",
            "[167]\tvalidation_0-logloss:0.57478\tvalidation_1-logloss:0.57982\n",
            "[168]\tvalidation_0-logloss:0.57428\tvalidation_1-logloss:0.57935\n",
            "[169]\tvalidation_0-logloss:0.57403\tvalidation_1-logloss:0.57913\n",
            "[170]\tvalidation_0-logloss:0.57366\tvalidation_1-logloss:0.57879\n",
            "[171]\tvalidation_0-logloss:0.57315\tvalidation_1-logloss:0.57830\n",
            "[172]\tvalidation_0-logloss:0.57285\tvalidation_1-logloss:0.57803\n",
            "[173]\tvalidation_0-logloss:0.57258\tvalidation_1-logloss:0.57778\n",
            "[174]\tvalidation_0-logloss:0.57219\tvalidation_1-logloss:0.57742\n",
            "[175]\tvalidation_0-logloss:0.57199\tvalidation_1-logloss:0.57723\n",
            "[176]\tvalidation_0-logloss:0.57162\tvalidation_1-logloss:0.57688\n",
            "[177]\tvalidation_0-logloss:0.57120\tvalidation_1-logloss:0.57648\n",
            "[178]\tvalidation_0-logloss:0.57092\tvalidation_1-logloss:0.57623\n",
            "[179]\tvalidation_0-logloss:0.57057\tvalidation_1-logloss:0.57589\n",
            "[180]\tvalidation_0-logloss:0.57026\tvalidation_1-logloss:0.57561\n",
            "[181]\tvalidation_0-logloss:0.56998\tvalidation_1-logloss:0.57535\n",
            "[182]\tvalidation_0-logloss:0.56969\tvalidation_1-logloss:0.57508\n",
            "[183]\tvalidation_0-logloss:0.56943\tvalidation_1-logloss:0.57485\n",
            "[184]\tvalidation_0-logloss:0.56913\tvalidation_1-logloss:0.57457\n",
            "[185]\tvalidation_0-logloss:0.56882\tvalidation_1-logloss:0.57428\n",
            "[186]\tvalidation_0-logloss:0.56848\tvalidation_1-logloss:0.57396\n",
            "[187]\tvalidation_0-logloss:0.56814\tvalidation_1-logloss:0.57366\n",
            "[188]\tvalidation_0-logloss:0.56795\tvalidation_1-logloss:0.57349\n",
            "[189]\tvalidation_0-logloss:0.56770\tvalidation_1-logloss:0.57325\n",
            "[190]\tvalidation_0-logloss:0.56751\tvalidation_1-logloss:0.57309\n",
            "[191]\tvalidation_0-logloss:0.56712\tvalidation_1-logloss:0.57271\n",
            "[192]\tvalidation_0-logloss:0.56683\tvalidation_1-logloss:0.57244\n",
            "[193]\tvalidation_0-logloss:0.56653\tvalidation_1-logloss:0.57218\n",
            "[194]\tvalidation_0-logloss:0.56635\tvalidation_1-logloss:0.57201\n",
            "[195]\tvalidation_0-logloss:0.56601\tvalidation_1-logloss:0.57169\n",
            "[196]\tvalidation_0-logloss:0.56562\tvalidation_1-logloss:0.57131\n",
            "[197]\tvalidation_0-logloss:0.56520\tvalidation_1-logloss:0.57092\n",
            "[198]\tvalidation_0-logloss:0.56482\tvalidation_1-logloss:0.57054\n",
            "[199]\tvalidation_0-logloss:0.56464\tvalidation_1-logloss:0.57038\n",
            "[200]\tvalidation_0-logloss:0.56439\tvalidation_1-logloss:0.57016\n",
            "[201]\tvalidation_0-logloss:0.56405\tvalidation_1-logloss:0.56984\n",
            "[202]\tvalidation_0-logloss:0.56364\tvalidation_1-logloss:0.56946\n",
            "[203]\tvalidation_0-logloss:0.56346\tvalidation_1-logloss:0.56930\n",
            "[204]\tvalidation_0-logloss:0.56309\tvalidation_1-logloss:0.56893\n",
            "[205]\tvalidation_0-logloss:0.56276\tvalidation_1-logloss:0.56863\n",
            "[206]\tvalidation_0-logloss:0.56238\tvalidation_1-logloss:0.56826\n",
            "[207]\tvalidation_0-logloss:0.56198\tvalidation_1-logloss:0.56789\n",
            "[208]\tvalidation_0-logloss:0.56174\tvalidation_1-logloss:0.56766\n",
            "[209]\tvalidation_0-logloss:0.56157\tvalidation_1-logloss:0.56751\n",
            "[210]\tvalidation_0-logloss:0.56120\tvalidation_1-logloss:0.56715\n",
            "[211]\tvalidation_0-logloss:0.56095\tvalidation_1-logloss:0.56692\n",
            "[212]\tvalidation_0-logloss:0.56056\tvalidation_1-logloss:0.56656\n",
            "[213]\tvalidation_0-logloss:0.56019\tvalidation_1-logloss:0.56620\n",
            "[214]\tvalidation_0-logloss:0.56000\tvalidation_1-logloss:0.56604\n",
            "[215]\tvalidation_0-logloss:0.55961\tvalidation_1-logloss:0.56568\n",
            "[216]\tvalidation_0-logloss:0.55944\tvalidation_1-logloss:0.56554\n",
            "[217]\tvalidation_0-logloss:0.55919\tvalidation_1-logloss:0.56531\n",
            "[218]\tvalidation_0-logloss:0.55882\tvalidation_1-logloss:0.56496\n",
            "[219]\tvalidation_0-logloss:0.55846\tvalidation_1-logloss:0.56460\n",
            "[220]\tvalidation_0-logloss:0.55830\tvalidation_1-logloss:0.56446\n",
            "[221]\tvalidation_0-logloss:0.55803\tvalidation_1-logloss:0.56422\n",
            "[222]\tvalidation_0-logloss:0.55768\tvalidation_1-logloss:0.56387\n",
            "[223]\tvalidation_0-logloss:0.55731\tvalidation_1-logloss:0.56353\n",
            "[224]\tvalidation_0-logloss:0.55709\tvalidation_1-logloss:0.56334\n",
            "[225]\tvalidation_0-logloss:0.55693\tvalidation_1-logloss:0.56321\n",
            "[226]\tvalidation_0-logloss:0.55659\tvalidation_1-logloss:0.56287\n",
            "[227]\tvalidation_0-logloss:0.55622\tvalidation_1-logloss:0.56252\n",
            "[228]\tvalidation_0-logloss:0.55595\tvalidation_1-logloss:0.56228\n",
            "[229]\tvalidation_0-logloss:0.55561\tvalidation_1-logloss:0.56195\n",
            "[230]\tvalidation_0-logloss:0.55525\tvalidation_1-logloss:0.56161\n",
            "[231]\tvalidation_0-logloss:0.55503\tvalidation_1-logloss:0.56141\n",
            "[232]\tvalidation_0-logloss:0.55487\tvalidation_1-logloss:0.56128\n",
            "[233]\tvalidation_0-logloss:0.55456\tvalidation_1-logloss:0.56099\n",
            "[234]\tvalidation_0-logloss:0.55420\tvalidation_1-logloss:0.56065\n",
            "[235]\tvalidation_0-logloss:0.55388\tvalidation_1-logloss:0.56033\n",
            "[236]\tvalidation_0-logloss:0.55369\tvalidation_1-logloss:0.56017\n",
            "[237]\tvalidation_0-logloss:0.55354\tvalidation_1-logloss:0.56004\n",
            "[238]\tvalidation_0-logloss:0.55319\tvalidation_1-logloss:0.55972\n",
            "[239]\tvalidation_0-logloss:0.55286\tvalidation_1-logloss:0.55939\n",
            "[240]\tvalidation_0-logloss:0.55267\tvalidation_1-logloss:0.55924\n",
            "[241]\tvalidation_0-logloss:0.55233\tvalidation_1-logloss:0.55892\n",
            "[242]\tvalidation_0-logloss:0.55214\tvalidation_1-logloss:0.55874\n",
            "[243]\tvalidation_0-logloss:0.55199\tvalidation_1-logloss:0.55861\n",
            "[244]\tvalidation_0-logloss:0.55167\tvalidation_1-logloss:0.55830\n",
            "[245]\tvalidation_0-logloss:0.55150\tvalidation_1-logloss:0.55815\n",
            "[246]\tvalidation_0-logloss:0.55116\tvalidation_1-logloss:0.55784\n",
            "[247]\tvalidation_0-logloss:0.55084\tvalidation_1-logloss:0.55753\n",
            "[248]\tvalidation_0-logloss:0.55070\tvalidation_1-logloss:0.55741\n",
            "[249]\tvalidation_0-logloss:0.55050\tvalidation_1-logloss:0.55724\n",
            "[250]\tvalidation_0-logloss:0.55029\tvalidation_1-logloss:0.55705\n",
            "[251]\tvalidation_0-logloss:0.54997\tvalidation_1-logloss:0.55674\n",
            "[252]\tvalidation_0-logloss:0.54975\tvalidation_1-logloss:0.55656\n",
            "[253]\tvalidation_0-logloss:0.54961\tvalidation_1-logloss:0.55644\n",
            "[254]\tvalidation_0-logloss:0.54941\tvalidation_1-logloss:0.55625\n",
            "[255]\tvalidation_0-logloss:0.54908\tvalidation_1-logloss:0.55594\n",
            "[256]\tvalidation_0-logloss:0.54877\tvalidation_1-logloss:0.55565\n",
            "[257]\tvalidation_0-logloss:0.54837\tvalidation_1-logloss:0.55528\n",
            "[258]\tvalidation_0-logloss:0.54817\tvalidation_1-logloss:0.55510\n",
            "[259]\tvalidation_0-logloss:0.54803\tvalidation_1-logloss:0.55498\n",
            "[260]\tvalidation_0-logloss:0.54783\tvalidation_1-logloss:0.55479\n",
            "[261]\tvalidation_0-logloss:0.54753\tvalidation_1-logloss:0.55450\n",
            "[262]\tvalidation_0-logloss:0.54729\tvalidation_1-logloss:0.55427\n",
            "[263]\tvalidation_0-logloss:0.54715\tvalidation_1-logloss:0.55416\n",
            "[264]\tvalidation_0-logloss:0.54683\tvalidation_1-logloss:0.55386\n",
            "[265]\tvalidation_0-logloss:0.54661\tvalidation_1-logloss:0.55367\n",
            "[266]\tvalidation_0-logloss:0.54631\tvalidation_1-logloss:0.55338\n",
            "[267]\tvalidation_0-logloss:0.54617\tvalidation_1-logloss:0.55326\n",
            "[268]\tvalidation_0-logloss:0.54585\tvalidation_1-logloss:0.55296\n",
            "[269]\tvalidation_0-logloss:0.54561\tvalidation_1-logloss:0.55274\n",
            "[270]\tvalidation_0-logloss:0.54548\tvalidation_1-logloss:0.55263\n",
            "[271]\tvalidation_0-logloss:0.54530\tvalidation_1-logloss:0.55248\n",
            "[272]\tvalidation_0-logloss:0.54501\tvalidation_1-logloss:0.55220\n",
            "[273]\tvalidation_0-logloss:0.54468\tvalidation_1-logloss:0.55188\n",
            "[274]\tvalidation_0-logloss:0.54454\tvalidation_1-logloss:0.55176\n",
            "[275]\tvalidation_0-logloss:0.54423\tvalidation_1-logloss:0.55147\n",
            "[276]\tvalidation_0-logloss:0.54410\tvalidation_1-logloss:0.55136\n",
            "[277]\tvalidation_0-logloss:0.54392\tvalidation_1-logloss:0.55119\n",
            "[278]\tvalidation_0-logloss:0.54376\tvalidation_1-logloss:0.55105\n",
            "[279]\tvalidation_0-logloss:0.54345\tvalidation_1-logloss:0.55077\n",
            "[280]\tvalidation_0-logloss:0.54317\tvalidation_1-logloss:0.55049\n",
            "[281]\tvalidation_0-logloss:0.54301\tvalidation_1-logloss:0.55035\n",
            "[282]\tvalidation_0-logloss:0.54269\tvalidation_1-logloss:0.55005\n",
            "[283]\tvalidation_0-logloss:0.54253\tvalidation_1-logloss:0.54991\n",
            "[284]\tvalidation_0-logloss:0.54234\tvalidation_1-logloss:0.54974\n",
            "[285]\tvalidation_0-logloss:0.54222\tvalidation_1-logloss:0.54964\n",
            "[286]\tvalidation_0-logloss:0.54202\tvalidation_1-logloss:0.54947\n",
            "[287]\tvalidation_0-logloss:0.54171\tvalidation_1-logloss:0.54917\n",
            "[288]\tvalidation_0-logloss:0.54143\tvalidation_1-logloss:0.54889\n",
            "[289]\tvalidation_0-logloss:0.54129\tvalidation_1-logloss:0.54877\n",
            "[290]\tvalidation_0-logloss:0.54114\tvalidation_1-logloss:0.54864\n",
            "[291]\tvalidation_0-logloss:0.54101\tvalidation_1-logloss:0.54853\n",
            "[292]\tvalidation_0-logloss:0.54071\tvalidation_1-logloss:0.54824\n",
            "[293]\tvalidation_0-logloss:0.54042\tvalidation_1-logloss:0.54797\n",
            "[294]\tvalidation_0-logloss:0.54024\tvalidation_1-logloss:0.54781\n",
            "[295]\tvalidation_0-logloss:0.53996\tvalidation_1-logloss:0.54754\n",
            "[296]\tvalidation_0-logloss:0.53984\tvalidation_1-logloss:0.54745\n",
            "[297]\tvalidation_0-logloss:0.53969\tvalidation_1-logloss:0.54731\n",
            "[298]\tvalidation_0-logloss:0.53949\tvalidation_1-logloss:0.54713\n",
            "[299]\tvalidation_0-logloss:0.53919\tvalidation_1-logloss:0.54684\n",
            "[300]\tvalidation_0-logloss:0.53901\tvalidation_1-logloss:0.54669\n",
            "[301]\tvalidation_0-logloss:0.53849\tvalidation_1-logloss:0.54620\n",
            "[302]\tvalidation_0-logloss:0.53836\tvalidation_1-logloss:0.54609\n",
            "[303]\tvalidation_0-logloss:0.53823\tvalidation_1-logloss:0.54597\n",
            "[304]\tvalidation_0-logloss:0.53811\tvalidation_1-logloss:0.54587\n",
            "[305]\tvalidation_0-logloss:0.53785\tvalidation_1-logloss:0.54562\n",
            "[306]\tvalidation_0-logloss:0.53756\tvalidation_1-logloss:0.54534\n",
            "[307]\tvalidation_0-logloss:0.53728\tvalidation_1-logloss:0.54508\n",
            "[308]\tvalidation_0-logloss:0.53711\tvalidation_1-logloss:0.54493\n",
            "[309]\tvalidation_0-logloss:0.53696\tvalidation_1-logloss:0.54480\n",
            "[310]\tvalidation_0-logloss:0.53668\tvalidation_1-logloss:0.54453\n",
            "[311]\tvalidation_0-logloss:0.53656\tvalidation_1-logloss:0.54444\n",
            "[312]\tvalidation_0-logloss:0.53644\tvalidation_1-logloss:0.54432\n",
            "[313]\tvalidation_0-logloss:0.53593\tvalidation_1-logloss:0.54385\n",
            "[314]\tvalidation_0-logloss:0.53567\tvalidation_1-logloss:0.54360\n",
            "[315]\tvalidation_0-logloss:0.53550\tvalidation_1-logloss:0.54345\n",
            "[316]\tvalidation_0-logloss:0.53522\tvalidation_1-logloss:0.54318\n",
            "[317]\tvalidation_0-logloss:0.53495\tvalidation_1-logloss:0.54293\n",
            "[318]\tvalidation_0-logloss:0.53481\tvalidation_1-logloss:0.54281\n",
            "[319]\tvalidation_0-logloss:0.53470\tvalidation_1-logloss:0.54272\n",
            "[320]\tvalidation_0-logloss:0.53445\tvalidation_1-logloss:0.54248\n",
            "[321]\tvalidation_0-logloss:0.53427\tvalidation_1-logloss:0.54232\n",
            "[322]\tvalidation_0-logloss:0.53414\tvalidation_1-logloss:0.54221\n",
            "[323]\tvalidation_0-logloss:0.53398\tvalidation_1-logloss:0.54207\n",
            "[324]\tvalidation_0-logloss:0.53349\tvalidation_1-logloss:0.54160\n",
            "[325]\tvalidation_0-logloss:0.53322\tvalidation_1-logloss:0.54135\n",
            "[326]\tvalidation_0-logloss:0.53299\tvalidation_1-logloss:0.54113\n",
            "[327]\tvalidation_0-logloss:0.53288\tvalidation_1-logloss:0.54104\n",
            "[328]\tvalidation_0-logloss:0.53254\tvalidation_1-logloss:0.54071\n",
            "[329]\tvalidation_0-logloss:0.53236\tvalidation_1-logloss:0.54056\n",
            "[330]\tvalidation_0-logloss:0.53221\tvalidation_1-logloss:0.54042\n",
            "[331]\tvalidation_0-logloss:0.53198\tvalidation_1-logloss:0.54021\n",
            "[332]\tvalidation_0-logloss:0.53186\tvalidation_1-logloss:0.54011\n",
            "[333]\tvalidation_0-logloss:0.53159\tvalidation_1-logloss:0.53986\n",
            "[334]\tvalidation_0-logloss:0.53135\tvalidation_1-logloss:0.53962\n",
            "[335]\tvalidation_0-logloss:0.53124\tvalidation_1-logloss:0.53953\n",
            "[336]\tvalidation_0-logloss:0.53102\tvalidation_1-logloss:0.53933\n",
            "[337]\tvalidation_0-logloss:0.53068\tvalidation_1-logloss:0.53900\n",
            "[338]\tvalidation_0-logloss:0.53051\tvalidation_1-logloss:0.53885\n",
            "[339]\tvalidation_0-logloss:0.53026\tvalidation_1-logloss:0.53860\n",
            "[340]\tvalidation_0-logloss:0.53010\tvalidation_1-logloss:0.53847\n",
            "[341]\tvalidation_0-logloss:0.52998\tvalidation_1-logloss:0.53836\n",
            "[342]\tvalidation_0-logloss:0.52988\tvalidation_1-logloss:0.53828\n",
            "[343]\tvalidation_0-logloss:0.52964\tvalidation_1-logloss:0.53805\n",
            "[344]\tvalidation_0-logloss:0.52938\tvalidation_1-logloss:0.53781\n",
            "[345]\tvalidation_0-logloss:0.52905\tvalidation_1-logloss:0.53749\n",
            "[346]\tvalidation_0-logloss:0.52889\tvalidation_1-logloss:0.53735\n",
            "[347]\tvalidation_0-logloss:0.52879\tvalidation_1-logloss:0.53726\n",
            "[348]\tvalidation_0-logloss:0.52854\tvalidation_1-logloss:0.53703\n",
            "[349]\tvalidation_0-logloss:0.52833\tvalidation_1-logloss:0.53683\n",
            "[350]\tvalidation_0-logloss:0.52817\tvalidation_1-logloss:0.53670\n",
            "[351]\tvalidation_0-logloss:0.52806\tvalidation_1-logloss:0.53660\n",
            "[352]\tvalidation_0-logloss:0.52774\tvalidation_1-logloss:0.53629\n",
            "[353]\tvalidation_0-logloss:0.52757\tvalidation_1-logloss:0.53615\n",
            "[354]\tvalidation_0-logloss:0.52748\tvalidation_1-logloss:0.53607\n",
            "[355]\tvalidation_0-logloss:0.52725\tvalidation_1-logloss:0.53585\n",
            "[356]\tvalidation_0-logloss:0.52700\tvalidation_1-logloss:0.53562\n",
            "[357]\tvalidation_0-logloss:0.52685\tvalidation_1-logloss:0.53549\n",
            "[358]\tvalidation_0-logloss:0.52654\tvalidation_1-logloss:0.53519\n",
            "[359]\tvalidation_0-logloss:0.52642\tvalidation_1-logloss:0.53509\n",
            "[360]\tvalidation_0-logloss:0.52618\tvalidation_1-logloss:0.53486\n",
            "[361]\tvalidation_0-logloss:0.52608\tvalidation_1-logloss:0.53478\n",
            "[362]\tvalidation_0-logloss:0.52567\tvalidation_1-logloss:0.53440\n",
            "[363]\tvalidation_0-logloss:0.52523\tvalidation_1-logloss:0.53398\n",
            "[364]\tvalidation_0-logloss:0.52508\tvalidation_1-logloss:0.53385\n",
            "[365]\tvalidation_0-logloss:0.52464\tvalidation_1-logloss:0.53344\n",
            "[366]\tvalidation_0-logloss:0.52434\tvalidation_1-logloss:0.53315\n",
            "[367]\tvalidation_0-logloss:0.52423\tvalidation_1-logloss:0.53306\n",
            "[368]\tvalidation_0-logloss:0.52400\tvalidation_1-logloss:0.53284\n",
            "[369]\tvalidation_0-logloss:0.52377\tvalidation_1-logloss:0.53262\n",
            "[370]\tvalidation_0-logloss:0.52362\tvalidation_1-logloss:0.53249\n",
            "[371]\tvalidation_0-logloss:0.52353\tvalidation_1-logloss:0.53241\n",
            "[372]\tvalidation_0-logloss:0.52333\tvalidation_1-logloss:0.53222\n",
            "[373]\tvalidation_0-logloss:0.52318\tvalidation_1-logloss:0.53210\n",
            "[374]\tvalidation_0-logloss:0.52295\tvalidation_1-logloss:0.53188\n",
            "[375]\tvalidation_0-logloss:0.52266\tvalidation_1-logloss:0.53160\n",
            "[376]\tvalidation_0-logloss:0.52246\tvalidation_1-logloss:0.53142\n",
            "[377]\tvalidation_0-logloss:0.52235\tvalidation_1-logloss:0.53133\n",
            "[378]\tvalidation_0-logloss:0.52213\tvalidation_1-logloss:0.53112\n",
            "[379]\tvalidation_0-logloss:0.52190\tvalidation_1-logloss:0.53091\n",
            "[380]\tvalidation_0-logloss:0.52161\tvalidation_1-logloss:0.53063\n",
            "[381]\tvalidation_0-logloss:0.52147\tvalidation_1-logloss:0.53051\n",
            "[382]\tvalidation_0-logloss:0.52108\tvalidation_1-logloss:0.53015\n",
            "[383]\tvalidation_0-logloss:0.52086\tvalidation_1-logloss:0.52995\n",
            "[384]\tvalidation_0-logloss:0.52073\tvalidation_1-logloss:0.52984\n",
            "[385]\tvalidation_0-logloss:0.52060\tvalidation_1-logloss:0.52973\n",
            "[386]\tvalidation_0-logloss:0.52051\tvalidation_1-logloss:0.52966\n",
            "[387]\tvalidation_0-logloss:0.52029\tvalidation_1-logloss:0.52946\n",
            "[388]\tvalidation_0-logloss:0.52007\tvalidation_1-logloss:0.52925\n",
            "[389]\tvalidation_0-logloss:0.51986\tvalidation_1-logloss:0.52905\n",
            "[390]\tvalidation_0-logloss:0.51947\tvalidation_1-logloss:0.52870\n",
            "[391]\tvalidation_0-logloss:0.51926\tvalidation_1-logloss:0.52850\n",
            "[392]\tvalidation_0-logloss:0.51898\tvalidation_1-logloss:0.52823\n",
            "[393]\tvalidation_0-logloss:0.51886\tvalidation_1-logloss:0.52813\n",
            "[394]\tvalidation_0-logloss:0.51871\tvalidation_1-logloss:0.52800\n",
            "[395]\tvalidation_0-logloss:0.51850\tvalidation_1-logloss:0.52780\n",
            "[396]\tvalidation_0-logloss:0.51840\tvalidation_1-logloss:0.52772\n",
            "[397]\tvalidation_0-logloss:0.51819\tvalidation_1-logloss:0.52752\n",
            "[398]\tvalidation_0-logloss:0.51779\tvalidation_1-logloss:0.52715\n",
            "[399]\tvalidation_0-logloss:0.51743\tvalidation_1-logloss:0.52681\n",
            "[400]\tvalidation_0-logloss:0.51719\tvalidation_1-logloss:0.52659\n",
            "[401]\tvalidation_0-logloss:0.51701\tvalidation_1-logloss:0.52643\n",
            "[402]\tvalidation_0-logloss:0.51673\tvalidation_1-logloss:0.52617\n",
            "[403]\tvalidation_0-logloss:0.51653\tvalidation_1-logloss:0.52597\n",
            "[404]\tvalidation_0-logloss:0.51641\tvalidation_1-logloss:0.52587\n",
            "[405]\tvalidation_0-logloss:0.51627\tvalidation_1-logloss:0.52575\n",
            "[406]\tvalidation_0-logloss:0.51609\tvalidation_1-logloss:0.52559\n",
            "[407]\tvalidation_0-logloss:0.51588\tvalidation_1-logloss:0.52540\n",
            "[408]\tvalidation_0-logloss:0.51568\tvalidation_1-logloss:0.52521\n",
            "[409]\tvalidation_0-logloss:0.51559\tvalidation_1-logloss:0.52514\n",
            "[410]\tvalidation_0-logloss:0.51532\tvalidation_1-logloss:0.52488\n",
            "[411]\tvalidation_0-logloss:0.51520\tvalidation_1-logloss:0.52478\n",
            "[412]\tvalidation_0-logloss:0.51506\tvalidation_1-logloss:0.52466\n",
            "[413]\tvalidation_0-logloss:0.51489\tvalidation_1-logloss:0.52450\n",
            "[414]\tvalidation_0-logloss:0.51462\tvalidation_1-logloss:0.52425\n",
            "[415]\tvalidation_0-logloss:0.51443\tvalidation_1-logloss:0.52407\n",
            "[416]\tvalidation_0-logloss:0.51430\tvalidation_1-logloss:0.52396\n",
            "[417]\tvalidation_0-logloss:0.51422\tvalidation_1-logloss:0.52390\n",
            "[418]\tvalidation_0-logloss:0.51402\tvalidation_1-logloss:0.52371\n",
            "[419]\tvalidation_0-logloss:0.51367\tvalidation_1-logloss:0.52339\n",
            "[420]\tvalidation_0-logloss:0.51345\tvalidation_1-logloss:0.52319\n",
            "[421]\tvalidation_0-logloss:0.51325\tvalidation_1-logloss:0.52300\n",
            "[422]\tvalidation_0-logloss:0.51300\tvalidation_1-logloss:0.52276\n",
            "[423]\tvalidation_0-logloss:0.51287\tvalidation_1-logloss:0.52265\n",
            "[424]\tvalidation_0-logloss:0.51278\tvalidation_1-logloss:0.52258\n",
            "[425]\tvalidation_0-logloss:0.51258\tvalidation_1-logloss:0.52240\n",
            "[426]\tvalidation_0-logloss:0.51247\tvalidation_1-logloss:0.52231\n",
            "[427]\tvalidation_0-logloss:0.51228\tvalidation_1-logloss:0.52213\n",
            "[428]\tvalidation_0-logloss:0.51215\tvalidation_1-logloss:0.52201\n",
            "[429]\tvalidation_0-logloss:0.51194\tvalidation_1-logloss:0.52183\n",
            "[430]\tvalidation_0-logloss:0.51177\tvalidation_1-logloss:0.52168\n",
            "[431]\tvalidation_0-logloss:0.51144\tvalidation_1-logloss:0.52137\n",
            "[432]\tvalidation_0-logloss:0.51123\tvalidation_1-logloss:0.52118\n",
            "[433]\tvalidation_0-logloss:0.51098\tvalidation_1-logloss:0.52094\n",
            "[434]\tvalidation_0-logloss:0.51089\tvalidation_1-logloss:0.52087\n",
            "[435]\tvalidation_0-logloss:0.51070\tvalidation_1-logloss:0.52070\n",
            "[436]\tvalidation_0-logloss:0.51051\tvalidation_1-logloss:0.52053\n",
            "[437]\tvalidation_0-logloss:0.51033\tvalidation_1-logloss:0.52037\n",
            "[438]\tvalidation_0-logloss:0.51016\tvalidation_1-logloss:0.52023\n",
            "[439]\tvalidation_0-logloss:0.51004\tvalidation_1-logloss:0.52012\n",
            "[440]\tvalidation_0-logloss:0.50993\tvalidation_1-logloss:0.52003\n",
            "[441]\tvalidation_0-logloss:0.50975\tvalidation_1-logloss:0.51986\n",
            "[442]\tvalidation_0-logloss:0.50943\tvalidation_1-logloss:0.51957\n",
            "[443]\tvalidation_0-logloss:0.50922\tvalidation_1-logloss:0.51938\n",
            "[444]\tvalidation_0-logloss:0.50904\tvalidation_1-logloss:0.51921\n",
            "[445]\tvalidation_0-logloss:0.50892\tvalidation_1-logloss:0.51910\n",
            "[446]\tvalidation_0-logloss:0.50873\tvalidation_1-logloss:0.51893\n",
            "[447]\tvalidation_0-logloss:0.50849\tvalidation_1-logloss:0.51871\n",
            "[448]\tvalidation_0-logloss:0.50840\tvalidation_1-logloss:0.51864\n",
            "[449]\tvalidation_0-logloss:0.50830\tvalidation_1-logloss:0.51855\n",
            "[450]\tvalidation_0-logloss:0.50819\tvalidation_1-logloss:0.51846\n",
            "[451]\tvalidation_0-logloss:0.50798\tvalidation_1-logloss:0.51827\n",
            "[452]\tvalidation_0-logloss:0.50775\tvalidation_1-logloss:0.51805\n",
            "[453]\tvalidation_0-logloss:0.50763\tvalidation_1-logloss:0.51795\n",
            "[454]\tvalidation_0-logloss:0.50746\tvalidation_1-logloss:0.51779\n",
            "[455]\tvalidation_0-logloss:0.50726\tvalidation_1-logloss:0.51761\n",
            "[456]\tvalidation_0-logloss:0.50710\tvalidation_1-logloss:0.51747\n",
            "[457]\tvalidation_0-logloss:0.50692\tvalidation_1-logloss:0.51730\n",
            "[458]\tvalidation_0-logloss:0.50674\tvalidation_1-logloss:0.51714\n",
            "[459]\tvalidation_0-logloss:0.50652\tvalidation_1-logloss:0.51693\n",
            "[460]\tvalidation_0-logloss:0.50643\tvalidation_1-logloss:0.51686\n",
            "[461]\tvalidation_0-logloss:0.50632\tvalidation_1-logloss:0.51676\n",
            "[462]\tvalidation_0-logloss:0.50615\tvalidation_1-logloss:0.51661\n",
            "[463]\tvalidation_0-logloss:0.50603\tvalidation_1-logloss:0.51651\n",
            "[464]\tvalidation_0-logloss:0.50581\tvalidation_1-logloss:0.51630\n",
            "[465]\tvalidation_0-logloss:0.50572\tvalidation_1-logloss:0.51622\n",
            "[466]\tvalidation_0-logloss:0.50541\tvalidation_1-logloss:0.51595\n",
            "[467]\tvalidation_0-logloss:0.50523\tvalidation_1-logloss:0.51578\n",
            "[468]\tvalidation_0-logloss:0.50504\tvalidation_1-logloss:0.51560\n",
            "[469]\tvalidation_0-logloss:0.50486\tvalidation_1-logloss:0.51544\n",
            "[470]\tvalidation_0-logloss:0.50475\tvalidation_1-logloss:0.51535\n",
            "[471]\tvalidation_0-logloss:0.50466\tvalidation_1-logloss:0.51527\n",
            "[472]\tvalidation_0-logloss:0.50449\tvalidation_1-logloss:0.51511\n",
            "[473]\tvalidation_0-logloss:0.50427\tvalidation_1-logloss:0.51491\n",
            "[474]\tvalidation_0-logloss:0.50408\tvalidation_1-logloss:0.51474\n",
            "[475]\tvalidation_0-logloss:0.50400\tvalidation_1-logloss:0.51468\n",
            "[476]\tvalidation_0-logloss:0.50370\tvalidation_1-logloss:0.51441\n",
            "[477]\tvalidation_0-logloss:0.50354\tvalidation_1-logloss:0.51426\n",
            "[478]\tvalidation_0-logloss:0.50340\tvalidation_1-logloss:0.51414\n",
            "[479]\tvalidation_0-logloss:0.50323\tvalidation_1-logloss:0.51398\n",
            "[480]\tvalidation_0-logloss:0.50308\tvalidation_1-logloss:0.51386\n",
            "[481]\tvalidation_0-logloss:0.50299\tvalidation_1-logloss:0.51377\n",
            "[482]\tvalidation_0-logloss:0.50282\tvalidation_1-logloss:0.51362\n",
            "[483]\tvalidation_0-logloss:0.50271\tvalidation_1-logloss:0.51353\n",
            "[484]\tvalidation_0-logloss:0.50252\tvalidation_1-logloss:0.51336\n",
            "[485]\tvalidation_0-logloss:0.50231\tvalidation_1-logloss:0.51316\n",
            "[486]\tvalidation_0-logloss:0.50220\tvalidation_1-logloss:0.51308\n",
            "[487]\tvalidation_0-logloss:0.50199\tvalidation_1-logloss:0.51289\n",
            "[488]\tvalidation_0-logloss:0.50183\tvalidation_1-logloss:0.51274\n",
            "[489]\tvalidation_0-logloss:0.50175\tvalidation_1-logloss:0.51268\n",
            "[490]\tvalidation_0-logloss:0.50160\tvalidation_1-logloss:0.51255\n",
            "[491]\tvalidation_0-logloss:0.50150\tvalidation_1-logloss:0.51246\n",
            "[492]\tvalidation_0-logloss:0.50134\tvalidation_1-logloss:0.51232\n",
            "[493]\tvalidation_0-logloss:0.50113\tvalidation_1-logloss:0.51213\n",
            "[494]\tvalidation_0-logloss:0.50104\tvalidation_1-logloss:0.51206\n",
            "[495]\tvalidation_0-logloss:0.50087\tvalidation_1-logloss:0.51191\n",
            "[496]\tvalidation_0-logloss:0.50079\tvalidation_1-logloss:0.51184\n",
            "[497]\tvalidation_0-logloss:0.50058\tvalidation_1-logloss:0.51165\n",
            "[498]\tvalidation_0-logloss:0.50048\tvalidation_1-logloss:0.51157\n",
            "[499]\tvalidation_0-logloss:0.50038\tvalidation_1-logloss:0.51150\n",
            "[500]\tvalidation_0-logloss:0.50010\tvalidation_1-logloss:0.51125\n",
            "[501]\tvalidation_0-logloss:0.49993\tvalidation_1-logloss:0.51109\n",
            "[502]\tvalidation_0-logloss:0.49976\tvalidation_1-logloss:0.51094\n",
            "[503]\tvalidation_0-logloss:0.49961\tvalidation_1-logloss:0.51080\n",
            "[504]\tvalidation_0-logloss:0.49947\tvalidation_1-logloss:0.51068\n",
            "[505]\tvalidation_0-logloss:0.49932\tvalidation_1-logloss:0.51055\n",
            "[506]\tvalidation_0-logloss:0.49901\tvalidation_1-logloss:0.51025\n",
            "[507]\tvalidation_0-logloss:0.49886\tvalidation_1-logloss:0.51011\n",
            "[508]\tvalidation_0-logloss:0.49866\tvalidation_1-logloss:0.50993\n",
            "[509]\tvalidation_0-logloss:0.49855\tvalidation_1-logloss:0.50983\n",
            "[510]\tvalidation_0-logloss:0.49845\tvalidation_1-logloss:0.50975\n",
            "[511]\tvalidation_0-logloss:0.49838\tvalidation_1-logloss:0.50969\n",
            "[512]\tvalidation_0-logloss:0.49818\tvalidation_1-logloss:0.50952\n",
            "[513]\tvalidation_0-logloss:0.49802\tvalidation_1-logloss:0.50937\n",
            "[514]\tvalidation_0-logloss:0.49782\tvalidation_1-logloss:0.50918\n",
            "[515]\tvalidation_0-logloss:0.49770\tvalidation_1-logloss:0.50908\n",
            "[516]\tvalidation_0-logloss:0.49753\tvalidation_1-logloss:0.50893\n",
            "[517]\tvalidation_0-logloss:0.49734\tvalidation_1-logloss:0.50875\n",
            "[518]\tvalidation_0-logloss:0.49725\tvalidation_1-logloss:0.50868\n",
            "[519]\tvalidation_0-logloss:0.49707\tvalidation_1-logloss:0.50852\n",
            "[520]\tvalidation_0-logloss:0.49699\tvalidation_1-logloss:0.50846\n",
            "[521]\tvalidation_0-logloss:0.49690\tvalidation_1-logloss:0.50838\n",
            "[522]\tvalidation_0-logloss:0.49677\tvalidation_1-logloss:0.50827\n",
            "[523]\tvalidation_0-logloss:0.49658\tvalidation_1-logloss:0.50809\n",
            "[524]\tvalidation_0-logloss:0.49644\tvalidation_1-logloss:0.50797\n",
            "[525]\tvalidation_0-logloss:0.49625\tvalidation_1-logloss:0.50781\n",
            "[526]\tvalidation_0-logloss:0.49608\tvalidation_1-logloss:0.50766\n",
            "[527]\tvalidation_0-logloss:0.49593\tvalidation_1-logloss:0.50752\n",
            "[528]\tvalidation_0-logloss:0.49578\tvalidation_1-logloss:0.50738\n",
            "[529]\tvalidation_0-logloss:0.49559\tvalidation_1-logloss:0.50721\n",
            "[530]\tvalidation_0-logloss:0.49552\tvalidation_1-logloss:0.50715\n",
            "[531]\tvalidation_0-logloss:0.49538\tvalidation_1-logloss:0.50703\n",
            "[532]\tvalidation_0-logloss:0.49520\tvalidation_1-logloss:0.50686\n",
            "[533]\tvalidation_0-logloss:0.49502\tvalidation_1-logloss:0.50669\n",
            "[534]\tvalidation_0-logloss:0.49492\tvalidation_1-logloss:0.50662\n",
            "[535]\tvalidation_0-logloss:0.49476\tvalidation_1-logloss:0.50646\n",
            "[536]\tvalidation_0-logloss:0.49461\tvalidation_1-logloss:0.50634\n",
            "[537]\tvalidation_0-logloss:0.49443\tvalidation_1-logloss:0.50618\n",
            "[538]\tvalidation_0-logloss:0.49428\tvalidation_1-logloss:0.50605\n",
            "[539]\tvalidation_0-logloss:0.49421\tvalidation_1-logloss:0.50599\n",
            "[540]\tvalidation_0-logloss:0.49405\tvalidation_1-logloss:0.50585\n",
            "[541]\tvalidation_0-logloss:0.49393\tvalidation_1-logloss:0.50575\n",
            "[542]\tvalidation_0-logloss:0.49376\tvalidation_1-logloss:0.50559\n",
            "[543]\tvalidation_0-logloss:0.49360\tvalidation_1-logloss:0.50545\n",
            "[544]\tvalidation_0-logloss:0.49350\tvalidation_1-logloss:0.50538\n",
            "[545]\tvalidation_0-logloss:0.49332\tvalidation_1-logloss:0.50522\n",
            "[546]\tvalidation_0-logloss:0.49317\tvalidation_1-logloss:0.50509\n",
            "[547]\tvalidation_0-logloss:0.49300\tvalidation_1-logloss:0.50493\n",
            "[548]\tvalidation_0-logloss:0.49291\tvalidation_1-logloss:0.50486\n",
            "[549]\tvalidation_0-logloss:0.49277\tvalidation_1-logloss:0.50473\n",
            "[550]\tvalidation_0-logloss:0.49263\tvalidation_1-logloss:0.50461\n",
            "[551]\tvalidation_0-logloss:0.49245\tvalidation_1-logloss:0.50445\n",
            "[552]\tvalidation_0-logloss:0.49238\tvalidation_1-logloss:0.50439\n",
            "[553]\tvalidation_0-logloss:0.49230\tvalidation_1-logloss:0.50433\n",
            "[554]\tvalidation_0-logloss:0.49205\tvalidation_1-logloss:0.50408\n",
            "[555]\tvalidation_0-logloss:0.49190\tvalidation_1-logloss:0.50395\n",
            "[556]\tvalidation_0-logloss:0.49181\tvalidation_1-logloss:0.50388\n",
            "[557]\tvalidation_0-logloss:0.49174\tvalidation_1-logloss:0.50382\n",
            "[558]\tvalidation_0-logloss:0.49157\tvalidation_1-logloss:0.50367\n",
            "[559]\tvalidation_0-logloss:0.49130\tvalidation_1-logloss:0.50342\n",
            "[560]\tvalidation_0-logloss:0.49113\tvalidation_1-logloss:0.50327\n",
            "[561]\tvalidation_0-logloss:0.49100\tvalidation_1-logloss:0.50316\n",
            "[562]\tvalidation_0-logloss:0.49083\tvalidation_1-logloss:0.50300\n",
            "[563]\tvalidation_0-logloss:0.49068\tvalidation_1-logloss:0.50286\n",
            "[564]\tvalidation_0-logloss:0.49058\tvalidation_1-logloss:0.50277\n",
            "[565]\tvalidation_0-logloss:0.49033\tvalidation_1-logloss:0.50253\n",
            "[566]\tvalidation_0-logloss:0.49024\tvalidation_1-logloss:0.50247\n",
            "[567]\tvalidation_0-logloss:0.49011\tvalidation_1-logloss:0.50234\n",
            "[568]\tvalidation_0-logloss:0.48994\tvalidation_1-logloss:0.50219\n",
            "[569]\tvalidation_0-logloss:0.48988\tvalidation_1-logloss:0.50215\n",
            "[570]\tvalidation_0-logloss:0.48973\tvalidation_1-logloss:0.50202\n",
            "[571]\tvalidation_0-logloss:0.48959\tvalidation_1-logloss:0.50190\n",
            "[572]\tvalidation_0-logloss:0.48948\tvalidation_1-logloss:0.50181\n",
            "[573]\tvalidation_0-logloss:0.48924\tvalidation_1-logloss:0.50157\n",
            "[574]\tvalidation_0-logloss:0.48911\tvalidation_1-logloss:0.50145\n",
            "[575]\tvalidation_0-logloss:0.48902\tvalidation_1-logloss:0.50139\n",
            "[576]\tvalidation_0-logloss:0.48887\tvalidation_1-logloss:0.50126\n",
            "[577]\tvalidation_0-logloss:0.48876\tvalidation_1-logloss:0.50117\n",
            "[578]\tvalidation_0-logloss:0.48860\tvalidation_1-logloss:0.50102\n",
            "[579]\tvalidation_0-logloss:0.48844\tvalidation_1-logloss:0.50087\n",
            "[580]\tvalidation_0-logloss:0.48820\tvalidation_1-logloss:0.50064\n",
            "[581]\tvalidation_0-logloss:0.48813\tvalidation_1-logloss:0.50059\n",
            "[582]\tvalidation_0-logloss:0.48797\tvalidation_1-logloss:0.50045\n",
            "[583]\tvalidation_0-logloss:0.48781\tvalidation_1-logloss:0.50030\n",
            "[584]\tvalidation_0-logloss:0.48773\tvalidation_1-logloss:0.50025\n",
            "[585]\tvalidation_0-logloss:0.48760\tvalidation_1-logloss:0.50014\n",
            "[586]\tvalidation_0-logloss:0.48747\tvalidation_1-logloss:0.50002\n",
            "[587]\tvalidation_0-logloss:0.48731\tvalidation_1-logloss:0.49988\n",
            "[588]\tvalidation_0-logloss:0.48709\tvalidation_1-logloss:0.49966\n",
            "[589]\tvalidation_0-logloss:0.48700\tvalidation_1-logloss:0.49960\n",
            "[590]\tvalidation_0-logloss:0.48694\tvalidation_1-logloss:0.49955\n",
            "[591]\tvalidation_0-logloss:0.48684\tvalidation_1-logloss:0.49946\n",
            "[592]\tvalidation_0-logloss:0.48670\tvalidation_1-logloss:0.49934\n",
            "[593]\tvalidation_0-logloss:0.48648\tvalidation_1-logloss:0.49912\n",
            "[594]\tvalidation_0-logloss:0.48633\tvalidation_1-logloss:0.49898\n",
            "[595]\tvalidation_0-logloss:0.48625\tvalidation_1-logloss:0.49892\n",
            "[596]\tvalidation_0-logloss:0.48618\tvalidation_1-logloss:0.49887\n",
            "[597]\tvalidation_0-logloss:0.48604\tvalidation_1-logloss:0.49876\n",
            "[598]\tvalidation_0-logloss:0.48594\tvalidation_1-logloss:0.49868\n",
            "[599]\tvalidation_0-logloss:0.48585\tvalidation_1-logloss:0.49860\n",
            "[600]\tvalidation_0-logloss:0.48570\tvalidation_1-logloss:0.49847\n",
            "[601]\tvalidation_0-logloss:0.48555\tvalidation_1-logloss:0.49833\n",
            "[602]\tvalidation_0-logloss:0.48540\tvalidation_1-logloss:0.49820\n",
            "[603]\tvalidation_0-logloss:0.48519\tvalidation_1-logloss:0.49799\n",
            "[604]\tvalidation_0-logloss:0.48510\tvalidation_1-logloss:0.49792\n",
            "[605]\tvalidation_0-logloss:0.48495\tvalidation_1-logloss:0.49779\n",
            "[606]\tvalidation_0-logloss:0.48481\tvalidation_1-logloss:0.49765\n",
            "[607]\tvalidation_0-logloss:0.48468\tvalidation_1-logloss:0.49754\n",
            "[608]\tvalidation_0-logloss:0.48462\tvalidation_1-logloss:0.49750\n",
            "[609]\tvalidation_0-logloss:0.48440\tvalidation_1-logloss:0.49729\n",
            "[610]\tvalidation_0-logloss:0.48433\tvalidation_1-logloss:0.49723\n",
            "[611]\tvalidation_0-logloss:0.48419\tvalidation_1-logloss:0.49711\n",
            "[612]\tvalidation_0-logloss:0.48412\tvalidation_1-logloss:0.49708\n",
            "[613]\tvalidation_0-logloss:0.48398\tvalidation_1-logloss:0.49695\n",
            "[614]\tvalidation_0-logloss:0.48377\tvalidation_1-logloss:0.49675\n",
            "[615]\tvalidation_0-logloss:0.48371\tvalidation_1-logloss:0.49670\n",
            "[616]\tvalidation_0-logloss:0.48363\tvalidation_1-logloss:0.49664\n",
            "[617]\tvalidation_0-logloss:0.48351\tvalidation_1-logloss:0.49654\n",
            "[618]\tvalidation_0-logloss:0.48337\tvalidation_1-logloss:0.49642\n",
            "[619]\tvalidation_0-logloss:0.48323\tvalidation_1-logloss:0.49629\n",
            "[620]\tvalidation_0-logloss:0.48303\tvalidation_1-logloss:0.49609\n",
            "[621]\tvalidation_0-logloss:0.48293\tvalidation_1-logloss:0.49601\n",
            "[622]\tvalidation_0-logloss:0.48285\tvalidation_1-logloss:0.49594\n",
            "[623]\tvalidation_0-logloss:0.48271\tvalidation_1-logloss:0.49582\n",
            "[624]\tvalidation_0-logloss:0.48264\tvalidation_1-logloss:0.49577\n",
            "[625]\tvalidation_0-logloss:0.48257\tvalidation_1-logloss:0.49572\n",
            "[626]\tvalidation_0-logloss:0.48244\tvalidation_1-logloss:0.49560\n",
            "[627]\tvalidation_0-logloss:0.48230\tvalidation_1-logloss:0.49548\n",
            "[628]\tvalidation_0-logloss:0.48210\tvalidation_1-logloss:0.49529\n",
            "[629]\tvalidation_0-logloss:0.48197\tvalidation_1-logloss:0.49517\n",
            "[630]\tvalidation_0-logloss:0.48182\tvalidation_1-logloss:0.49505\n",
            "[631]\tvalidation_0-logloss:0.48174\tvalidation_1-logloss:0.49500\n",
            "[632]\tvalidation_0-logloss:0.48161\tvalidation_1-logloss:0.49489\n",
            "[633]\tvalidation_0-logloss:0.48148\tvalidation_1-logloss:0.49476\n",
            "[634]\tvalidation_0-logloss:0.48137\tvalidation_1-logloss:0.49467\n",
            "[635]\tvalidation_0-logloss:0.48131\tvalidation_1-logloss:0.49463\n",
            "[636]\tvalidation_0-logloss:0.48123\tvalidation_1-logloss:0.49458\n",
            "[637]\tvalidation_0-logloss:0.48109\tvalidation_1-logloss:0.49445\n",
            "[638]\tvalidation_0-logloss:0.48090\tvalidation_1-logloss:0.49426\n",
            "[639]\tvalidation_0-logloss:0.48077\tvalidation_1-logloss:0.49414\n",
            "[640]\tvalidation_0-logloss:0.48064\tvalidation_1-logloss:0.49402\n",
            "[641]\tvalidation_0-logloss:0.48053\tvalidation_1-logloss:0.49392\n",
            "[642]\tvalidation_0-logloss:0.48046\tvalidation_1-logloss:0.49387\n",
            "[643]\tvalidation_0-logloss:0.48032\tvalidation_1-logloss:0.49375\n",
            "[644]\tvalidation_0-logloss:0.48013\tvalidation_1-logloss:0.49357\n",
            "[645]\tvalidation_0-logloss:0.48007\tvalidation_1-logloss:0.49353\n",
            "[646]\tvalidation_0-logloss:0.47994\tvalidation_1-logloss:0.49341\n",
            "[647]\tvalidation_0-logloss:0.47982\tvalidation_1-logloss:0.49331\n",
            "[648]\tvalidation_0-logloss:0.47974\tvalidation_1-logloss:0.49324\n",
            "[649]\tvalidation_0-logloss:0.47962\tvalidation_1-logloss:0.49313\n",
            "[650]\tvalidation_0-logloss:0.47948\tvalidation_1-logloss:0.49301\n",
            "[651]\tvalidation_0-logloss:0.47930\tvalidation_1-logloss:0.49283\n",
            "[652]\tvalidation_0-logloss:0.47917\tvalidation_1-logloss:0.49271\n",
            "[653]\tvalidation_0-logloss:0.47908\tvalidation_1-logloss:0.49265\n",
            "[654]\tvalidation_0-logloss:0.47900\tvalidation_1-logloss:0.49260\n",
            "[655]\tvalidation_0-logloss:0.47887\tvalidation_1-logloss:0.49249\n",
            "[656]\tvalidation_0-logloss:0.47882\tvalidation_1-logloss:0.49245\n",
            "[657]\tvalidation_0-logloss:0.47869\tvalidation_1-logloss:0.49234\n",
            "[658]\tvalidation_0-logloss:0.47856\tvalidation_1-logloss:0.49222\n",
            "[659]\tvalidation_0-logloss:0.47845\tvalidation_1-logloss:0.49213\n",
            "[660]\tvalidation_0-logloss:0.47835\tvalidation_1-logloss:0.49206\n",
            "[661]\tvalidation_0-logloss:0.47816\tvalidation_1-logloss:0.49189\n",
            "[662]\tvalidation_0-logloss:0.47804\tvalidation_1-logloss:0.49178\n",
            "[663]\tvalidation_0-logloss:0.47796\tvalidation_1-logloss:0.49172\n",
            "[664]\tvalidation_0-logloss:0.47789\tvalidation_1-logloss:0.49167\n",
            "[665]\tvalidation_0-logloss:0.47778\tvalidation_1-logloss:0.49158\n",
            "[666]\tvalidation_0-logloss:0.47766\tvalidation_1-logloss:0.49147\n",
            "[667]\tvalidation_0-logloss:0.47760\tvalidation_1-logloss:0.49143\n",
            "[668]\tvalidation_0-logloss:0.47746\tvalidation_1-logloss:0.49131\n",
            "[669]\tvalidation_0-logloss:0.47733\tvalidation_1-logloss:0.49120\n",
            "[670]\tvalidation_0-logloss:0.47716\tvalidation_1-logloss:0.49103\n",
            "[671]\tvalidation_0-logloss:0.47705\tvalidation_1-logloss:0.49093\n",
            "[672]\tvalidation_0-logloss:0.47697\tvalidation_1-logloss:0.49088\n",
            "[673]\tvalidation_0-logloss:0.47682\tvalidation_1-logloss:0.49073\n",
            "[674]\tvalidation_0-logloss:0.47669\tvalidation_1-logloss:0.49062\n",
            "[675]\tvalidation_0-logloss:0.47664\tvalidation_1-logloss:0.49059\n",
            "[676]\tvalidation_0-logloss:0.47655\tvalidation_1-logloss:0.49051\n",
            "[677]\tvalidation_0-logloss:0.47643\tvalidation_1-logloss:0.49041\n",
            "[678]\tvalidation_0-logloss:0.47631\tvalidation_1-logloss:0.49030\n",
            "[679]\tvalidation_0-logloss:0.47619\tvalidation_1-logloss:0.49020\n",
            "[680]\tvalidation_0-logloss:0.47606\tvalidation_1-logloss:0.49008\n",
            "[681]\tvalidation_0-logloss:0.47597\tvalidation_1-logloss:0.49001\n",
            "[682]\tvalidation_0-logloss:0.47590\tvalidation_1-logloss:0.48996\n",
            "[683]\tvalidation_0-logloss:0.47584\tvalidation_1-logloss:0.48992\n",
            "[684]\tvalidation_0-logloss:0.47571\tvalidation_1-logloss:0.48981\n",
            "[685]\tvalidation_0-logloss:0.47564\tvalidation_1-logloss:0.48975\n",
            "[686]\tvalidation_0-logloss:0.47552\tvalidation_1-logloss:0.48965\n",
            "[687]\tvalidation_0-logloss:0.47541\tvalidation_1-logloss:0.48955\n",
            "[688]\tvalidation_0-logloss:0.47528\tvalidation_1-logloss:0.48944\n",
            "[689]\tvalidation_0-logloss:0.47517\tvalidation_1-logloss:0.48935\n",
            "[690]\tvalidation_0-logloss:0.47500\tvalidation_1-logloss:0.48919\n",
            "[691]\tvalidation_0-logloss:0.47487\tvalidation_1-logloss:0.48908\n",
            "[692]\tvalidation_0-logloss:0.47475\tvalidation_1-logloss:0.48897\n",
            "[693]\tvalidation_0-logloss:0.47468\tvalidation_1-logloss:0.48892\n",
            "[694]\tvalidation_0-logloss:0.47460\tvalidation_1-logloss:0.48886\n",
            "[695]\tvalidation_0-logloss:0.47455\tvalidation_1-logloss:0.48881\n",
            "[696]\tvalidation_0-logloss:0.47444\tvalidation_1-logloss:0.48872\n",
            "[697]\tvalidation_0-logloss:0.47436\tvalidation_1-logloss:0.48867\n",
            "[698]\tvalidation_0-logloss:0.47423\tvalidation_1-logloss:0.48856\n",
            "[699]\tvalidation_0-logloss:0.47412\tvalidation_1-logloss:0.48847\n",
            "[700]\tvalidation_0-logloss:0.47405\tvalidation_1-logloss:0.48841\n",
            "[701]\tvalidation_0-logloss:0.47395\tvalidation_1-logloss:0.48832\n",
            "[702]\tvalidation_0-logloss:0.47384\tvalidation_1-logloss:0.48822\n",
            "[703]\tvalidation_0-logloss:0.47376\tvalidation_1-logloss:0.48817\n",
            "[704]\tvalidation_0-logloss:0.47370\tvalidation_1-logloss:0.48813\n",
            "[705]\tvalidation_0-logloss:0.47358\tvalidation_1-logloss:0.48803\n",
            "[706]\tvalidation_0-logloss:0.47348\tvalidation_1-logloss:0.48794\n",
            "[707]\tvalidation_0-logloss:0.47331\tvalidation_1-logloss:0.48779\n",
            "[708]\tvalidation_0-logloss:0.47320\tvalidation_1-logloss:0.48768\n",
            "[709]\tvalidation_0-logloss:0.47307\tvalidation_1-logloss:0.48758\n",
            "[710]\tvalidation_0-logloss:0.47299\tvalidation_1-logloss:0.48752\n",
            "[711]\tvalidation_0-logloss:0.47293\tvalidation_1-logloss:0.48747\n",
            "[712]\tvalidation_0-logloss:0.47281\tvalidation_1-logloss:0.48738\n",
            "[713]\tvalidation_0-logloss:0.47270\tvalidation_1-logloss:0.48728\n",
            "[714]\tvalidation_0-logloss:0.47256\tvalidation_1-logloss:0.48715\n",
            "[715]\tvalidation_0-logloss:0.47250\tvalidation_1-logloss:0.48711\n",
            "[716]\tvalidation_0-logloss:0.47238\tvalidation_1-logloss:0.48700\n",
            "[717]\tvalidation_0-logloss:0.47228\tvalidation_1-logloss:0.48692\n",
            "[718]\tvalidation_0-logloss:0.47216\tvalidation_1-logloss:0.48682\n",
            "[719]\tvalidation_0-logloss:0.47206\tvalidation_1-logloss:0.48674\n",
            "[720]\tvalidation_0-logloss:0.47199\tvalidation_1-logloss:0.48668\n",
            "[721]\tvalidation_0-logloss:0.47189\tvalidation_1-logloss:0.48660\n",
            "[722]\tvalidation_0-logloss:0.47177\tvalidation_1-logloss:0.48650\n",
            "[723]\tvalidation_0-logloss:0.47167\tvalidation_1-logloss:0.48641\n",
            "[724]\tvalidation_0-logloss:0.47156\tvalidation_1-logloss:0.48631\n",
            "[725]\tvalidation_0-logloss:0.47148\tvalidation_1-logloss:0.48626\n",
            "[726]\tvalidation_0-logloss:0.47136\tvalidation_1-logloss:0.48615\n",
            "[727]\tvalidation_0-logloss:0.47131\tvalidation_1-logloss:0.48611\n",
            "[728]\tvalidation_0-logloss:0.47118\tvalidation_1-logloss:0.48600\n",
            "[729]\tvalidation_0-logloss:0.47108\tvalidation_1-logloss:0.48593\n",
            "[730]\tvalidation_0-logloss:0.47097\tvalidation_1-logloss:0.48583\n",
            "[731]\tvalidation_0-logloss:0.47088\tvalidation_1-logloss:0.48576\n",
            "[732]\tvalidation_0-logloss:0.47078\tvalidation_1-logloss:0.48567\n",
            "[733]\tvalidation_0-logloss:0.47068\tvalidation_1-logloss:0.48559\n",
            "[734]\tvalidation_0-logloss:0.47057\tvalidation_1-logloss:0.48550\n",
            "[735]\tvalidation_0-logloss:0.47045\tvalidation_1-logloss:0.48540\n",
            "[736]\tvalidation_0-logloss:0.47038\tvalidation_1-logloss:0.48536\n",
            "[737]\tvalidation_0-logloss:0.47026\tvalidation_1-logloss:0.48525\n",
            "[738]\tvalidation_0-logloss:0.47016\tvalidation_1-logloss:0.48516\n",
            "[739]\tvalidation_0-logloss:0.47000\tvalidation_1-logloss:0.48502\n",
            "[740]\tvalidation_0-logloss:0.46991\tvalidation_1-logloss:0.48494\n",
            "[741]\tvalidation_0-logloss:0.46982\tvalidation_1-logloss:0.48487\n",
            "[742]\tvalidation_0-logloss:0.46970\tvalidation_1-logloss:0.48476\n",
            "[743]\tvalidation_0-logloss:0.46963\tvalidation_1-logloss:0.48471\n",
            "[744]\tvalidation_0-logloss:0.46943\tvalidation_1-logloss:0.48454\n",
            "[745]\tvalidation_0-logloss:0.46935\tvalidation_1-logloss:0.48447\n",
            "[746]\tvalidation_0-logloss:0.46926\tvalidation_1-logloss:0.48440\n",
            "[747]\tvalidation_0-logloss:0.46914\tvalidation_1-logloss:0.48430\n",
            "[748]\tvalidation_0-logloss:0.46903\tvalidation_1-logloss:0.48421\n",
            "[749]\tvalidation_0-logloss:0.46892\tvalidation_1-logloss:0.48411\n",
            "[750]\tvalidation_0-logloss:0.46886\tvalidation_1-logloss:0.48406\n",
            "[751]\tvalidation_0-logloss:0.46877\tvalidation_1-logloss:0.48400\n",
            "[752]\tvalidation_0-logloss:0.46872\tvalidation_1-logloss:0.48396\n",
            "[753]\tvalidation_0-logloss:0.46860\tvalidation_1-logloss:0.48386\n",
            "[754]\tvalidation_0-logloss:0.46853\tvalidation_1-logloss:0.48381\n",
            "[755]\tvalidation_0-logloss:0.46835\tvalidation_1-logloss:0.48365\n",
            "[756]\tvalidation_0-logloss:0.46824\tvalidation_1-logloss:0.48355\n",
            "[757]\tvalidation_0-logloss:0.46813\tvalidation_1-logloss:0.48346\n",
            "[758]\tvalidation_0-logloss:0.46805\tvalidation_1-logloss:0.48339\n",
            "[759]\tvalidation_0-logloss:0.46784\tvalidation_1-logloss:0.48320\n",
            "[760]\tvalidation_0-logloss:0.46766\tvalidation_1-logloss:0.48304\n",
            "[761]\tvalidation_0-logloss:0.46754\tvalidation_1-logloss:0.48294\n",
            "[762]\tvalidation_0-logloss:0.46748\tvalidation_1-logloss:0.48290\n",
            "[763]\tvalidation_0-logloss:0.46739\tvalidation_1-logloss:0.48283\n",
            "[764]\tvalidation_0-logloss:0.46728\tvalidation_1-logloss:0.48274\n",
            "[765]\tvalidation_0-logloss:0.46720\tvalidation_1-logloss:0.48267\n",
            "[766]\tvalidation_0-logloss:0.46704\tvalidation_1-logloss:0.48254\n",
            "[767]\tvalidation_0-logloss:0.46698\tvalidation_1-logloss:0.48249\n",
            "[768]\tvalidation_0-logloss:0.46691\tvalidation_1-logloss:0.48244\n",
            "[769]\tvalidation_0-logloss:0.46680\tvalidation_1-logloss:0.48235\n",
            "[770]\tvalidation_0-logloss:0.46672\tvalidation_1-logloss:0.48227\n",
            "[771]\tvalidation_0-logloss:0.46664\tvalidation_1-logloss:0.48221\n",
            "[772]\tvalidation_0-logloss:0.46649\tvalidation_1-logloss:0.48208\n",
            "[773]\tvalidation_0-logloss:0.46632\tvalidation_1-logloss:0.48192\n",
            "[774]\tvalidation_0-logloss:0.46624\tvalidation_1-logloss:0.48185\n",
            "[775]\tvalidation_0-logloss:0.46615\tvalidation_1-logloss:0.48177\n",
            "[776]\tvalidation_0-logloss:0.46604\tvalidation_1-logloss:0.48168\n",
            "[777]\tvalidation_0-logloss:0.46597\tvalidation_1-logloss:0.48163\n",
            "[778]\tvalidation_0-logloss:0.46591\tvalidation_1-logloss:0.48158\n",
            "[779]\tvalidation_0-logloss:0.46575\tvalidation_1-logloss:0.48144\n",
            "[780]\tvalidation_0-logloss:0.46558\tvalidation_1-logloss:0.48129\n",
            "[781]\tvalidation_0-logloss:0.46549\tvalidation_1-logloss:0.48120\n",
            "[782]\tvalidation_0-logloss:0.46538\tvalidation_1-logloss:0.48111\n",
            "[783]\tvalidation_0-logloss:0.46530\tvalidation_1-logloss:0.48105\n",
            "[784]\tvalidation_0-logloss:0.46514\tvalidation_1-logloss:0.48090\n",
            "[785]\tvalidation_0-logloss:0.46507\tvalidation_1-logloss:0.48086\n",
            "[786]\tvalidation_0-logloss:0.46498\tvalidation_1-logloss:0.48079\n",
            "[787]\tvalidation_0-logloss:0.46489\tvalidation_1-logloss:0.48071\n",
            "[788]\tvalidation_0-logloss:0.46481\tvalidation_1-logloss:0.48065\n",
            "[789]\tvalidation_0-logloss:0.46471\tvalidation_1-logloss:0.48056\n",
            "[790]\tvalidation_0-logloss:0.46462\tvalidation_1-logloss:0.48048\n",
            "[791]\tvalidation_0-logloss:0.46455\tvalidation_1-logloss:0.48043\n",
            "[792]\tvalidation_0-logloss:0.46439\tvalidation_1-logloss:0.48029\n",
            "[793]\tvalidation_0-logloss:0.46429\tvalidation_1-logloss:0.48021\n",
            "[794]\tvalidation_0-logloss:0.46422\tvalidation_1-logloss:0.48015\n",
            "[795]\tvalidation_0-logloss:0.46403\tvalidation_1-logloss:0.47998\n",
            "[796]\tvalidation_0-logloss:0.46394\tvalidation_1-logloss:0.47991\n",
            "[797]\tvalidation_0-logloss:0.46384\tvalidation_1-logloss:0.47982\n",
            "[798]\tvalidation_0-logloss:0.46378\tvalidation_1-logloss:0.47978\n",
            "[799]\tvalidation_0-logloss:0.46369\tvalidation_1-logloss:0.47971\n",
            "[800]\tvalidation_0-logloss:0.46360\tvalidation_1-logloss:0.47964\n",
            "[801]\tvalidation_0-logloss:0.46345\tvalidation_1-logloss:0.47949\n",
            "[802]\tvalidation_0-logloss:0.46335\tvalidation_1-logloss:0.47941\n",
            "[803]\tvalidation_0-logloss:0.46322\tvalidation_1-logloss:0.47929\n",
            "[804]\tvalidation_0-logloss:0.46316\tvalidation_1-logloss:0.47925\n",
            "[805]\tvalidation_0-logloss:0.46309\tvalidation_1-logloss:0.47921\n",
            "[806]\tvalidation_0-logloss:0.46299\tvalidation_1-logloss:0.47912\n",
            "[807]\tvalidation_0-logloss:0.46292\tvalidation_1-logloss:0.47906\n",
            "[808]\tvalidation_0-logloss:0.46283\tvalidation_1-logloss:0.47900\n",
            "[809]\tvalidation_0-logloss:0.46274\tvalidation_1-logloss:0.47891\n",
            "[810]\tvalidation_0-logloss:0.46264\tvalidation_1-logloss:0.47883\n",
            "[811]\tvalidation_0-logloss:0.46256\tvalidation_1-logloss:0.47877\n",
            "[812]\tvalidation_0-logloss:0.46245\tvalidation_1-logloss:0.47869\n",
            "[813]\tvalidation_0-logloss:0.46238\tvalidation_1-logloss:0.47863\n",
            "[814]\tvalidation_0-logloss:0.46231\tvalidation_1-logloss:0.47858\n",
            "[815]\tvalidation_0-logloss:0.46225\tvalidation_1-logloss:0.47853\n",
            "[816]\tvalidation_0-logloss:0.46212\tvalidation_1-logloss:0.47842\n",
            "[817]\tvalidation_0-logloss:0.46205\tvalidation_1-logloss:0.47838\n",
            "[818]\tvalidation_0-logloss:0.46200\tvalidation_1-logloss:0.47834\n",
            "[819]\tvalidation_0-logloss:0.46191\tvalidation_1-logloss:0.47827\n",
            "[820]\tvalidation_0-logloss:0.46182\tvalidation_1-logloss:0.47820\n",
            "[821]\tvalidation_0-logloss:0.46173\tvalidation_1-logloss:0.47812\n",
            "[822]\tvalidation_0-logloss:0.46164\tvalidation_1-logloss:0.47804\n",
            "[823]\tvalidation_0-logloss:0.46155\tvalidation_1-logloss:0.47796\n",
            "[824]\tvalidation_0-logloss:0.46150\tvalidation_1-logloss:0.47792\n",
            "[825]\tvalidation_0-logloss:0.46141\tvalidation_1-logloss:0.47785\n",
            "[826]\tvalidation_0-logloss:0.46130\tvalidation_1-logloss:0.47777\n",
            "[827]\tvalidation_0-logloss:0.46122\tvalidation_1-logloss:0.47771\n",
            "[828]\tvalidation_0-logloss:0.46111\tvalidation_1-logloss:0.47763\n",
            "[829]\tvalidation_0-logloss:0.46099\tvalidation_1-logloss:0.47752\n",
            "[830]\tvalidation_0-logloss:0.46093\tvalidation_1-logloss:0.47748\n",
            "[831]\tvalidation_0-logloss:0.46085\tvalidation_1-logloss:0.47741\n",
            "[832]\tvalidation_0-logloss:0.46077\tvalidation_1-logloss:0.47735\n",
            "[833]\tvalidation_0-logloss:0.46068\tvalidation_1-logloss:0.47727\n",
            "[834]\tvalidation_0-logloss:0.46061\tvalidation_1-logloss:0.47722\n",
            "[835]\tvalidation_0-logloss:0.46052\tvalidation_1-logloss:0.47713\n",
            "[836]\tvalidation_0-logloss:0.46039\tvalidation_1-logloss:0.47702\n",
            "[837]\tvalidation_0-logloss:0.46032\tvalidation_1-logloss:0.47698\n",
            "[838]\tvalidation_0-logloss:0.46023\tvalidation_1-logloss:0.47691\n",
            "[839]\tvalidation_0-logloss:0.46009\tvalidation_1-logloss:0.47679\n",
            "[840]\tvalidation_0-logloss:0.45999\tvalidation_1-logloss:0.47671\n",
            "[841]\tvalidation_0-logloss:0.45992\tvalidation_1-logloss:0.47666\n",
            "[842]\tvalidation_0-logloss:0.45984\tvalidation_1-logloss:0.47659\n",
            "[843]\tvalidation_0-logloss:0.45977\tvalidation_1-logloss:0.47655\n",
            "[844]\tvalidation_0-logloss:0.45971\tvalidation_1-logloss:0.47651\n",
            "[845]\tvalidation_0-logloss:0.45961\tvalidation_1-logloss:0.47643\n",
            "[846]\tvalidation_0-logloss:0.45953\tvalidation_1-logloss:0.47637\n",
            "[847]\tvalidation_0-logloss:0.45944\tvalidation_1-logloss:0.47629\n",
            "[848]\tvalidation_0-logloss:0.45937\tvalidation_1-logloss:0.47624\n",
            "[849]\tvalidation_0-logloss:0.45929\tvalidation_1-logloss:0.47617\n",
            "[850]\tvalidation_0-logloss:0.45917\tvalidation_1-logloss:0.47607\n",
            "[851]\tvalidation_0-logloss:0.45911\tvalidation_1-logloss:0.47602\n",
            "[852]\tvalidation_0-logloss:0.45905\tvalidation_1-logloss:0.47598\n",
            "[853]\tvalidation_0-logloss:0.45897\tvalidation_1-logloss:0.47591\n",
            "[854]\tvalidation_0-logloss:0.45883\tvalidation_1-logloss:0.47580\n",
            "[855]\tvalidation_0-logloss:0.45874\tvalidation_1-logloss:0.47572\n",
            "[856]\tvalidation_0-logloss:0.45863\tvalidation_1-logloss:0.47564\n",
            "[857]\tvalidation_0-logloss:0.45855\tvalidation_1-logloss:0.47558\n",
            "[858]\tvalidation_0-logloss:0.45847\tvalidation_1-logloss:0.47551\n",
            "[859]\tvalidation_0-logloss:0.45842\tvalidation_1-logloss:0.47546\n",
            "[860]\tvalidation_0-logloss:0.45833\tvalidation_1-logloss:0.47540\n",
            "[861]\tvalidation_0-logloss:0.45826\tvalidation_1-logloss:0.47534\n",
            "[862]\tvalidation_0-logloss:0.45819\tvalidation_1-logloss:0.47530\n",
            "[863]\tvalidation_0-logloss:0.45811\tvalidation_1-logloss:0.47524\n",
            "[864]\tvalidation_0-logloss:0.45800\tvalidation_1-logloss:0.47516\n",
            "[865]\tvalidation_0-logloss:0.45793\tvalidation_1-logloss:0.47510\n",
            "[866]\tvalidation_0-logloss:0.45779\tvalidation_1-logloss:0.47500\n",
            "[867]\tvalidation_0-logloss:0.45771\tvalidation_1-logloss:0.47493\n",
            "[868]\tvalidation_0-logloss:0.45762\tvalidation_1-logloss:0.47485\n",
            "[869]\tvalidation_0-logloss:0.45758\tvalidation_1-logloss:0.47482\n",
            "[870]\tvalidation_0-logloss:0.45753\tvalidation_1-logloss:0.47479\n",
            "[871]\tvalidation_0-logloss:0.45739\tvalidation_1-logloss:0.47468\n",
            "[872]\tvalidation_0-logloss:0.45730\tvalidation_1-logloss:0.47462\n",
            "[873]\tvalidation_0-logloss:0.45722\tvalidation_1-logloss:0.47455\n",
            "[874]\tvalidation_0-logloss:0.45714\tvalidation_1-logloss:0.47448\n",
            "[875]\tvalidation_0-logloss:0.45708\tvalidation_1-logloss:0.47443\n",
            "[876]\tvalidation_0-logloss:0.45699\tvalidation_1-logloss:0.47436\n",
            "[877]\tvalidation_0-logloss:0.45687\tvalidation_1-logloss:0.47426\n",
            "[878]\tvalidation_0-logloss:0.45674\tvalidation_1-logloss:0.47416\n",
            "[879]\tvalidation_0-logloss:0.45663\tvalidation_1-logloss:0.47406\n",
            "[880]\tvalidation_0-logloss:0.45654\tvalidation_1-logloss:0.47399\n",
            "[881]\tvalidation_0-logloss:0.45650\tvalidation_1-logloss:0.47396\n",
            "[882]\tvalidation_0-logloss:0.45643\tvalidation_1-logloss:0.47391\n",
            "[883]\tvalidation_0-logloss:0.45633\tvalidation_1-logloss:0.47384\n",
            "[884]\tvalidation_0-logloss:0.45624\tvalidation_1-logloss:0.47377\n",
            "[885]\tvalidation_0-logloss:0.45619\tvalidation_1-logloss:0.47374\n",
            "[886]\tvalidation_0-logloss:0.45611\tvalidation_1-logloss:0.47368\n",
            "[887]\tvalidation_0-logloss:0.45602\tvalidation_1-logloss:0.47362\n",
            "[888]\tvalidation_0-logloss:0.45596\tvalidation_1-logloss:0.47357\n",
            "[889]\tvalidation_0-logloss:0.45590\tvalidation_1-logloss:0.47352\n",
            "[890]\tvalidation_0-logloss:0.45582\tvalidation_1-logloss:0.47346\n",
            "[891]\tvalidation_0-logloss:0.45576\tvalidation_1-logloss:0.47342\n",
            "[892]\tvalidation_0-logloss:0.45568\tvalidation_1-logloss:0.47336\n",
            "[893]\tvalidation_0-logloss:0.45562\tvalidation_1-logloss:0.47332\n",
            "[894]\tvalidation_0-logloss:0.45554\tvalidation_1-logloss:0.47326\n",
            "[895]\tvalidation_0-logloss:0.45549\tvalidation_1-logloss:0.47322\n",
            "[896]\tvalidation_0-logloss:0.45542\tvalidation_1-logloss:0.47317\n",
            "[897]\tvalidation_0-logloss:0.45536\tvalidation_1-logloss:0.47314\n",
            "[898]\tvalidation_0-logloss:0.45528\tvalidation_1-logloss:0.47308\n",
            "[899]\tvalidation_0-logloss:0.45516\tvalidation_1-logloss:0.47297\n",
            "[900]\tvalidation_0-logloss:0.45509\tvalidation_1-logloss:0.47291\n",
            "[901]\tvalidation_0-logloss:0.45501\tvalidation_1-logloss:0.47286\n",
            "[902]\tvalidation_0-logloss:0.45496\tvalidation_1-logloss:0.47283\n",
            "[903]\tvalidation_0-logloss:0.45488\tvalidation_1-logloss:0.47277\n",
            "[904]\tvalidation_0-logloss:0.45484\tvalidation_1-logloss:0.47274\n",
            "[905]\tvalidation_0-logloss:0.45479\tvalidation_1-logloss:0.47271\n",
            "[906]\tvalidation_0-logloss:0.45471\tvalidation_1-logloss:0.47266\n",
            "[907]\tvalidation_0-logloss:0.45464\tvalidation_1-logloss:0.47260\n",
            "[908]\tvalidation_0-logloss:0.45449\tvalidation_1-logloss:0.47246\n",
            "[909]\tvalidation_0-logloss:0.45440\tvalidation_1-logloss:0.47239\n",
            "[910]\tvalidation_0-logloss:0.45434\tvalidation_1-logloss:0.47235\n",
            "[911]\tvalidation_0-logloss:0.45427\tvalidation_1-logloss:0.47230\n",
            "[912]\tvalidation_0-logloss:0.45420\tvalidation_1-logloss:0.47225\n",
            "[913]\tvalidation_0-logloss:0.45414\tvalidation_1-logloss:0.47221\n",
            "[914]\tvalidation_0-logloss:0.45402\tvalidation_1-logloss:0.47211\n",
            "[915]\tvalidation_0-logloss:0.45395\tvalidation_1-logloss:0.47206\n",
            "[916]\tvalidation_0-logloss:0.45390\tvalidation_1-logloss:0.47202\n",
            "[917]\tvalidation_0-logloss:0.45383\tvalidation_1-logloss:0.47196\n",
            "[918]\tvalidation_0-logloss:0.45376\tvalidation_1-logloss:0.47191\n",
            "[919]\tvalidation_0-logloss:0.45367\tvalidation_1-logloss:0.47185\n",
            "[920]\tvalidation_0-logloss:0.45358\tvalidation_1-logloss:0.47178\n",
            "[921]\tvalidation_0-logloss:0.45342\tvalidation_1-logloss:0.47166\n",
            "[922]\tvalidation_0-logloss:0.45334\tvalidation_1-logloss:0.47160\n",
            "[923]\tvalidation_0-logloss:0.45320\tvalidation_1-logloss:0.47148\n",
            "[924]\tvalidation_0-logloss:0.45313\tvalidation_1-logloss:0.47142\n",
            "[925]\tvalidation_0-logloss:0.45308\tvalidation_1-logloss:0.47139\n",
            "[926]\tvalidation_0-logloss:0.45304\tvalidation_1-logloss:0.47137\n",
            "[927]\tvalidation_0-logloss:0.45296\tvalidation_1-logloss:0.47132\n",
            "[928]\tvalidation_0-logloss:0.45281\tvalidation_1-logloss:0.47120\n",
            "[929]\tvalidation_0-logloss:0.45274\tvalidation_1-logloss:0.47115\n",
            "[930]\tvalidation_0-logloss:0.45263\tvalidation_1-logloss:0.47106\n",
            "[931]\tvalidation_0-logloss:0.45256\tvalidation_1-logloss:0.47100\n",
            "[932]\tvalidation_0-logloss:0.45249\tvalidation_1-logloss:0.47095\n",
            "[933]\tvalidation_0-logloss:0.45241\tvalidation_1-logloss:0.47088\n",
            "[934]\tvalidation_0-logloss:0.45235\tvalidation_1-logloss:0.47085\n",
            "[935]\tvalidation_0-logloss:0.45228\tvalidation_1-logloss:0.47079\n",
            "[936]\tvalidation_0-logloss:0.45224\tvalidation_1-logloss:0.47076\n",
            "[937]\tvalidation_0-logloss:0.45217\tvalidation_1-logloss:0.47071\n",
            "[938]\tvalidation_0-logloss:0.45203\tvalidation_1-logloss:0.47060\n",
            "[939]\tvalidation_0-logloss:0.45192\tvalidation_1-logloss:0.47051\n",
            "[940]\tvalidation_0-logloss:0.45184\tvalidation_1-logloss:0.47045\n",
            "[941]\tvalidation_0-logloss:0.45176\tvalidation_1-logloss:0.47039\n",
            "[942]\tvalidation_0-logloss:0.45171\tvalidation_1-logloss:0.47035\n",
            "[943]\tvalidation_0-logloss:0.45165\tvalidation_1-logloss:0.47029\n",
            "[944]\tvalidation_0-logloss:0.45158\tvalidation_1-logloss:0.47025\n",
            "[945]\tvalidation_0-logloss:0.45154\tvalidation_1-logloss:0.47022\n",
            "[946]\tvalidation_0-logloss:0.45147\tvalidation_1-logloss:0.47016\n",
            "[947]\tvalidation_0-logloss:0.45141\tvalidation_1-logloss:0.47011\n",
            "[948]\tvalidation_0-logloss:0.45134\tvalidation_1-logloss:0.47007\n",
            "[949]\tvalidation_0-logloss:0.45128\tvalidation_1-logloss:0.47002\n",
            "[950]\tvalidation_0-logloss:0.45121\tvalidation_1-logloss:0.46997\n",
            "[951]\tvalidation_0-logloss:0.45114\tvalidation_1-logloss:0.46992\n",
            "[952]\tvalidation_0-logloss:0.45107\tvalidation_1-logloss:0.46987\n",
            "[953]\tvalidation_0-logloss:0.45102\tvalidation_1-logloss:0.46984\n",
            "[954]\tvalidation_0-logloss:0.45098\tvalidation_1-logloss:0.46980\n",
            "[955]\tvalidation_0-logloss:0.45084\tvalidation_1-logloss:0.46967\n",
            "[956]\tvalidation_0-logloss:0.45077\tvalidation_1-logloss:0.46962\n",
            "[957]\tvalidation_0-logloss:0.45072\tvalidation_1-logloss:0.46957\n",
            "[958]\tvalidation_0-logloss:0.45067\tvalidation_1-logloss:0.46955\n",
            "[959]\tvalidation_0-logloss:0.45060\tvalidation_1-logloss:0.46950\n",
            "[960]\tvalidation_0-logloss:0.45054\tvalidation_1-logloss:0.46946\n",
            "[961]\tvalidation_0-logloss:0.45048\tvalidation_1-logloss:0.46941\n",
            "[962]\tvalidation_0-logloss:0.45041\tvalidation_1-logloss:0.46935\n",
            "[963]\tvalidation_0-logloss:0.45033\tvalidation_1-logloss:0.46928\n",
            "[964]\tvalidation_0-logloss:0.45028\tvalidation_1-logloss:0.46925\n",
            "[965]\tvalidation_0-logloss:0.45022\tvalidation_1-logloss:0.46920\n",
            "[966]\tvalidation_0-logloss:0.45016\tvalidation_1-logloss:0.46916\n",
            "[967]\tvalidation_0-logloss:0.45002\tvalidation_1-logloss:0.46903\n",
            "[968]\tvalidation_0-logloss:0.44997\tvalidation_1-logloss:0.46900\n",
            "[969]\tvalidation_0-logloss:0.44989\tvalidation_1-logloss:0.46894\n",
            "[970]\tvalidation_0-logloss:0.44975\tvalidation_1-logloss:0.46884\n",
            "[971]\tvalidation_0-logloss:0.44965\tvalidation_1-logloss:0.46877\n",
            "[972]\tvalidation_0-logloss:0.44958\tvalidation_1-logloss:0.46871\n",
            "[973]\tvalidation_0-logloss:0.44952\tvalidation_1-logloss:0.46866\n",
            "[974]\tvalidation_0-logloss:0.44948\tvalidation_1-logloss:0.46863\n",
            "[975]\tvalidation_0-logloss:0.44940\tvalidation_1-logloss:0.46858\n",
            "[976]\tvalidation_0-logloss:0.44935\tvalidation_1-logloss:0.46854\n",
            "[977]\tvalidation_0-logloss:0.44930\tvalidation_1-logloss:0.46850\n",
            "[978]\tvalidation_0-logloss:0.44924\tvalidation_1-logloss:0.46845\n",
            "[979]\tvalidation_0-logloss:0.44919\tvalidation_1-logloss:0.46842\n",
            "[980]\tvalidation_0-logloss:0.44913\tvalidation_1-logloss:0.46838\n",
            "[981]\tvalidation_0-logloss:0.44909\tvalidation_1-logloss:0.46835\n",
            "[982]\tvalidation_0-logloss:0.44903\tvalidation_1-logloss:0.46831\n",
            "[983]\tvalidation_0-logloss:0.44896\tvalidation_1-logloss:0.46825\n",
            "[984]\tvalidation_0-logloss:0.44889\tvalidation_1-logloss:0.46820\n",
            "[985]\tvalidation_0-logloss:0.44876\tvalidation_1-logloss:0.46808\n",
            "[986]\tvalidation_0-logloss:0.44871\tvalidation_1-logloss:0.46804\n",
            "[987]\tvalidation_0-logloss:0.44865\tvalidation_1-logloss:0.46800\n",
            "[988]\tvalidation_0-logloss:0.44858\tvalidation_1-logloss:0.46795\n",
            "[989]\tvalidation_0-logloss:0.44846\tvalidation_1-logloss:0.46783\n",
            "[990]\tvalidation_0-logloss:0.44841\tvalidation_1-logloss:0.46781\n",
            "[991]\tvalidation_0-logloss:0.44835\tvalidation_1-logloss:0.46777\n",
            "[992]\tvalidation_0-logloss:0.44830\tvalidation_1-logloss:0.46773\n",
            "[993]\tvalidation_0-logloss:0.44824\tvalidation_1-logloss:0.46769\n",
            "[994]\tvalidation_0-logloss:0.44816\tvalidation_1-logloss:0.46763\n",
            "[995]\tvalidation_0-logloss:0.44810\tvalidation_1-logloss:0.46758\n",
            "[996]\tvalidation_0-logloss:0.44798\tvalidation_1-logloss:0.46747\n",
            "[997]\tvalidation_0-logloss:0.44793\tvalidation_1-logloss:0.46744\n",
            "[998]\tvalidation_0-logloss:0.44787\tvalidation_1-logloss:0.46739\n",
            "[999]\tvalidation_0-logloss:0.44783\tvalidation_1-logloss:0.46737\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=42, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = xgb_over_model.predict(X_valid)\n",
        "get_clf_eval(y_valid, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHxn__3wc-TW",
        "outputId": "9493f3db-bec7-4368-b1d3-83e4bb5ceffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차 행렬\n",
            "[[35335   609]\n",
            " [ 7223   483]]\n",
            "정확도 : 0.8206, 정밀도 : 0.4423, 재현율 : 0.0627, F1 : 0.1098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_over_report = metrics.classification_report(y_valid, y_pred, zero_division=1)\n",
        "print(xgb_over_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ouLmU_8dG7h",
        "outputId": "27e104d7-1420-4ff0-b046-a50e34d61b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.98      0.90     35944\n",
            "           1       0.44      0.06      0.11      7706\n",
            "\n",
            "    accuracy                           0.82     43650\n",
            "   macro avg       0.64      0.52      0.51     43650\n",
            "weighted avg       0.76      0.82      0.76     43650\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 재현율이 유의미하게 개선되지 않았다"
      ],
      "metadata": {
        "id": "AuNP2FlbdsoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM"
      ],
      "metadata": {
        "id": "psRxl6Duxh-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(C=1, kernel='rbf', gamma=10, random_state=42)\n",
        "svm.fit(X_train_over, y_train_over)"
      ],
      "metadata": {
        "id": "5VYYStvbxkaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svm.predict(X_test)\n",
        "get_clf_eval(y_test, y_pred)"
      ],
      "metadata": {
        "id": "LDB30hZSxwgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_report_under = metrics.classification_report(y_test, y_pred, zero_division=1)\n",
        "print(svm_report_under)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JRFP2J1xweg",
        "outputId": "f9196ef0-a4ee-419b-a495-228973cf50a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90     35944\n",
            "           1       1.00      0.00      0.00      7706\n",
            "\n",
            "    accuracy                           0.82     43650\n",
            "   macro avg       0.91      0.50      0.45     43650\n",
            "weighted avg       0.85      0.82      0.74     43650\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FU7IrcHAIgGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfVghfW9hPqG"
      },
      "source": [
        "# label 불균형 해결 2 : Under Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vA2GGrOWo4tn"
      },
      "outputs": [],
      "source": [
        "not_delayed_data = train[train['Delay'] == 0]\n",
        "delayed_data = train[train['Delay'] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1FRheWBo6mF"
      },
      "outputs": [],
      "source": [
        "under_not_delayed = not_delayed_data.sample(n=len(delayed_data), random_state=42)\n",
        "under_data = pd.concat([delayed_data, under_not_delayed], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUC7ggThpFkq",
        "outputId": "cec19ebc-56bf-4103-8be3-06defaeffdf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Delay\n",
            "1    38529\n",
            "0    38529\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(under_data['Delay'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwqj8kWOpVRW"
      },
      "outputs": [],
      "source": [
        "X = under_data.iloc[:,:-1]\n",
        "y = under_data.iloc[:,-1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.1, random_state=42)"
      ],
      "metadata": {
        "id": "VYLxzU9uqdyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYR4_vuypoN3",
        "outputId": "d79c5f82-b80d-4638-f26c-23ba14098d54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(55481, 13) (55481,)\n",
            "(6165, 13) (6165,)\n",
            "(15412, 13) (15412,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape, y_train.shape)\n",
        "print(X_valid.shape, y_valid.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_cols = X_train.select_dtypes(exclude=['object']).columns\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
        "X_valid[numeric_cols] = scaler.transform(X_valid[numeric_cols])\n",
        "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_valid.shape, y_valid.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqbGYze57DQk",
        "outputId": "41a96c1c-5a5b-41a2-fd06-533c5cbba2df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(55481, 13) (55481,)\n",
            "(6165, 13) (6165,)\n",
            "(15412, 13) (15412,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "XMwSRR3D1ffz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression(random_state=42, max_iter=1000, verbose=True,\n",
        "                              penalty='l2', n_jobs=-1)\n",
        "\n",
        "lr_model.fit(X_train, y_train)\n",
        "y_pred = lr_model.predict(X_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlkNv9M21iW5",
        "outputId": "fcb1dcab-b924-4725-95dc-34ce862bd85d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_clf_eval(y_valid, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbaTZYLP1iSW",
        "outputId": "f4399124-0833-4bd2-8064-fd279846c0e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차 행렬\n",
            "[[1697 1414]\n",
            " [1176 1878]]\n",
            "정확도 : 0.5799, 정밀도 : 0.5705, 재현율 : 0.6149, F1 : 0.5919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_report_over = metrics.classification_report(y_valid, y_pred, zero_division=1)\n",
        "print(lr_report_over)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXcaED0y1iQE",
        "outputId": "a73bf14e-1742-4b6f-f64e-a1164ff4bf7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.55      0.57      3111\n",
            "           1       0.57      0.61      0.59      3054\n",
            "\n",
            "    accuracy                           0.58      6165\n",
            "   macro avg       0.58      0.58      0.58      6165\n",
            "weighted avg       0.58      0.58      0.58      6165\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBM"
      ],
      "metadata": {
        "id": "DAzDtIqo8pGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_under_model = LGBMClassifier(n_estimators=1000, num_leaves=64,\n",
        "                          n_jobs=-1, boost_from_average=False, force_col_wise=True)"
      ],
      "metadata": {
        "id": "FycNcClp-I1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_under_model.fit(X_train, y_train, callbacks=[early_stopping(stopping_rounds=50)],\n",
        "              eval_metric=['logloss'], eval_set=[(X_train, y_train), (X_valid, y_valid)])\n",
        "\n",
        "y_pred = lgbm_under_model.predict(X_test)\n",
        "get_clf_eval(y_test, y_pred)\n",
        "\n",
        "lgbm_under_report = metrics.classification_report(y_test, y_pred, zero_division=1)\n",
        "print(lgbm_under_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaCtXV1V7Z3z",
        "outputId": "6820c8fc-171b-4576-d162-351289b0f8af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 27769, number of negative: 27712\n",
            "[LightGBM] [Info] Total Bins 1802\n",
            "[LightGBM] [Info] Number of data points in the train set: 55481, number of used features: 12\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[96]\ttraining's binary_logloss: 0.593364\tvalid_1's binary_logloss: 0.650798\n",
            "오차 행렬\n",
            "[[4772 2934]\n",
            " [3020 4686]]\n",
            "정확도 : 0.6137, 정밀도 : 0.6150, 재현율 : 0.6081, F1 : 0.6115\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.62      0.62      7706\n",
            "           1       0.61      0.61      0.61      7706\n",
            "\n",
            "    accuracy                           0.61     15412\n",
            "   macro avg       0.61      0.61      0.61     15412\n",
            "weighted avg       0.61      0.61      0.61     15412\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXs-JvvZmVu0"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "oZMHdsFlprhM",
        "outputId": "bb4d558d-f633-43ed-931e-d740073604b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
              "             param_grid={'n_neighbors': [5, 7, 9, 12]})"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
              "             param_grid={&#x27;n_neighbors&#x27;: [5, 7, 9, 12]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
              "             param_grid={&#x27;n_neighbors&#x27;: [5, 7, 9, 12]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "knn = KNeighborsClassifier()\n",
        "\n",
        "parameters = {'n_neighbors' : [5, 7, 9, 12]}\n",
        "knn_grid = GridSearchCV(knn, param_grid=parameters, cv=3, refit=True)\n",
        "knn_grid.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_df = pd.DataFrame(knn_grid.cv_results_)\n",
        "scores_df[['params', 'mean_test_score',\n",
        "           'rank_test_score', 'split0_test_score',\n",
        "           'split1_test_score', 'split2_test_score']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "DIxTJU3S9oR1",
        "outputId": "fa5268dd-7541-45c0-8670-23b6079ccaa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                params  mean_test_score  rank_test_score  split0_test_score  \\\n",
              "0   {'n_neighbors': 5}         0.555632                4           0.557748   \n",
              "1   {'n_neighbors': 7}         0.559399                3           0.560722   \n",
              "2   {'n_neighbors': 9}         0.562589                2           0.564616   \n",
              "3  {'n_neighbors': 12}         0.565761                1           0.567103   \n",
              "\n",
              "   split1_test_score  split2_test_score  \n",
              "0           0.551747           0.557400  \n",
              "1           0.559154           0.558319  \n",
              "2           0.562236           0.560915  \n",
              "3           0.564399           0.565782  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6da5648-343f-4860-8a0e-0ea888304162\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'n_neighbors': 5}</td>\n",
              "      <td>0.555632</td>\n",
              "      <td>4</td>\n",
              "      <td>0.557748</td>\n",
              "      <td>0.551747</td>\n",
              "      <td>0.557400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'n_neighbors': 7}</td>\n",
              "      <td>0.559399</td>\n",
              "      <td>3</td>\n",
              "      <td>0.560722</td>\n",
              "      <td>0.559154</td>\n",
              "      <td>0.558319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'n_neighbors': 9}</td>\n",
              "      <td>0.562589</td>\n",
              "      <td>2</td>\n",
              "      <td>0.564616</td>\n",
              "      <td>0.562236</td>\n",
              "      <td>0.560915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'n_neighbors': 12}</td>\n",
              "      <td>0.565761</td>\n",
              "      <td>1</td>\n",
              "      <td>0.567103</td>\n",
              "      <td>0.564399</td>\n",
              "      <td>0.565782</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6da5648-343f-4860-8a0e-0ea888304162')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e6da5648-343f-4860-8a0e-0ea888304162 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e6da5648-343f-4860-8a0e-0ea888304162');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5f84d4b2-2e64-44e1-8735-8bbe093d0928\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f84d4b2-2e64-44e1-8735-8bbe093d0928')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5f84d4b2-2e64-44e1-8735-8bbe093d0928 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"           'split1_test_score', 'split2_test_score']]\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"params\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_test_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004339022645427392,\n        \"min\": 0.5556316895587278,\n        \"max\": 0.5657612519672527,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5593986936189049,\n          0.5657612519672527,\n          0.5556316895587278\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rank_test_score\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          1,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split0_test_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004138832085142702,\n        \"min\": 0.5577484589596626,\n        \"max\": 0.5671028441656754,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5607223964529037,\n          0.5671028441656754,\n          0.5577484589596626\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split1_test_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005527900159211549,\n        \"min\": 0.5517465123823942,\n        \"max\": 0.5643992646263654,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5591543203201038,\n          0.5643992646263654,\n          0.5517465123823942\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split2_test_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.003758956740393818,\n        \"min\": 0.5574000973341264,\n        \"max\": 0.5657816471097172,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5583193640837073,\n          0.5657816471097172,\n          0.5574000973341264\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = knn_grid.predict(X_valid)\n",
        "get_clf_eval(y_valid, y_pred)\n",
        "\n",
        "knn_report_under = metrics.classification_report(y_valid, y_pred, zero_division=1)\n",
        "print(knn_report_under)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuCESRgY9pTL",
        "outputId": "d5d6cafa-4659-4bca-991b-e87e8ca19fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차 행렬\n",
            "[[1994 1117]\n",
            " [1530 1524]]\n",
            "정확도 : 0.5706, 정밀도 : 0.5771, 재현율 : 0.4990, F1 : 0.5352\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.64      0.60      3111\n",
            "           1       0.58      0.50      0.54      3054\n",
            "\n",
            "    accuracy                           0.57      6165\n",
            "   macro avg       0.57      0.57      0.57      6165\n",
            "weighted avg       0.57      0.57      0.57      6165\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLTwNwM1mREo"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = XGBClassifier(learning_rate=0.01,\n",
        "                          n_estimators=1000,\n",
        "                          max_depth=8,\n",
        "                          random_state=42)"
      ],
      "metadata": {
        "id": "rj05g-_u-O8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "A0YeT-FpymYp",
        "outputId": "e8769bfb-5ed7-4ccf-97bb-78ffe6693a60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-logloss:0.69234\tvalidation_1-logloss:0.69256\n",
            "[1]\tvalidation_0-logloss:0.69154\tvalidation_1-logloss:0.69197\n",
            "[2]\tvalidation_0-logloss:0.69076\tvalidation_1-logloss:0.69139\n",
            "[3]\tvalidation_0-logloss:0.68998\tvalidation_1-logloss:0.69082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4]\tvalidation_0-logloss:0.68923\tvalidation_1-logloss:0.69028\n",
            "[5]\tvalidation_0-logloss:0.68848\tvalidation_1-logloss:0.68974\n",
            "[6]\tvalidation_0-logloss:0.68775\tvalidation_1-logloss:0.68922\n",
            "[7]\tvalidation_0-logloss:0.68699\tvalidation_1-logloss:0.68869\n",
            "[8]\tvalidation_0-logloss:0.68624\tvalidation_1-logloss:0.68814\n",
            "[9]\tvalidation_0-logloss:0.68556\tvalidation_1-logloss:0.68766\n",
            "[10]\tvalidation_0-logloss:0.68483\tvalidation_1-logloss:0.68713\n",
            "[11]\tvalidation_0-logloss:0.68412\tvalidation_1-logloss:0.68661\n",
            "[12]\tvalidation_0-logloss:0.68342\tvalidation_1-logloss:0.68612\n",
            "[13]\tvalidation_0-logloss:0.68273\tvalidation_1-logloss:0.68565\n",
            "[14]\tvalidation_0-logloss:0.68208\tvalidation_1-logloss:0.68520\n",
            "[15]\tvalidation_0-logloss:0.68141\tvalidation_1-logloss:0.68474\n",
            "[16]\tvalidation_0-logloss:0.68076\tvalidation_1-logloss:0.68425\n",
            "[17]\tvalidation_0-logloss:0.68011\tvalidation_1-logloss:0.68382\n",
            "[18]\tvalidation_0-logloss:0.67947\tvalidation_1-logloss:0.68338\n",
            "[19]\tvalidation_0-logloss:0.67883\tvalidation_1-logloss:0.68294\n",
            "[20]\tvalidation_0-logloss:0.67821\tvalidation_1-logloss:0.68248\n",
            "[21]\tvalidation_0-logloss:0.67759\tvalidation_1-logloss:0.68203\n",
            "[22]\tvalidation_0-logloss:0.67700\tvalidation_1-logloss:0.68162\n",
            "[23]\tvalidation_0-logloss:0.67641\tvalidation_1-logloss:0.68121\n",
            "[24]\tvalidation_0-logloss:0.67581\tvalidation_1-logloss:0.68082\n",
            "[25]\tvalidation_0-logloss:0.67524\tvalidation_1-logloss:0.68041\n",
            "[26]\tvalidation_0-logloss:0.67469\tvalidation_1-logloss:0.68004\n",
            "[27]\tvalidation_0-logloss:0.67412\tvalidation_1-logloss:0.67967\n",
            "[28]\tvalidation_0-logloss:0.67356\tvalidation_1-logloss:0.67928\n",
            "[29]\tvalidation_0-logloss:0.67301\tvalidation_1-logloss:0.67893\n",
            "[30]\tvalidation_0-logloss:0.67246\tvalidation_1-logloss:0.67858\n",
            "[31]\tvalidation_0-logloss:0.67192\tvalidation_1-logloss:0.67822\n",
            "[32]\tvalidation_0-logloss:0.67139\tvalidation_1-logloss:0.67787\n",
            "[33]\tvalidation_0-logloss:0.67088\tvalidation_1-logloss:0.67753\n",
            "[34]\tvalidation_0-logloss:0.67036\tvalidation_1-logloss:0.67721\n",
            "[35]\tvalidation_0-logloss:0.66984\tvalidation_1-logloss:0.67686\n",
            "[36]\tvalidation_0-logloss:0.66933\tvalidation_1-logloss:0.67653\n",
            "[37]\tvalidation_0-logloss:0.66883\tvalidation_1-logloss:0.67621\n",
            "[38]\tvalidation_0-logloss:0.66835\tvalidation_1-logloss:0.67594\n",
            "[39]\tvalidation_0-logloss:0.66786\tvalidation_1-logloss:0.67562\n",
            "[40]\tvalidation_0-logloss:0.66738\tvalidation_1-logloss:0.67532\n",
            "[41]\tvalidation_0-logloss:0.66690\tvalidation_1-logloss:0.67502\n",
            "[42]\tvalidation_0-logloss:0.66646\tvalidation_1-logloss:0.67477\n",
            "[43]\tvalidation_0-logloss:0.66599\tvalidation_1-logloss:0.67449\n",
            "[44]\tvalidation_0-logloss:0.66552\tvalidation_1-logloss:0.67421\n",
            "[45]\tvalidation_0-logloss:0.66506\tvalidation_1-logloss:0.67395\n",
            "[46]\tvalidation_0-logloss:0.66462\tvalidation_1-logloss:0.67368\n",
            "[47]\tvalidation_0-logloss:0.66418\tvalidation_1-logloss:0.67343\n",
            "[48]\tvalidation_0-logloss:0.66375\tvalidation_1-logloss:0.67318\n",
            "[49]\tvalidation_0-logloss:0.66332\tvalidation_1-logloss:0.67294\n",
            "[50]\tvalidation_0-logloss:0.66290\tvalidation_1-logloss:0.67269\n",
            "[51]\tvalidation_0-logloss:0.66249\tvalidation_1-logloss:0.67246\n",
            "[52]\tvalidation_0-logloss:0.66210\tvalidation_1-logloss:0.67222\n",
            "[53]\tvalidation_0-logloss:0.66167\tvalidation_1-logloss:0.67199\n",
            "[54]\tvalidation_0-logloss:0.66128\tvalidation_1-logloss:0.67175\n",
            "[55]\tvalidation_0-logloss:0.66089\tvalidation_1-logloss:0.67152\n",
            "[56]\tvalidation_0-logloss:0.66051\tvalidation_1-logloss:0.67130\n",
            "[57]\tvalidation_0-logloss:0.66011\tvalidation_1-logloss:0.67110\n",
            "[58]\tvalidation_0-logloss:0.65974\tvalidation_1-logloss:0.67089\n",
            "[59]\tvalidation_0-logloss:0.65935\tvalidation_1-logloss:0.67067\n",
            "[60]\tvalidation_0-logloss:0.65899\tvalidation_1-logloss:0.67047\n",
            "[61]\tvalidation_0-logloss:0.65863\tvalidation_1-logloss:0.67027\n",
            "[62]\tvalidation_0-logloss:0.65823\tvalidation_1-logloss:0.67004\n",
            "[63]\tvalidation_0-logloss:0.65788\tvalidation_1-logloss:0.66984\n",
            "[64]\tvalidation_0-logloss:0.65752\tvalidation_1-logloss:0.66966\n",
            "[65]\tvalidation_0-logloss:0.65718\tvalidation_1-logloss:0.66948\n",
            "[66]\tvalidation_0-logloss:0.65683\tvalidation_1-logloss:0.66930\n",
            "[67]\tvalidation_0-logloss:0.65648\tvalidation_1-logloss:0.66913\n",
            "[68]\tvalidation_0-logloss:0.65615\tvalidation_1-logloss:0.66897\n",
            "[69]\tvalidation_0-logloss:0.65581\tvalidation_1-logloss:0.66880\n",
            "[70]\tvalidation_0-logloss:0.65545\tvalidation_1-logloss:0.66861\n",
            "[71]\tvalidation_0-logloss:0.65513\tvalidation_1-logloss:0.66845\n",
            "[72]\tvalidation_0-logloss:0.65479\tvalidation_1-logloss:0.66831\n",
            "[73]\tvalidation_0-logloss:0.65442\tvalidation_1-logloss:0.66812\n",
            "[74]\tvalidation_0-logloss:0.65410\tvalidation_1-logloss:0.66798\n",
            "[75]\tvalidation_0-logloss:0.65380\tvalidation_1-logloss:0.66785\n",
            "[76]\tvalidation_0-logloss:0.65346\tvalidation_1-logloss:0.66770\n",
            "[77]\tvalidation_0-logloss:0.65310\tvalidation_1-logloss:0.66752\n",
            "[78]\tvalidation_0-logloss:0.65282\tvalidation_1-logloss:0.66738\n",
            "[79]\tvalidation_0-logloss:0.65249\tvalidation_1-logloss:0.66724\n",
            "[80]\tvalidation_0-logloss:0.65214\tvalidation_1-logloss:0.66704\n",
            "[81]\tvalidation_0-logloss:0.65185\tvalidation_1-logloss:0.66692\n",
            "[82]\tvalidation_0-logloss:0.65152\tvalidation_1-logloss:0.66678\n",
            "[83]\tvalidation_0-logloss:0.65119\tvalidation_1-logloss:0.66662\n",
            "[84]\tvalidation_0-logloss:0.65089\tvalidation_1-logloss:0.66648\n",
            "[85]\tvalidation_0-logloss:0.65059\tvalidation_1-logloss:0.66634\n",
            "[86]\tvalidation_0-logloss:0.65026\tvalidation_1-logloss:0.66619\n",
            "[87]\tvalidation_0-logloss:0.64996\tvalidation_1-logloss:0.66607\n",
            "[88]\tvalidation_0-logloss:0.64966\tvalidation_1-logloss:0.66596\n",
            "[89]\tvalidation_0-logloss:0.64937\tvalidation_1-logloss:0.66583\n",
            "[90]\tvalidation_0-logloss:0.64906\tvalidation_1-logloss:0.66569\n",
            "[91]\tvalidation_0-logloss:0.64876\tvalidation_1-logloss:0.66553\n",
            "[92]\tvalidation_0-logloss:0.64847\tvalidation_1-logloss:0.66542\n",
            "[93]\tvalidation_0-logloss:0.64817\tvalidation_1-logloss:0.66528\n",
            "[94]\tvalidation_0-logloss:0.64789\tvalidation_1-logloss:0.66514\n",
            "[95]\tvalidation_0-logloss:0.64761\tvalidation_1-logloss:0.66499\n",
            "[96]\tvalidation_0-logloss:0.64732\tvalidation_1-logloss:0.66487\n",
            "[97]\tvalidation_0-logloss:0.64702\tvalidation_1-logloss:0.66476\n",
            "[98]\tvalidation_0-logloss:0.64676\tvalidation_1-logloss:0.66466\n",
            "[99]\tvalidation_0-logloss:0.64649\tvalidation_1-logloss:0.66454\n",
            "[100]\tvalidation_0-logloss:0.64622\tvalidation_1-logloss:0.66440\n",
            "[101]\tvalidation_0-logloss:0.64592\tvalidation_1-logloss:0.66429\n",
            "[102]\tvalidation_0-logloss:0.64567\tvalidation_1-logloss:0.66417\n",
            "[103]\tvalidation_0-logloss:0.64539\tvalidation_1-logloss:0.66403\n",
            "[104]\tvalidation_0-logloss:0.64511\tvalidation_1-logloss:0.66396\n",
            "[105]\tvalidation_0-logloss:0.64487\tvalidation_1-logloss:0.66387\n",
            "[106]\tvalidation_0-logloss:0.64462\tvalidation_1-logloss:0.66377\n",
            "[107]\tvalidation_0-logloss:0.64434\tvalidation_1-logloss:0.66368\n",
            "[108]\tvalidation_0-logloss:0.64405\tvalidation_1-logloss:0.66357\n",
            "[109]\tvalidation_0-logloss:0.64377\tvalidation_1-logloss:0.66349\n",
            "[110]\tvalidation_0-logloss:0.64353\tvalidation_1-logloss:0.66340\n",
            "[111]\tvalidation_0-logloss:0.64329\tvalidation_1-logloss:0.66332\n",
            "[112]\tvalidation_0-logloss:0.64304\tvalidation_1-logloss:0.66325\n",
            "[113]\tvalidation_0-logloss:0.64277\tvalidation_1-logloss:0.66316\n",
            "[114]\tvalidation_0-logloss:0.64251\tvalidation_1-logloss:0.66309\n",
            "[115]\tvalidation_0-logloss:0.64225\tvalidation_1-logloss:0.66298\n",
            "[116]\tvalidation_0-logloss:0.64197\tvalidation_1-logloss:0.66284\n",
            "[117]\tvalidation_0-logloss:0.64171\tvalidation_1-logloss:0.66274\n",
            "[118]\tvalidation_0-logloss:0.64145\tvalidation_1-logloss:0.66260\n",
            "[119]\tvalidation_0-logloss:0.64119\tvalidation_1-logloss:0.66250\n",
            "[120]\tvalidation_0-logloss:0.64092\tvalidation_1-logloss:0.66241\n",
            "[121]\tvalidation_0-logloss:0.64066\tvalidation_1-logloss:0.66233\n",
            "[122]\tvalidation_0-logloss:0.64043\tvalidation_1-logloss:0.66227\n",
            "[123]\tvalidation_0-logloss:0.64018\tvalidation_1-logloss:0.66214\n",
            "[124]\tvalidation_0-logloss:0.63995\tvalidation_1-logloss:0.66209\n",
            "[125]\tvalidation_0-logloss:0.63970\tvalidation_1-logloss:0.66202\n",
            "[126]\tvalidation_0-logloss:0.63943\tvalidation_1-logloss:0.66195\n",
            "[127]\tvalidation_0-logloss:0.63920\tvalidation_1-logloss:0.66183\n",
            "[128]\tvalidation_0-logloss:0.63893\tvalidation_1-logloss:0.66176\n",
            "[129]\tvalidation_0-logloss:0.63868\tvalidation_1-logloss:0.66167\n",
            "[130]\tvalidation_0-logloss:0.63843\tvalidation_1-logloss:0.66161\n",
            "[131]\tvalidation_0-logloss:0.63820\tvalidation_1-logloss:0.66153\n",
            "[132]\tvalidation_0-logloss:0.63795\tvalidation_1-logloss:0.66145\n",
            "[133]\tvalidation_0-logloss:0.63771\tvalidation_1-logloss:0.66138\n",
            "[134]\tvalidation_0-logloss:0.63746\tvalidation_1-logloss:0.66131\n",
            "[135]\tvalidation_0-logloss:0.63723\tvalidation_1-logloss:0.66126\n",
            "[136]\tvalidation_0-logloss:0.63701\tvalidation_1-logloss:0.66117\n",
            "[137]\tvalidation_0-logloss:0.63679\tvalidation_1-logloss:0.66110\n",
            "[138]\tvalidation_0-logloss:0.63655\tvalidation_1-logloss:0.66104\n",
            "[139]\tvalidation_0-logloss:0.63631\tvalidation_1-logloss:0.66097\n",
            "[140]\tvalidation_0-logloss:0.63609\tvalidation_1-logloss:0.66092\n",
            "[141]\tvalidation_0-logloss:0.63587\tvalidation_1-logloss:0.66086\n",
            "[142]\tvalidation_0-logloss:0.63564\tvalidation_1-logloss:0.66080\n",
            "[143]\tvalidation_0-logloss:0.63542\tvalidation_1-logloss:0.66073\n",
            "[144]\tvalidation_0-logloss:0.63521\tvalidation_1-logloss:0.66068\n",
            "[145]\tvalidation_0-logloss:0.63499\tvalidation_1-logloss:0.66061\n",
            "[146]\tvalidation_0-logloss:0.63477\tvalidation_1-logloss:0.66056\n",
            "[147]\tvalidation_0-logloss:0.63453\tvalidation_1-logloss:0.66050\n",
            "[148]\tvalidation_0-logloss:0.63432\tvalidation_1-logloss:0.66045\n",
            "[149]\tvalidation_0-logloss:0.63410\tvalidation_1-logloss:0.66039\n",
            "[150]\tvalidation_0-logloss:0.63388\tvalidation_1-logloss:0.66035\n",
            "[151]\tvalidation_0-logloss:0.63368\tvalidation_1-logloss:0.66029\n",
            "[152]\tvalidation_0-logloss:0.63344\tvalidation_1-logloss:0.66020\n",
            "[153]\tvalidation_0-logloss:0.63323\tvalidation_1-logloss:0.66013\n",
            "[154]\tvalidation_0-logloss:0.63300\tvalidation_1-logloss:0.66007\n",
            "[155]\tvalidation_0-logloss:0.63279\tvalidation_1-logloss:0.66003\n",
            "[156]\tvalidation_0-logloss:0.63256\tvalidation_1-logloss:0.65997\n",
            "[157]\tvalidation_0-logloss:0.63235\tvalidation_1-logloss:0.65992\n",
            "[158]\tvalidation_0-logloss:0.63217\tvalidation_1-logloss:0.65986\n",
            "[159]\tvalidation_0-logloss:0.63194\tvalidation_1-logloss:0.65980\n",
            "[160]\tvalidation_0-logloss:0.63174\tvalidation_1-logloss:0.65976\n",
            "[161]\tvalidation_0-logloss:0.63152\tvalidation_1-logloss:0.65969\n",
            "[162]\tvalidation_0-logloss:0.63131\tvalidation_1-logloss:0.65963\n",
            "[163]\tvalidation_0-logloss:0.63109\tvalidation_1-logloss:0.65957\n",
            "[164]\tvalidation_0-logloss:0.63090\tvalidation_1-logloss:0.65954\n",
            "[165]\tvalidation_0-logloss:0.63072\tvalidation_1-logloss:0.65952\n",
            "[166]\tvalidation_0-logloss:0.63050\tvalidation_1-logloss:0.65943\n",
            "[167]\tvalidation_0-logloss:0.63029\tvalidation_1-logloss:0.65938\n",
            "[168]\tvalidation_0-logloss:0.63009\tvalidation_1-logloss:0.65933\n",
            "[169]\tvalidation_0-logloss:0.62988\tvalidation_1-logloss:0.65925\n",
            "[170]\tvalidation_0-logloss:0.62970\tvalidation_1-logloss:0.65923\n",
            "[171]\tvalidation_0-logloss:0.62949\tvalidation_1-logloss:0.65917\n",
            "[172]\tvalidation_0-logloss:0.62929\tvalidation_1-logloss:0.65910\n",
            "[173]\tvalidation_0-logloss:0.62910\tvalidation_1-logloss:0.65905\n",
            "[174]\tvalidation_0-logloss:0.62890\tvalidation_1-logloss:0.65899\n",
            "[175]\tvalidation_0-logloss:0.62870\tvalidation_1-logloss:0.65893\n",
            "[176]\tvalidation_0-logloss:0.62850\tvalidation_1-logloss:0.65887\n",
            "[177]\tvalidation_0-logloss:0.62830\tvalidation_1-logloss:0.65885\n",
            "[178]\tvalidation_0-logloss:0.62811\tvalidation_1-logloss:0.65880\n",
            "[179]\tvalidation_0-logloss:0.62791\tvalidation_1-logloss:0.65874\n",
            "[180]\tvalidation_0-logloss:0.62771\tvalidation_1-logloss:0.65872\n",
            "[181]\tvalidation_0-logloss:0.62753\tvalidation_1-logloss:0.65866\n",
            "[182]\tvalidation_0-logloss:0.62735\tvalidation_1-logloss:0.65861\n",
            "[183]\tvalidation_0-logloss:0.62712\tvalidation_1-logloss:0.65855\n",
            "[184]\tvalidation_0-logloss:0.62694\tvalidation_1-logloss:0.65853\n",
            "[185]\tvalidation_0-logloss:0.62676\tvalidation_1-logloss:0.65846\n",
            "[186]\tvalidation_0-logloss:0.62657\tvalidation_1-logloss:0.65842\n",
            "[187]\tvalidation_0-logloss:0.62640\tvalidation_1-logloss:0.65834\n",
            "[188]\tvalidation_0-logloss:0.62618\tvalidation_1-logloss:0.65834\n",
            "[189]\tvalidation_0-logloss:0.62600\tvalidation_1-logloss:0.65829\n",
            "[190]\tvalidation_0-logloss:0.62583\tvalidation_1-logloss:0.65826\n",
            "[191]\tvalidation_0-logloss:0.62565\tvalidation_1-logloss:0.65820\n",
            "[192]\tvalidation_0-logloss:0.62544\tvalidation_1-logloss:0.65820\n",
            "[193]\tvalidation_0-logloss:0.62525\tvalidation_1-logloss:0.65814\n",
            "[194]\tvalidation_0-logloss:0.62509\tvalidation_1-logloss:0.65809\n",
            "[195]\tvalidation_0-logloss:0.62488\tvalidation_1-logloss:0.65803\n",
            "[196]\tvalidation_0-logloss:0.62469\tvalidation_1-logloss:0.65796\n",
            "[197]\tvalidation_0-logloss:0.62453\tvalidation_1-logloss:0.65790\n",
            "[198]\tvalidation_0-logloss:0.62433\tvalidation_1-logloss:0.65785\n",
            "[199]\tvalidation_0-logloss:0.62416\tvalidation_1-logloss:0.65781\n",
            "[200]\tvalidation_0-logloss:0.62398\tvalidation_1-logloss:0.65776\n",
            "[201]\tvalidation_0-logloss:0.62381\tvalidation_1-logloss:0.65771\n",
            "[202]\tvalidation_0-logloss:0.62365\tvalidation_1-logloss:0.65765\n",
            "[203]\tvalidation_0-logloss:0.62348\tvalidation_1-logloss:0.65761\n",
            "[204]\tvalidation_0-logloss:0.62329\tvalidation_1-logloss:0.65760\n",
            "[205]\tvalidation_0-logloss:0.62313\tvalidation_1-logloss:0.65755\n",
            "[206]\tvalidation_0-logloss:0.62294\tvalidation_1-logloss:0.65750\n",
            "[207]\tvalidation_0-logloss:0.62277\tvalidation_1-logloss:0.65747\n",
            "[208]\tvalidation_0-logloss:0.62257\tvalidation_1-logloss:0.65742\n",
            "[209]\tvalidation_0-logloss:0.62239\tvalidation_1-logloss:0.65742\n",
            "[210]\tvalidation_0-logloss:0.62223\tvalidation_1-logloss:0.65739\n",
            "[211]\tvalidation_0-logloss:0.62204\tvalidation_1-logloss:0.65735\n",
            "[212]\tvalidation_0-logloss:0.62186\tvalidation_1-logloss:0.65734\n",
            "[213]\tvalidation_0-logloss:0.62169\tvalidation_1-logloss:0.65729\n",
            "[214]\tvalidation_0-logloss:0.62150\tvalidation_1-logloss:0.65726\n",
            "[215]\tvalidation_0-logloss:0.62135\tvalidation_1-logloss:0.65721\n",
            "[216]\tvalidation_0-logloss:0.62116\tvalidation_1-logloss:0.65717\n",
            "[217]\tvalidation_0-logloss:0.62100\tvalidation_1-logloss:0.65715\n",
            "[218]\tvalidation_0-logloss:0.62079\tvalidation_1-logloss:0.65708\n",
            "[219]\tvalidation_0-logloss:0.62061\tvalidation_1-logloss:0.65706\n",
            "[220]\tvalidation_0-logloss:0.62047\tvalidation_1-logloss:0.65703\n",
            "[221]\tvalidation_0-logloss:0.62029\tvalidation_1-logloss:0.65698\n",
            "[222]\tvalidation_0-logloss:0.62009\tvalidation_1-logloss:0.65693\n",
            "[223]\tvalidation_0-logloss:0.61995\tvalidation_1-logloss:0.65689\n",
            "[224]\tvalidation_0-logloss:0.61977\tvalidation_1-logloss:0.65684\n",
            "[225]\tvalidation_0-logloss:0.61958\tvalidation_1-logloss:0.65678\n",
            "[226]\tvalidation_0-logloss:0.61943\tvalidation_1-logloss:0.65673\n",
            "[227]\tvalidation_0-logloss:0.61922\tvalidation_1-logloss:0.65667\n",
            "[228]\tvalidation_0-logloss:0.61908\tvalidation_1-logloss:0.65664\n",
            "[229]\tvalidation_0-logloss:0.61890\tvalidation_1-logloss:0.65657\n",
            "[230]\tvalidation_0-logloss:0.61875\tvalidation_1-logloss:0.65652\n",
            "[231]\tvalidation_0-logloss:0.61861\tvalidation_1-logloss:0.65651\n",
            "[232]\tvalidation_0-logloss:0.61843\tvalidation_1-logloss:0.65645\n",
            "[233]\tvalidation_0-logloss:0.61828\tvalidation_1-logloss:0.65640\n",
            "[234]\tvalidation_0-logloss:0.61810\tvalidation_1-logloss:0.65639\n",
            "[235]\tvalidation_0-logloss:0.61793\tvalidation_1-logloss:0.65633\n",
            "[236]\tvalidation_0-logloss:0.61780\tvalidation_1-logloss:0.65629\n",
            "[237]\tvalidation_0-logloss:0.61762\tvalidation_1-logloss:0.65623\n",
            "[238]\tvalidation_0-logloss:0.61747\tvalidation_1-logloss:0.65616\n",
            "[239]\tvalidation_0-logloss:0.61731\tvalidation_1-logloss:0.65614\n",
            "[240]\tvalidation_0-logloss:0.61717\tvalidation_1-logloss:0.65609\n",
            "[241]\tvalidation_0-logloss:0.61698\tvalidation_1-logloss:0.65605\n",
            "[242]\tvalidation_0-logloss:0.61681\tvalidation_1-logloss:0.65597\n",
            "[243]\tvalidation_0-logloss:0.61668\tvalidation_1-logloss:0.65594\n",
            "[244]\tvalidation_0-logloss:0.61652\tvalidation_1-logloss:0.65589\n",
            "[245]\tvalidation_0-logloss:0.61639\tvalidation_1-logloss:0.65584\n",
            "[246]\tvalidation_0-logloss:0.61619\tvalidation_1-logloss:0.65580\n",
            "[247]\tvalidation_0-logloss:0.61606\tvalidation_1-logloss:0.65575\n",
            "[248]\tvalidation_0-logloss:0.61592\tvalidation_1-logloss:0.65570\n",
            "[249]\tvalidation_0-logloss:0.61577\tvalidation_1-logloss:0.65563\n",
            "[250]\tvalidation_0-logloss:0.61565\tvalidation_1-logloss:0.65562\n",
            "[251]\tvalidation_0-logloss:0.61551\tvalidation_1-logloss:0.65557\n",
            "[252]\tvalidation_0-logloss:0.61532\tvalidation_1-logloss:0.65554\n",
            "[253]\tvalidation_0-logloss:0.61520\tvalidation_1-logloss:0.65551\n",
            "[254]\tvalidation_0-logloss:0.61506\tvalidation_1-logloss:0.65548\n",
            "[255]\tvalidation_0-logloss:0.61492\tvalidation_1-logloss:0.65544\n",
            "[256]\tvalidation_0-logloss:0.61477\tvalidation_1-logloss:0.65539\n",
            "[257]\tvalidation_0-logloss:0.61464\tvalidation_1-logloss:0.65537\n",
            "[258]\tvalidation_0-logloss:0.61445\tvalidation_1-logloss:0.65535\n",
            "[259]\tvalidation_0-logloss:0.61432\tvalidation_1-logloss:0.65531\n",
            "[260]\tvalidation_0-logloss:0.61417\tvalidation_1-logloss:0.65526\n",
            "[261]\tvalidation_0-logloss:0.61402\tvalidation_1-logloss:0.65519\n",
            "[262]\tvalidation_0-logloss:0.61387\tvalidation_1-logloss:0.65513\n",
            "[263]\tvalidation_0-logloss:0.61368\tvalidation_1-logloss:0.65511\n",
            "[264]\tvalidation_0-logloss:0.61351\tvalidation_1-logloss:0.65506\n",
            "[265]\tvalidation_0-logloss:0.61339\tvalidation_1-logloss:0.65503\n",
            "[266]\tvalidation_0-logloss:0.61328\tvalidation_1-logloss:0.65499\n",
            "[267]\tvalidation_0-logloss:0.61311\tvalidation_1-logloss:0.65495\n",
            "[268]\tvalidation_0-logloss:0.61297\tvalidation_1-logloss:0.65491\n",
            "[269]\tvalidation_0-logloss:0.61281\tvalidation_1-logloss:0.65486\n",
            "[270]\tvalidation_0-logloss:0.61266\tvalidation_1-logloss:0.65483\n",
            "[271]\tvalidation_0-logloss:0.61252\tvalidation_1-logloss:0.65480\n",
            "[272]\tvalidation_0-logloss:0.61236\tvalidation_1-logloss:0.65476\n",
            "[273]\tvalidation_0-logloss:0.61218\tvalidation_1-logloss:0.65473\n",
            "[274]\tvalidation_0-logloss:0.61206\tvalidation_1-logloss:0.65470\n",
            "[275]\tvalidation_0-logloss:0.61191\tvalidation_1-logloss:0.65466\n",
            "[276]\tvalidation_0-logloss:0.61176\tvalidation_1-logloss:0.65463\n",
            "[277]\tvalidation_0-logloss:0.61163\tvalidation_1-logloss:0.65461\n",
            "[278]\tvalidation_0-logloss:0.61152\tvalidation_1-logloss:0.65457\n",
            "[279]\tvalidation_0-logloss:0.61138\tvalidation_1-logloss:0.65454\n",
            "[280]\tvalidation_0-logloss:0.61123\tvalidation_1-logloss:0.65453\n",
            "[281]\tvalidation_0-logloss:0.61109\tvalidation_1-logloss:0.65449\n",
            "[282]\tvalidation_0-logloss:0.61092\tvalidation_1-logloss:0.65446\n",
            "[283]\tvalidation_0-logloss:0.61081\tvalidation_1-logloss:0.65442\n",
            "[284]\tvalidation_0-logloss:0.61069\tvalidation_1-logloss:0.65440\n",
            "[285]\tvalidation_0-logloss:0.61055\tvalidation_1-logloss:0.65439\n",
            "[286]\tvalidation_0-logloss:0.61040\tvalidation_1-logloss:0.65435\n",
            "[287]\tvalidation_0-logloss:0.61024\tvalidation_1-logloss:0.65433\n",
            "[288]\tvalidation_0-logloss:0.61010\tvalidation_1-logloss:0.65432\n",
            "[289]\tvalidation_0-logloss:0.60999\tvalidation_1-logloss:0.65429\n",
            "[290]\tvalidation_0-logloss:0.60983\tvalidation_1-logloss:0.65428\n",
            "[291]\tvalidation_0-logloss:0.60971\tvalidation_1-logloss:0.65425\n",
            "[292]\tvalidation_0-logloss:0.60955\tvalidation_1-logloss:0.65423\n",
            "[293]\tvalidation_0-logloss:0.60943\tvalidation_1-logloss:0.65422\n",
            "[294]\tvalidation_0-logloss:0.60927\tvalidation_1-logloss:0.65420\n",
            "[295]\tvalidation_0-logloss:0.60914\tvalidation_1-logloss:0.65420\n",
            "[296]\tvalidation_0-logloss:0.60897\tvalidation_1-logloss:0.65417\n",
            "[297]\tvalidation_0-logloss:0.60882\tvalidation_1-logloss:0.65414\n",
            "[298]\tvalidation_0-logloss:0.60866\tvalidation_1-logloss:0.65411\n",
            "[299]\tvalidation_0-logloss:0.60852\tvalidation_1-logloss:0.65407\n",
            "[300]\tvalidation_0-logloss:0.60836\tvalidation_1-logloss:0.65405\n",
            "[301]\tvalidation_0-logloss:0.60820\tvalidation_1-logloss:0.65402\n",
            "[302]\tvalidation_0-logloss:0.60807\tvalidation_1-logloss:0.65400\n",
            "[303]\tvalidation_0-logloss:0.60793\tvalidation_1-logloss:0.65397\n",
            "[304]\tvalidation_0-logloss:0.60781\tvalidation_1-logloss:0.65393\n",
            "[305]\tvalidation_0-logloss:0.60764\tvalidation_1-logloss:0.65389\n",
            "[306]\tvalidation_0-logloss:0.60750\tvalidation_1-logloss:0.65386\n",
            "[307]\tvalidation_0-logloss:0.60737\tvalidation_1-logloss:0.65385\n",
            "[308]\tvalidation_0-logloss:0.60724\tvalidation_1-logloss:0.65383\n",
            "[309]\tvalidation_0-logloss:0.60709\tvalidation_1-logloss:0.65381\n",
            "[310]\tvalidation_0-logloss:0.60692\tvalidation_1-logloss:0.65379\n",
            "[311]\tvalidation_0-logloss:0.60679\tvalidation_1-logloss:0.65378\n",
            "[312]\tvalidation_0-logloss:0.60664\tvalidation_1-logloss:0.65376\n",
            "[313]\tvalidation_0-logloss:0.60651\tvalidation_1-logloss:0.65374\n",
            "[314]\tvalidation_0-logloss:0.60639\tvalidation_1-logloss:0.65374\n",
            "[315]\tvalidation_0-logloss:0.60627\tvalidation_1-logloss:0.65372\n",
            "[316]\tvalidation_0-logloss:0.60612\tvalidation_1-logloss:0.65370\n",
            "[317]\tvalidation_0-logloss:0.60600\tvalidation_1-logloss:0.65370\n",
            "[318]\tvalidation_0-logloss:0.60585\tvalidation_1-logloss:0.65367\n",
            "[319]\tvalidation_0-logloss:0.60573\tvalidation_1-logloss:0.65367\n",
            "[320]\tvalidation_0-logloss:0.60559\tvalidation_1-logloss:0.65364\n",
            "[321]\tvalidation_0-logloss:0.60543\tvalidation_1-logloss:0.65361\n",
            "[322]\tvalidation_0-logloss:0.60529\tvalidation_1-logloss:0.65359\n",
            "[323]\tvalidation_0-logloss:0.60516\tvalidation_1-logloss:0.65355\n",
            "[324]\tvalidation_0-logloss:0.60501\tvalidation_1-logloss:0.65351\n",
            "[325]\tvalidation_0-logloss:0.60487\tvalidation_1-logloss:0.65350\n",
            "[326]\tvalidation_0-logloss:0.60474\tvalidation_1-logloss:0.65347\n",
            "[327]\tvalidation_0-logloss:0.60460\tvalidation_1-logloss:0.65345\n",
            "[328]\tvalidation_0-logloss:0.60448\tvalidation_1-logloss:0.65344\n",
            "[329]\tvalidation_0-logloss:0.60434\tvalidation_1-logloss:0.65342\n",
            "[330]\tvalidation_0-logloss:0.60421\tvalidation_1-logloss:0.65340\n",
            "[331]\tvalidation_0-logloss:0.60410\tvalidation_1-logloss:0.65340\n",
            "[332]\tvalidation_0-logloss:0.60392\tvalidation_1-logloss:0.65338\n",
            "[333]\tvalidation_0-logloss:0.60374\tvalidation_1-logloss:0.65336\n",
            "[334]\tvalidation_0-logloss:0.60363\tvalidation_1-logloss:0.65334\n",
            "[335]\tvalidation_0-logloss:0.60346\tvalidation_1-logloss:0.65333\n",
            "[336]\tvalidation_0-logloss:0.60335\tvalidation_1-logloss:0.65331\n",
            "[337]\tvalidation_0-logloss:0.60317\tvalidation_1-logloss:0.65329\n",
            "[338]\tvalidation_0-logloss:0.60307\tvalidation_1-logloss:0.65327\n",
            "[339]\tvalidation_0-logloss:0.60291\tvalidation_1-logloss:0.65325\n",
            "[340]\tvalidation_0-logloss:0.60275\tvalidation_1-logloss:0.65321\n",
            "[341]\tvalidation_0-logloss:0.60260\tvalidation_1-logloss:0.65319\n",
            "[342]\tvalidation_0-logloss:0.60245\tvalidation_1-logloss:0.65316\n",
            "[343]\tvalidation_0-logloss:0.60232\tvalidation_1-logloss:0.65314\n",
            "[344]\tvalidation_0-logloss:0.60216\tvalidation_1-logloss:0.65312\n",
            "[345]\tvalidation_0-logloss:0.60201\tvalidation_1-logloss:0.65308\n",
            "[346]\tvalidation_0-logloss:0.60186\tvalidation_1-logloss:0.65304\n",
            "[347]\tvalidation_0-logloss:0.60170\tvalidation_1-logloss:0.65301\n",
            "[348]\tvalidation_0-logloss:0.60155\tvalidation_1-logloss:0.65298\n",
            "[349]\tvalidation_0-logloss:0.60140\tvalidation_1-logloss:0.65294\n",
            "[350]\tvalidation_0-logloss:0.60129\tvalidation_1-logloss:0.65294\n",
            "[351]\tvalidation_0-logloss:0.60115\tvalidation_1-logloss:0.65291\n",
            "[352]\tvalidation_0-logloss:0.60101\tvalidation_1-logloss:0.65288\n",
            "[353]\tvalidation_0-logloss:0.60085\tvalidation_1-logloss:0.65286\n",
            "[354]\tvalidation_0-logloss:0.60075\tvalidation_1-logloss:0.65286\n",
            "[355]\tvalidation_0-logloss:0.60060\tvalidation_1-logloss:0.65284\n",
            "[356]\tvalidation_0-logloss:0.60046\tvalidation_1-logloss:0.65281\n",
            "[357]\tvalidation_0-logloss:0.60032\tvalidation_1-logloss:0.65279\n",
            "[358]\tvalidation_0-logloss:0.60016\tvalidation_1-logloss:0.65277\n",
            "[359]\tvalidation_0-logloss:0.60005\tvalidation_1-logloss:0.65275\n",
            "[360]\tvalidation_0-logloss:0.59991\tvalidation_1-logloss:0.65273\n",
            "[361]\tvalidation_0-logloss:0.59977\tvalidation_1-logloss:0.65271\n",
            "[362]\tvalidation_0-logloss:0.59963\tvalidation_1-logloss:0.65269\n",
            "[363]\tvalidation_0-logloss:0.59949\tvalidation_1-logloss:0.65266\n",
            "[364]\tvalidation_0-logloss:0.59935\tvalidation_1-logloss:0.65264\n",
            "[365]\tvalidation_0-logloss:0.59924\tvalidation_1-logloss:0.65259\n",
            "[366]\tvalidation_0-logloss:0.59909\tvalidation_1-logloss:0.65257\n",
            "[367]\tvalidation_0-logloss:0.59898\tvalidation_1-logloss:0.65257\n",
            "[368]\tvalidation_0-logloss:0.59884\tvalidation_1-logloss:0.65257\n",
            "[369]\tvalidation_0-logloss:0.59864\tvalidation_1-logloss:0.65249\n",
            "[370]\tvalidation_0-logloss:0.59852\tvalidation_1-logloss:0.65248\n",
            "[371]\tvalidation_0-logloss:0.59832\tvalidation_1-logloss:0.65240\n",
            "[372]\tvalidation_0-logloss:0.59820\tvalidation_1-logloss:0.65240\n",
            "[373]\tvalidation_0-logloss:0.59799\tvalidation_1-logloss:0.65232\n",
            "[374]\tvalidation_0-logloss:0.59787\tvalidation_1-logloss:0.65230\n",
            "[375]\tvalidation_0-logloss:0.59767\tvalidation_1-logloss:0.65224\n",
            "[376]\tvalidation_0-logloss:0.59755\tvalidation_1-logloss:0.65221\n",
            "[377]\tvalidation_0-logloss:0.59743\tvalidation_1-logloss:0.65221\n",
            "[378]\tvalidation_0-logloss:0.59724\tvalidation_1-logloss:0.65215\n",
            "[379]\tvalidation_0-logloss:0.59713\tvalidation_1-logloss:0.65215\n",
            "[380]\tvalidation_0-logloss:0.59699\tvalidation_1-logloss:0.65214\n",
            "[381]\tvalidation_0-logloss:0.59687\tvalidation_1-logloss:0.65213\n",
            "[382]\tvalidation_0-logloss:0.59668\tvalidation_1-logloss:0.65205\n",
            "[383]\tvalidation_0-logloss:0.59657\tvalidation_1-logloss:0.65205\n",
            "[384]\tvalidation_0-logloss:0.59646\tvalidation_1-logloss:0.65205\n",
            "[385]\tvalidation_0-logloss:0.59628\tvalidation_1-logloss:0.65199\n",
            "[386]\tvalidation_0-logloss:0.59613\tvalidation_1-logloss:0.65197\n",
            "[387]\tvalidation_0-logloss:0.59602\tvalidation_1-logloss:0.65197\n",
            "[388]\tvalidation_0-logloss:0.59587\tvalidation_1-logloss:0.65195\n",
            "[389]\tvalidation_0-logloss:0.59573\tvalidation_1-logloss:0.65192\n",
            "[390]\tvalidation_0-logloss:0.59559\tvalidation_1-logloss:0.65191\n",
            "[391]\tvalidation_0-logloss:0.59549\tvalidation_1-logloss:0.65191\n",
            "[392]\tvalidation_0-logloss:0.59540\tvalidation_1-logloss:0.65189\n",
            "[393]\tvalidation_0-logloss:0.59531\tvalidation_1-logloss:0.65190\n",
            "[394]\tvalidation_0-logloss:0.59520\tvalidation_1-logloss:0.65189\n",
            "[395]\tvalidation_0-logloss:0.59502\tvalidation_1-logloss:0.65183\n",
            "[396]\tvalidation_0-logloss:0.59493\tvalidation_1-logloss:0.65183\n",
            "[397]\tvalidation_0-logloss:0.59478\tvalidation_1-logloss:0.65181\n",
            "[398]\tvalidation_0-logloss:0.59467\tvalidation_1-logloss:0.65179\n",
            "[399]\tvalidation_0-logloss:0.59453\tvalidation_1-logloss:0.65179\n",
            "[400]\tvalidation_0-logloss:0.59434\tvalidation_1-logloss:0.65174\n",
            "[401]\tvalidation_0-logloss:0.59421\tvalidation_1-logloss:0.65171\n",
            "[402]\tvalidation_0-logloss:0.59412\tvalidation_1-logloss:0.65171\n",
            "[403]\tvalidation_0-logloss:0.59393\tvalidation_1-logloss:0.65166\n",
            "[404]\tvalidation_0-logloss:0.59384\tvalidation_1-logloss:0.65168\n",
            "[405]\tvalidation_0-logloss:0.59370\tvalidation_1-logloss:0.65167\n",
            "[406]\tvalidation_0-logloss:0.59353\tvalidation_1-logloss:0.65163\n",
            "[407]\tvalidation_0-logloss:0.59340\tvalidation_1-logloss:0.65161\n",
            "[408]\tvalidation_0-logloss:0.59331\tvalidation_1-logloss:0.65162\n",
            "[409]\tvalidation_0-logloss:0.59322\tvalidation_1-logloss:0.65163\n",
            "[410]\tvalidation_0-logloss:0.59305\tvalidation_1-logloss:0.65159\n",
            "[411]\tvalidation_0-logloss:0.59296\tvalidation_1-logloss:0.65160\n",
            "[412]\tvalidation_0-logloss:0.59285\tvalidation_1-logloss:0.65158\n",
            "[413]\tvalidation_0-logloss:0.59276\tvalidation_1-logloss:0.65159\n",
            "[414]\tvalidation_0-logloss:0.59266\tvalidation_1-logloss:0.65157\n",
            "[415]\tvalidation_0-logloss:0.59257\tvalidation_1-logloss:0.65160\n",
            "[416]\tvalidation_0-logloss:0.59239\tvalidation_1-logloss:0.65157\n",
            "[417]\tvalidation_0-logloss:0.59231\tvalidation_1-logloss:0.65157\n",
            "[418]\tvalidation_0-logloss:0.59218\tvalidation_1-logloss:0.65154\n",
            "[419]\tvalidation_0-logloss:0.59203\tvalidation_1-logloss:0.65152\n",
            "[420]\tvalidation_0-logloss:0.59193\tvalidation_1-logloss:0.65152\n",
            "[421]\tvalidation_0-logloss:0.59181\tvalidation_1-logloss:0.65150\n",
            "[422]\tvalidation_0-logloss:0.59172\tvalidation_1-logloss:0.65150\n",
            "[423]\tvalidation_0-logloss:0.59160\tvalidation_1-logloss:0.65147\n",
            "[424]\tvalidation_0-logloss:0.59150\tvalidation_1-logloss:0.65147\n",
            "[425]\tvalidation_0-logloss:0.59135\tvalidation_1-logloss:0.65144\n",
            "[426]\tvalidation_0-logloss:0.59122\tvalidation_1-logloss:0.65143\n",
            "[427]\tvalidation_0-logloss:0.59111\tvalidation_1-logloss:0.65140\n",
            "[428]\tvalidation_0-logloss:0.59099\tvalidation_1-logloss:0.65138\n",
            "[429]\tvalidation_0-logloss:0.59087\tvalidation_1-logloss:0.65138\n",
            "[430]\tvalidation_0-logloss:0.59070\tvalidation_1-logloss:0.65135\n",
            "[431]\tvalidation_0-logloss:0.59059\tvalidation_1-logloss:0.65132\n",
            "[432]\tvalidation_0-logloss:0.59043\tvalidation_1-logloss:0.65128\n",
            "[433]\tvalidation_0-logloss:0.59033\tvalidation_1-logloss:0.65126\n",
            "[434]\tvalidation_0-logloss:0.59021\tvalidation_1-logloss:0.65124\n",
            "[435]\tvalidation_0-logloss:0.59008\tvalidation_1-logloss:0.65123\n",
            "[436]\tvalidation_0-logloss:0.58995\tvalidation_1-logloss:0.65122\n",
            "[437]\tvalidation_0-logloss:0.58980\tvalidation_1-logloss:0.65117\n",
            "[438]\tvalidation_0-logloss:0.58971\tvalidation_1-logloss:0.65115\n",
            "[439]\tvalidation_0-logloss:0.58956\tvalidation_1-logloss:0.65111\n",
            "[440]\tvalidation_0-logloss:0.58946\tvalidation_1-logloss:0.65109\n",
            "[441]\tvalidation_0-logloss:0.58934\tvalidation_1-logloss:0.65109\n",
            "[442]\tvalidation_0-logloss:0.58919\tvalidation_1-logloss:0.65104\n",
            "[443]\tvalidation_0-logloss:0.58910\tvalidation_1-logloss:0.65103\n",
            "[444]\tvalidation_0-logloss:0.58898\tvalidation_1-logloss:0.65102\n",
            "[445]\tvalidation_0-logloss:0.58886\tvalidation_1-logloss:0.65102\n",
            "[446]\tvalidation_0-logloss:0.58871\tvalidation_1-logloss:0.65096\n",
            "[447]\tvalidation_0-logloss:0.58861\tvalidation_1-logloss:0.65093\n",
            "[448]\tvalidation_0-logloss:0.58847\tvalidation_1-logloss:0.65090\n",
            "[449]\tvalidation_0-logloss:0.58836\tvalidation_1-logloss:0.65090\n",
            "[450]\tvalidation_0-logloss:0.58826\tvalidation_1-logloss:0.65086\n",
            "[451]\tvalidation_0-logloss:0.58817\tvalidation_1-logloss:0.65085\n",
            "[452]\tvalidation_0-logloss:0.58802\tvalidation_1-logloss:0.65088\n",
            "[453]\tvalidation_0-logloss:0.58792\tvalidation_1-logloss:0.65086\n",
            "[454]\tvalidation_0-logloss:0.58784\tvalidation_1-logloss:0.65085\n",
            "[455]\tvalidation_0-logloss:0.58774\tvalidation_1-logloss:0.65080\n",
            "[456]\tvalidation_0-logloss:0.58765\tvalidation_1-logloss:0.65079\n",
            "[457]\tvalidation_0-logloss:0.58756\tvalidation_1-logloss:0.65078\n",
            "[458]\tvalidation_0-logloss:0.58746\tvalidation_1-logloss:0.65074\n",
            "[459]\tvalidation_0-logloss:0.58735\tvalidation_1-logloss:0.65073\n",
            "[460]\tvalidation_0-logloss:0.58726\tvalidation_1-logloss:0.65069\n",
            "[461]\tvalidation_0-logloss:0.58716\tvalidation_1-logloss:0.65068\n",
            "[462]\tvalidation_0-logloss:0.58708\tvalidation_1-logloss:0.65066\n",
            "[463]\tvalidation_0-logloss:0.58694\tvalidation_1-logloss:0.65067\n",
            "[464]\tvalidation_0-logloss:0.58684\tvalidation_1-logloss:0.65061\n",
            "[465]\tvalidation_0-logloss:0.58675\tvalidation_1-logloss:0.65060\n",
            "[466]\tvalidation_0-logloss:0.58666\tvalidation_1-logloss:0.65057\n",
            "[467]\tvalidation_0-logloss:0.58654\tvalidation_1-logloss:0.65056\n",
            "[468]\tvalidation_0-logloss:0.58645\tvalidation_1-logloss:0.65054\n",
            "[469]\tvalidation_0-logloss:0.58637\tvalidation_1-logloss:0.65053\n",
            "[470]\tvalidation_0-logloss:0.58627\tvalidation_1-logloss:0.65049\n",
            "[471]\tvalidation_0-logloss:0.58618\tvalidation_1-logloss:0.65048\n",
            "[472]\tvalidation_0-logloss:0.58606\tvalidation_1-logloss:0.65046\n",
            "[473]\tvalidation_0-logloss:0.58598\tvalidation_1-logloss:0.65045\n",
            "[474]\tvalidation_0-logloss:0.58588\tvalidation_1-logloss:0.65042\n",
            "[475]\tvalidation_0-logloss:0.58580\tvalidation_1-logloss:0.65042\n",
            "[476]\tvalidation_0-logloss:0.58571\tvalidation_1-logloss:0.65041\n",
            "[477]\tvalidation_0-logloss:0.58555\tvalidation_1-logloss:0.65039\n",
            "[478]\tvalidation_0-logloss:0.58547\tvalidation_1-logloss:0.65039\n",
            "[479]\tvalidation_0-logloss:0.58538\tvalidation_1-logloss:0.65039\n",
            "[480]\tvalidation_0-logloss:0.58524\tvalidation_1-logloss:0.65034\n",
            "[481]\tvalidation_0-logloss:0.58515\tvalidation_1-logloss:0.65033\n",
            "[482]\tvalidation_0-logloss:0.58506\tvalidation_1-logloss:0.65032\n",
            "[483]\tvalidation_0-logloss:0.58496\tvalidation_1-logloss:0.65031\n",
            "[484]\tvalidation_0-logloss:0.58489\tvalidation_1-logloss:0.65030\n",
            "[485]\tvalidation_0-logloss:0.58485\tvalidation_1-logloss:0.65029\n",
            "[486]\tvalidation_0-logloss:0.58477\tvalidation_1-logloss:0.65028\n",
            "[487]\tvalidation_0-logloss:0.58468\tvalidation_1-logloss:0.65028\n",
            "[488]\tvalidation_0-logloss:0.58454\tvalidation_1-logloss:0.65027\n",
            "[489]\tvalidation_0-logloss:0.58445\tvalidation_1-logloss:0.65025\n",
            "[490]\tvalidation_0-logloss:0.58436\tvalidation_1-logloss:0.65021\n",
            "[491]\tvalidation_0-logloss:0.58427\tvalidation_1-logloss:0.65020\n",
            "[492]\tvalidation_0-logloss:0.58423\tvalidation_1-logloss:0.65018\n",
            "[493]\tvalidation_0-logloss:0.58414\tvalidation_1-logloss:0.65016\n",
            "[494]\tvalidation_0-logloss:0.58405\tvalidation_1-logloss:0.65015\n",
            "[495]\tvalidation_0-logloss:0.58401\tvalidation_1-logloss:0.65014\n",
            "[496]\tvalidation_0-logloss:0.58386\tvalidation_1-logloss:0.65013\n",
            "[497]\tvalidation_0-logloss:0.58378\tvalidation_1-logloss:0.65010\n",
            "[498]\tvalidation_0-logloss:0.58368\tvalidation_1-logloss:0.65008\n",
            "[499]\tvalidation_0-logloss:0.58359\tvalidation_1-logloss:0.65008\n",
            "[500]\tvalidation_0-logloss:0.58355\tvalidation_1-logloss:0.65007\n",
            "[501]\tvalidation_0-logloss:0.58347\tvalidation_1-logloss:0.65004\n",
            "[502]\tvalidation_0-logloss:0.58332\tvalidation_1-logloss:0.65003\n",
            "[503]\tvalidation_0-logloss:0.58320\tvalidation_1-logloss:0.65000\n",
            "[504]\tvalidation_0-logloss:0.58311\tvalidation_1-logloss:0.64999\n",
            "[505]\tvalidation_0-logloss:0.58308\tvalidation_1-logloss:0.64998\n",
            "[506]\tvalidation_0-logloss:0.58300\tvalidation_1-logloss:0.64996\n",
            "[507]\tvalidation_0-logloss:0.58292\tvalidation_1-logloss:0.64995\n",
            "[508]\tvalidation_0-logloss:0.58289\tvalidation_1-logloss:0.64994\n",
            "[509]\tvalidation_0-logloss:0.58280\tvalidation_1-logloss:0.64994\n",
            "[510]\tvalidation_0-logloss:0.58268\tvalidation_1-logloss:0.64991\n",
            "[511]\tvalidation_0-logloss:0.58259\tvalidation_1-logloss:0.64989\n",
            "[512]\tvalidation_0-logloss:0.58256\tvalidation_1-logloss:0.64988\n",
            "[513]\tvalidation_0-logloss:0.58245\tvalidation_1-logloss:0.64987\n",
            "[514]\tvalidation_0-logloss:0.58233\tvalidation_1-logloss:0.64986\n",
            "[515]\tvalidation_0-logloss:0.58221\tvalidation_1-logloss:0.64985\n",
            "[516]\tvalidation_0-logloss:0.58218\tvalidation_1-logloss:0.64985\n",
            "[517]\tvalidation_0-logloss:0.58209\tvalidation_1-logloss:0.64982\n",
            "[518]\tvalidation_0-logloss:0.58198\tvalidation_1-logloss:0.64980\n",
            "[519]\tvalidation_0-logloss:0.58193\tvalidation_1-logloss:0.64981\n",
            "[520]\tvalidation_0-logloss:0.58180\tvalidation_1-logloss:0.64980\n",
            "[521]\tvalidation_0-logloss:0.58173\tvalidation_1-logloss:0.64978\n",
            "[522]\tvalidation_0-logloss:0.58162\tvalidation_1-logloss:0.64978\n",
            "[523]\tvalidation_0-logloss:0.58150\tvalidation_1-logloss:0.64978\n",
            "[524]\tvalidation_0-logloss:0.58138\tvalidation_1-logloss:0.64977\n",
            "[525]\tvalidation_0-logloss:0.58135\tvalidation_1-logloss:0.64976\n",
            "[526]\tvalidation_0-logloss:0.58129\tvalidation_1-logloss:0.64975\n",
            "[527]\tvalidation_0-logloss:0.58118\tvalidation_1-logloss:0.64973\n",
            "[528]\tvalidation_0-logloss:0.58108\tvalidation_1-logloss:0.64973\n",
            "[529]\tvalidation_0-logloss:0.58099\tvalidation_1-logloss:0.64972\n",
            "[530]\tvalidation_0-logloss:0.58088\tvalidation_1-logloss:0.64971\n",
            "[531]\tvalidation_0-logloss:0.58085\tvalidation_1-logloss:0.64970\n",
            "[532]\tvalidation_0-logloss:0.58078\tvalidation_1-logloss:0.64970\n",
            "[533]\tvalidation_0-logloss:0.58066\tvalidation_1-logloss:0.64970\n",
            "[534]\tvalidation_0-logloss:0.58056\tvalidation_1-logloss:0.64968\n",
            "[535]\tvalidation_0-logloss:0.58049\tvalidation_1-logloss:0.64967\n",
            "[536]\tvalidation_0-logloss:0.58036\tvalidation_1-logloss:0.64965\n",
            "[537]\tvalidation_0-logloss:0.58033\tvalidation_1-logloss:0.64964\n",
            "[538]\tvalidation_0-logloss:0.58024\tvalidation_1-logloss:0.64964\n",
            "[539]\tvalidation_0-logloss:0.58013\tvalidation_1-logloss:0.64963\n",
            "[540]\tvalidation_0-logloss:0.58002\tvalidation_1-logloss:0.64963\n",
            "[541]\tvalidation_0-logloss:0.57994\tvalidation_1-logloss:0.64963\n",
            "[542]\tvalidation_0-logloss:0.57984\tvalidation_1-logloss:0.64963\n",
            "[543]\tvalidation_0-logloss:0.57981\tvalidation_1-logloss:0.64963\n",
            "[544]\tvalidation_0-logloss:0.57972\tvalidation_1-logloss:0.64962\n",
            "[545]\tvalidation_0-logloss:0.57962\tvalidation_1-logloss:0.64960\n",
            "[546]\tvalidation_0-logloss:0.57951\tvalidation_1-logloss:0.64960\n",
            "[547]\tvalidation_0-logloss:0.57944\tvalidation_1-logloss:0.64961\n",
            "[548]\tvalidation_0-logloss:0.57941\tvalidation_1-logloss:0.64960\n",
            "[549]\tvalidation_0-logloss:0.57934\tvalidation_1-logloss:0.64960\n",
            "[550]\tvalidation_0-logloss:0.57920\tvalidation_1-logloss:0.64959\n",
            "[551]\tvalidation_0-logloss:0.57911\tvalidation_1-logloss:0.64959\n",
            "[552]\tvalidation_0-logloss:0.57900\tvalidation_1-logloss:0.64959\n",
            "[553]\tvalidation_0-logloss:0.57893\tvalidation_1-logloss:0.64960\n",
            "[554]\tvalidation_0-logloss:0.57882\tvalidation_1-logloss:0.64959\n",
            "[555]\tvalidation_0-logloss:0.57870\tvalidation_1-logloss:0.64958\n",
            "[556]\tvalidation_0-logloss:0.57866\tvalidation_1-logloss:0.64957\n",
            "[557]\tvalidation_0-logloss:0.57857\tvalidation_1-logloss:0.64958\n",
            "[558]\tvalidation_0-logloss:0.57846\tvalidation_1-logloss:0.64958\n",
            "[559]\tvalidation_0-logloss:0.57837\tvalidation_1-logloss:0.64959\n",
            "[560]\tvalidation_0-logloss:0.57830\tvalidation_1-logloss:0.64958\n",
            "[561]\tvalidation_0-logloss:0.57821\tvalidation_1-logloss:0.64959\n",
            "[562]\tvalidation_0-logloss:0.57811\tvalidation_1-logloss:0.64958\n",
            "[563]\tvalidation_0-logloss:0.57802\tvalidation_1-logloss:0.64960\n",
            "[564]\tvalidation_0-logloss:0.57799\tvalidation_1-logloss:0.64959\n",
            "[565]\tvalidation_0-logloss:0.57788\tvalidation_1-logloss:0.64959\n",
            "[566]\tvalidation_0-logloss:0.57775\tvalidation_1-logloss:0.64957\n",
            "[567]\tvalidation_0-logloss:0.57768\tvalidation_1-logloss:0.64957\n",
            "[568]\tvalidation_0-logloss:0.57759\tvalidation_1-logloss:0.64955\n",
            "[569]\tvalidation_0-logloss:0.57746\tvalidation_1-logloss:0.64955\n",
            "[570]\tvalidation_0-logloss:0.57736\tvalidation_1-logloss:0.64954\n",
            "[571]\tvalidation_0-logloss:0.57723\tvalidation_1-logloss:0.64952\n",
            "[572]\tvalidation_0-logloss:0.57714\tvalidation_1-logloss:0.64950\n",
            "[573]\tvalidation_0-logloss:0.57711\tvalidation_1-logloss:0.64950\n",
            "[574]\tvalidation_0-logloss:0.57702\tvalidation_1-logloss:0.64948\n",
            "[575]\tvalidation_0-logloss:0.57696\tvalidation_1-logloss:0.64947\n",
            "[576]\tvalidation_0-logloss:0.57686\tvalidation_1-logloss:0.64947\n",
            "[577]\tvalidation_0-logloss:0.57679\tvalidation_1-logloss:0.64947\n",
            "[578]\tvalidation_0-logloss:0.57667\tvalidation_1-logloss:0.64947\n",
            "[579]\tvalidation_0-logloss:0.57658\tvalidation_1-logloss:0.64947\n",
            "[580]\tvalidation_0-logloss:0.57649\tvalidation_1-logloss:0.64946\n",
            "[581]\tvalidation_0-logloss:0.57641\tvalidation_1-logloss:0.64946\n",
            "[582]\tvalidation_0-logloss:0.57638\tvalidation_1-logloss:0.64945\n",
            "[583]\tvalidation_0-logloss:0.57627\tvalidation_1-logloss:0.64947\n",
            "[584]\tvalidation_0-logloss:0.57622\tvalidation_1-logloss:0.64948\n",
            "[585]\tvalidation_0-logloss:0.57616\tvalidation_1-logloss:0.64947\n",
            "[586]\tvalidation_0-logloss:0.57607\tvalidation_1-logloss:0.64946\n",
            "[587]\tvalidation_0-logloss:0.57604\tvalidation_1-logloss:0.64945\n",
            "[588]\tvalidation_0-logloss:0.57594\tvalidation_1-logloss:0.64946\n",
            "[589]\tvalidation_0-logloss:0.57587\tvalidation_1-logloss:0.64946\n",
            "[590]\tvalidation_0-logloss:0.57575\tvalidation_1-logloss:0.64944\n",
            "[591]\tvalidation_0-logloss:0.57566\tvalidation_1-logloss:0.64943\n",
            "[592]\tvalidation_0-logloss:0.57556\tvalidation_1-logloss:0.64943\n",
            "[593]\tvalidation_0-logloss:0.57543\tvalidation_1-logloss:0.64943\n",
            "[594]\tvalidation_0-logloss:0.57539\tvalidation_1-logloss:0.64943\n",
            "[595]\tvalidation_0-logloss:0.57531\tvalidation_1-logloss:0.64943\n",
            "[596]\tvalidation_0-logloss:0.57519\tvalidation_1-logloss:0.64942\n",
            "[597]\tvalidation_0-logloss:0.57514\tvalidation_1-logloss:0.64943\n",
            "[598]\tvalidation_0-logloss:0.57508\tvalidation_1-logloss:0.64942\n",
            "[599]\tvalidation_0-logloss:0.57500\tvalidation_1-logloss:0.64941\n",
            "[600]\tvalidation_0-logloss:0.57487\tvalidation_1-logloss:0.64940\n",
            "[601]\tvalidation_0-logloss:0.57479\tvalidation_1-logloss:0.64939\n",
            "[602]\tvalidation_0-logloss:0.57470\tvalidation_1-logloss:0.64940\n",
            "[603]\tvalidation_0-logloss:0.57461\tvalidation_1-logloss:0.64940\n",
            "[604]\tvalidation_0-logloss:0.57453\tvalidation_1-logloss:0.64940\n",
            "[605]\tvalidation_0-logloss:0.57444\tvalidation_1-logloss:0.64939\n",
            "[606]\tvalidation_0-logloss:0.57436\tvalidation_1-logloss:0.64940\n",
            "[607]\tvalidation_0-logloss:0.57427\tvalidation_1-logloss:0.64941\n",
            "[608]\tvalidation_0-logloss:0.57419\tvalidation_1-logloss:0.64941\n",
            "[609]\tvalidation_0-logloss:0.57411\tvalidation_1-logloss:0.64941\n",
            "[610]\tvalidation_0-logloss:0.57401\tvalidation_1-logloss:0.64941\n",
            "[611]\tvalidation_0-logloss:0.57392\tvalidation_1-logloss:0.64939\n",
            "[612]\tvalidation_0-logloss:0.57380\tvalidation_1-logloss:0.64938\n",
            "[613]\tvalidation_0-logloss:0.57372\tvalidation_1-logloss:0.64938\n",
            "[614]\tvalidation_0-logloss:0.57363\tvalidation_1-logloss:0.64936\n",
            "[615]\tvalidation_0-logloss:0.57354\tvalidation_1-logloss:0.64936\n",
            "[616]\tvalidation_0-logloss:0.57346\tvalidation_1-logloss:0.64937\n",
            "[617]\tvalidation_0-logloss:0.57337\tvalidation_1-logloss:0.64937\n",
            "[618]\tvalidation_0-logloss:0.57322\tvalidation_1-logloss:0.64935\n",
            "[619]\tvalidation_0-logloss:0.57312\tvalidation_1-logloss:0.64936\n",
            "[620]\tvalidation_0-logloss:0.57304\tvalidation_1-logloss:0.64935\n",
            "[621]\tvalidation_0-logloss:0.57301\tvalidation_1-logloss:0.64935\n",
            "[622]\tvalidation_0-logloss:0.57291\tvalidation_1-logloss:0.64935\n",
            "[623]\tvalidation_0-logloss:0.57283\tvalidation_1-logloss:0.64936\n",
            "[624]\tvalidation_0-logloss:0.57275\tvalidation_1-logloss:0.64936\n",
            "[625]\tvalidation_0-logloss:0.57266\tvalidation_1-logloss:0.64937\n",
            "[626]\tvalidation_0-logloss:0.57264\tvalidation_1-logloss:0.64936\n",
            "[627]\tvalidation_0-logloss:0.57255\tvalidation_1-logloss:0.64936\n",
            "[628]\tvalidation_0-logloss:0.57243\tvalidation_1-logloss:0.64933\n",
            "[629]\tvalidation_0-logloss:0.57233\tvalidation_1-logloss:0.64934\n",
            "[630]\tvalidation_0-logloss:0.57225\tvalidation_1-logloss:0.64933\n",
            "[631]\tvalidation_0-logloss:0.57217\tvalidation_1-logloss:0.64933\n",
            "[632]\tvalidation_0-logloss:0.57212\tvalidation_1-logloss:0.64932\n",
            "[633]\tvalidation_0-logloss:0.57204\tvalidation_1-logloss:0.64932\n",
            "[634]\tvalidation_0-logloss:0.57196\tvalidation_1-logloss:0.64931\n",
            "[635]\tvalidation_0-logloss:0.57190\tvalidation_1-logloss:0.64931\n",
            "[636]\tvalidation_0-logloss:0.57188\tvalidation_1-logloss:0.64930\n",
            "[637]\tvalidation_0-logloss:0.57182\tvalidation_1-logloss:0.64928\n",
            "[638]\tvalidation_0-logloss:0.57170\tvalidation_1-logloss:0.64927\n",
            "[639]\tvalidation_0-logloss:0.57162\tvalidation_1-logloss:0.64926\n",
            "[640]\tvalidation_0-logloss:0.57158\tvalidation_1-logloss:0.64925\n",
            "[641]\tvalidation_0-logloss:0.57149\tvalidation_1-logloss:0.64926\n",
            "[642]\tvalidation_0-logloss:0.57146\tvalidation_1-logloss:0.64925\n",
            "[643]\tvalidation_0-logloss:0.57141\tvalidation_1-logloss:0.64925\n",
            "[644]\tvalidation_0-logloss:0.57133\tvalidation_1-logloss:0.64926\n",
            "[645]\tvalidation_0-logloss:0.57130\tvalidation_1-logloss:0.64925\n",
            "[646]\tvalidation_0-logloss:0.57125\tvalidation_1-logloss:0.64924\n",
            "[647]\tvalidation_0-logloss:0.57117\tvalidation_1-logloss:0.64924\n",
            "[648]\tvalidation_0-logloss:0.57106\tvalidation_1-logloss:0.64923\n",
            "[649]\tvalidation_0-logloss:0.57096\tvalidation_1-logloss:0.64923\n",
            "[650]\tvalidation_0-logloss:0.57089\tvalidation_1-logloss:0.64922\n",
            "[651]\tvalidation_0-logloss:0.57080\tvalidation_1-logloss:0.64921\n",
            "[652]\tvalidation_0-logloss:0.57076\tvalidation_1-logloss:0.64921\n",
            "[653]\tvalidation_0-logloss:0.57074\tvalidation_1-logloss:0.64920\n",
            "[654]\tvalidation_0-logloss:0.57069\tvalidation_1-logloss:0.64920\n",
            "[655]\tvalidation_0-logloss:0.57061\tvalidation_1-logloss:0.64922\n",
            "[656]\tvalidation_0-logloss:0.57053\tvalidation_1-logloss:0.64921\n",
            "[657]\tvalidation_0-logloss:0.57049\tvalidation_1-logloss:0.64920\n",
            "[658]\tvalidation_0-logloss:0.57039\tvalidation_1-logloss:0.64921\n",
            "[659]\tvalidation_0-logloss:0.57034\tvalidation_1-logloss:0.64921\n",
            "[660]\tvalidation_0-logloss:0.57026\tvalidation_1-logloss:0.64919\n",
            "[661]\tvalidation_0-logloss:0.57018\tvalidation_1-logloss:0.64920\n",
            "[662]\tvalidation_0-logloss:0.57016\tvalidation_1-logloss:0.64919\n",
            "[663]\tvalidation_0-logloss:0.57009\tvalidation_1-logloss:0.64920\n",
            "[664]\tvalidation_0-logloss:0.57001\tvalidation_1-logloss:0.64920\n",
            "[665]\tvalidation_0-logloss:0.56994\tvalidation_1-logloss:0.64921\n",
            "[666]\tvalidation_0-logloss:0.56990\tvalidation_1-logloss:0.64920\n",
            "[667]\tvalidation_0-logloss:0.56981\tvalidation_1-logloss:0.64921\n",
            "[668]\tvalidation_0-logloss:0.56975\tvalidation_1-logloss:0.64921\n",
            "[669]\tvalidation_0-logloss:0.56969\tvalidation_1-logloss:0.64920\n",
            "[670]\tvalidation_0-logloss:0.56961\tvalidation_1-logloss:0.64921\n",
            "[671]\tvalidation_0-logloss:0.56959\tvalidation_1-logloss:0.64920\n",
            "[672]\tvalidation_0-logloss:0.56952\tvalidation_1-logloss:0.64922\n",
            "[673]\tvalidation_0-logloss:0.56944\tvalidation_1-logloss:0.64922\n",
            "[674]\tvalidation_0-logloss:0.56933\tvalidation_1-logloss:0.64921\n",
            "[675]\tvalidation_0-logloss:0.56925\tvalidation_1-logloss:0.64921\n",
            "[676]\tvalidation_0-logloss:0.56917\tvalidation_1-logloss:0.64922\n",
            "[677]\tvalidation_0-logloss:0.56911\tvalidation_1-logloss:0.64922\n",
            "[678]\tvalidation_0-logloss:0.56906\tvalidation_1-logloss:0.64921\n",
            "[679]\tvalidation_0-logloss:0.56895\tvalidation_1-logloss:0.64919\n",
            "[680]\tvalidation_0-logloss:0.56886\tvalidation_1-logloss:0.64920\n",
            "[681]\tvalidation_0-logloss:0.56880\tvalidation_1-logloss:0.64918\n",
            "[682]\tvalidation_0-logloss:0.56875\tvalidation_1-logloss:0.64918\n",
            "[683]\tvalidation_0-logloss:0.56864\tvalidation_1-logloss:0.64919\n",
            "[684]\tvalidation_0-logloss:0.56858\tvalidation_1-logloss:0.64920\n",
            "[685]\tvalidation_0-logloss:0.56854\tvalidation_1-logloss:0.64919\n",
            "[686]\tvalidation_0-logloss:0.56852\tvalidation_1-logloss:0.64918\n",
            "[687]\tvalidation_0-logloss:0.56842\tvalidation_1-logloss:0.64919\n",
            "[688]\tvalidation_0-logloss:0.56831\tvalidation_1-logloss:0.64918\n",
            "[689]\tvalidation_0-logloss:0.56825\tvalidation_1-logloss:0.64918\n",
            "[690]\tvalidation_0-logloss:0.56815\tvalidation_1-logloss:0.64918\n",
            "[691]\tvalidation_0-logloss:0.56803\tvalidation_1-logloss:0.64918\n",
            "[692]\tvalidation_0-logloss:0.56801\tvalidation_1-logloss:0.64917\n",
            "[693]\tvalidation_0-logloss:0.56792\tvalidation_1-logloss:0.64917\n",
            "[694]\tvalidation_0-logloss:0.56785\tvalidation_1-logloss:0.64918\n",
            "[695]\tvalidation_0-logloss:0.56776\tvalidation_1-logloss:0.64918\n",
            "[696]\tvalidation_0-logloss:0.56771\tvalidation_1-logloss:0.64916\n",
            "[697]\tvalidation_0-logloss:0.56767\tvalidation_1-logloss:0.64916\n",
            "[698]\tvalidation_0-logloss:0.56761\tvalidation_1-logloss:0.64915\n",
            "[699]\tvalidation_0-logloss:0.56755\tvalidation_1-logloss:0.64916\n",
            "[700]\tvalidation_0-logloss:0.56745\tvalidation_1-logloss:0.64917\n",
            "[701]\tvalidation_0-logloss:0.56735\tvalidation_1-logloss:0.64917\n",
            "[702]\tvalidation_0-logloss:0.56733\tvalidation_1-logloss:0.64917\n",
            "[703]\tvalidation_0-logloss:0.56726\tvalidation_1-logloss:0.64916\n",
            "[704]\tvalidation_0-logloss:0.56717\tvalidation_1-logloss:0.64918\n",
            "[705]\tvalidation_0-logloss:0.56709\tvalidation_1-logloss:0.64917\n",
            "[706]\tvalidation_0-logloss:0.56704\tvalidation_1-logloss:0.64916\n",
            "[707]\tvalidation_0-logloss:0.56699\tvalidation_1-logloss:0.64915\n",
            "[708]\tvalidation_0-logloss:0.56694\tvalidation_1-logloss:0.64914\n",
            "[709]\tvalidation_0-logloss:0.56685\tvalidation_1-logloss:0.64914\n",
            "[710]\tvalidation_0-logloss:0.56675\tvalidation_1-logloss:0.64913\n",
            "[711]\tvalidation_0-logloss:0.56665\tvalidation_1-logloss:0.64913\n",
            "[712]\tvalidation_0-logloss:0.56658\tvalidation_1-logloss:0.64913\n",
            "[713]\tvalidation_0-logloss:0.56653\tvalidation_1-logloss:0.64914\n",
            "[714]\tvalidation_0-logloss:0.56651\tvalidation_1-logloss:0.64913\n",
            "[715]\tvalidation_0-logloss:0.56643\tvalidation_1-logloss:0.64914\n",
            "[716]\tvalidation_0-logloss:0.56633\tvalidation_1-logloss:0.64915\n",
            "[717]\tvalidation_0-logloss:0.56625\tvalidation_1-logloss:0.64916\n",
            "[718]\tvalidation_0-logloss:0.56620\tvalidation_1-logloss:0.64916\n",
            "[719]\tvalidation_0-logloss:0.56611\tvalidation_1-logloss:0.64917\n",
            "[720]\tvalidation_0-logloss:0.56607\tvalidation_1-logloss:0.64916\n",
            "[721]\tvalidation_0-logloss:0.56602\tvalidation_1-logloss:0.64916\n",
            "[722]\tvalidation_0-logloss:0.56593\tvalidation_1-logloss:0.64914\n",
            "[723]\tvalidation_0-logloss:0.56583\tvalidation_1-logloss:0.64914\n",
            "[724]\tvalidation_0-logloss:0.56579\tvalidation_1-logloss:0.64914\n",
            "[725]\tvalidation_0-logloss:0.56570\tvalidation_1-logloss:0.64912\n",
            "[726]\tvalidation_0-logloss:0.56562\tvalidation_1-logloss:0.64913\n",
            "[727]\tvalidation_0-logloss:0.56557\tvalidation_1-logloss:0.64913\n",
            "[728]\tvalidation_0-logloss:0.56550\tvalidation_1-logloss:0.64913\n",
            "[729]\tvalidation_0-logloss:0.56546\tvalidation_1-logloss:0.64913\n",
            "[730]\tvalidation_0-logloss:0.56541\tvalidation_1-logloss:0.64914\n",
            "[731]\tvalidation_0-logloss:0.56532\tvalidation_1-logloss:0.64915\n",
            "[732]\tvalidation_0-logloss:0.56523\tvalidation_1-logloss:0.64915\n",
            "[733]\tvalidation_0-logloss:0.56515\tvalidation_1-logloss:0.64916\n",
            "[734]\tvalidation_0-logloss:0.56510\tvalidation_1-logloss:0.64916\n",
            "[735]\tvalidation_0-logloss:0.56504\tvalidation_1-logloss:0.64917\n",
            "[736]\tvalidation_0-logloss:0.56495\tvalidation_1-logloss:0.64918\n",
            "[737]\tvalidation_0-logloss:0.56480\tvalidation_1-logloss:0.64917\n",
            "[738]\tvalidation_0-logloss:0.56478\tvalidation_1-logloss:0.64917\n",
            "[739]\tvalidation_0-logloss:0.56472\tvalidation_1-logloss:0.64917\n",
            "[740]\tvalidation_0-logloss:0.56463\tvalidation_1-logloss:0.64917\n",
            "[741]\tvalidation_0-logloss:0.56456\tvalidation_1-logloss:0.64918\n",
            "[742]\tvalidation_0-logloss:0.56449\tvalidation_1-logloss:0.64917\n",
            "[743]\tvalidation_0-logloss:0.56435\tvalidation_1-logloss:0.64917\n",
            "[744]\tvalidation_0-logloss:0.56433\tvalidation_1-logloss:0.64917\n",
            "[745]\tvalidation_0-logloss:0.56425\tvalidation_1-logloss:0.64918\n",
            "[746]\tvalidation_0-logloss:0.56418\tvalidation_1-logloss:0.64919\n",
            "[747]\tvalidation_0-logloss:0.56411\tvalidation_1-logloss:0.64919\n",
            "[748]\tvalidation_0-logloss:0.56408\tvalidation_1-logloss:0.64918\n",
            "[749]\tvalidation_0-logloss:0.56400\tvalidation_1-logloss:0.64919\n",
            "[750]\tvalidation_0-logloss:0.56394\tvalidation_1-logloss:0.64918\n",
            "[751]\tvalidation_0-logloss:0.56380\tvalidation_1-logloss:0.64918\n",
            "[752]\tvalidation_0-logloss:0.56376\tvalidation_1-logloss:0.64918\n",
            "[753]\tvalidation_0-logloss:0.56371\tvalidation_1-logloss:0.64917\n",
            "[754]\tvalidation_0-logloss:0.56366\tvalidation_1-logloss:0.64918\n",
            "[755]\tvalidation_0-logloss:0.56359\tvalidation_1-logloss:0.64918\n",
            "[756]\tvalidation_0-logloss:0.56351\tvalidation_1-logloss:0.64918\n",
            "[757]\tvalidation_0-logloss:0.56337\tvalidation_1-logloss:0.64919\n",
            "[758]\tvalidation_0-logloss:0.56328\tvalidation_1-logloss:0.64918\n",
            "[759]\tvalidation_0-logloss:0.56321\tvalidation_1-logloss:0.64919\n",
            "[760]\tvalidation_0-logloss:0.56309\tvalidation_1-logloss:0.64919\n",
            "[761]\tvalidation_0-logloss:0.56301\tvalidation_1-logloss:0.64921\n",
            "[762]\tvalidation_0-logloss:0.56299\tvalidation_1-logloss:0.64921\n",
            "[763]\tvalidation_0-logloss:0.56294\tvalidation_1-logloss:0.64920\n",
            "[764]\tvalidation_0-logloss:0.56284\tvalidation_1-logloss:0.64919\n",
            "[765]\tvalidation_0-logloss:0.56280\tvalidation_1-logloss:0.64918\n",
            "[766]\tvalidation_0-logloss:0.56268\tvalidation_1-logloss:0.64918\n",
            "[767]\tvalidation_0-logloss:0.56259\tvalidation_1-logloss:0.64918\n",
            "[768]\tvalidation_0-logloss:0.56255\tvalidation_1-logloss:0.64918\n",
            "[769]\tvalidation_0-logloss:0.56247\tvalidation_1-logloss:0.64919\n",
            "[770]\tvalidation_0-logloss:0.56240\tvalidation_1-logloss:0.64920\n",
            "[771]\tvalidation_0-logloss:0.56235\tvalidation_1-logloss:0.64920\n",
            "[772]\tvalidation_0-logloss:0.56223\tvalidation_1-logloss:0.64919\n",
            "[773]\tvalidation_0-logloss:0.56221\tvalidation_1-logloss:0.64919\n",
            "[774]\tvalidation_0-logloss:0.56215\tvalidation_1-logloss:0.64918\n",
            "[775]\tvalidation_0-logloss:0.56208\tvalidation_1-logloss:0.64920\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=42, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "xgb_model.fit(X_train, y_train, early_stopping_rounds=50,\n",
        "              eval_metric=['logloss'], eval_set=[(X_train, y_train), (X_valid, y_valid)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = xgb_model.predict(X_test)\n",
        "get_clf_eval(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0klkf0y-GLD",
        "outputId": "ceb81166-9d37-4b53-e553-a84f2f35df82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차 행렬\n",
            "[[4799 2907]\n",
            " [3079 4627]]\n",
            "정확도 : 0.6116, 정밀도 : 0.6141, 재현율 : 0.6004, F1 : 0.6072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_report_under = metrics.classification_report(y_test, y_pred, zero_division=1)\n",
        "print(xgb_report_under)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYimyNC9-I_n",
        "outputId": "486d39a5-1440-4400-cd83-277ae4e728a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.62      0.62      7706\n",
            "           1       0.61      0.60      0.61      7706\n",
            "\n",
            "    accuracy                           0.61     15412\n",
            "   macro avg       0.61      0.61      0.61     15412\n",
            "weighted avg       0.61      0.61      0.61     15412\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nvi52ZymGWb"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "4Zt5pm590BaU",
        "outputId": "eeff37c3-d42d-457b-ce9f-45d5bbde8327"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.2, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.2, random_state=42)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SVC(C=0.2, random_state=42)"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "svm = SVC(C=0.2, kernel='rbf', random_state=42)\n",
        "svm.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0-JExKA8mDC",
        "outputId": "8cbde906-9bde-4c05-92d7-376f22b61831"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "오차 행렬\n",
            "[[4227 3479]\n",
            " [2954 4752]]\n",
            "정확도 : 0.5826, 정밀도 : 0.5773, 재현율 : 0.6167, F1 : 0.5963\n"
          ]
        }
      ],
      "source": [
        "y_pred = svm.predict(X_valid)\n",
        "get_clf_eval(y_valid, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-IMzZXo9pQc",
        "outputId": "66f6c704-93b1-40a2-88a1-5352ca336fa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.55      0.57      7706\n",
            "           1       0.58      0.62      0.60      7706\n",
            "\n",
            "    accuracy                           0.58     15412\n",
            "   macro avg       0.58      0.58      0.58     15412\n",
            "weighted avg       0.58      0.58      0.58     15412\n",
            "\n"
          ]
        }
      ],
      "source": [
        "svm_report_under = metrics.classification_report(y_valid, y_pred, zero_division=1)\n",
        "print(svm_report_under)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25ubFDJlocqO"
      },
      "source": [
        "# 하이퍼파라미터 튜닝 : GridSearch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "zYQiOdJF-9fC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2HE0Gh7lpvQ"
      },
      "source": [
        "- 다른 모델보다 XGB 모델의 성능이 전반적으로 높으므로 XGB 모델을 채택해 하이퍼파라미터 튜닝을 진행했다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwp1xmt3-ApC"
      },
      "outputs": [],
      "source": [
        "grid_search = {'max_depth' : [2, 3, 4, 5],\n",
        "               'learning_rate' : [0.01, 0.05, 0.1],\n",
        "               'n_estimators': [100, 200, 300, 400, 500, 600]}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb = XGBClassifier()\n",
        "xgb_grid = GridSearchCV(estimator = xgb, param_grid = grid_search, cv = 5, verbose= 5, n_jobs = -1)\n",
        "\n",
        "xgb_grid.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "b5kMRrlUuOuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROKmxKBet2VD",
        "outputId": "da34cba5-96bf-4356-da68-9b7488d7fb37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n"
          ]
        }
      ],
      "source": [
        "print(xgb_grid.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdDzFUyjq0cR",
        "outputId": "8a549ac7-6359-42b7-de8f-585c10e9d885"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "오차 행렬\n",
            "[[4811 2895]\n",
            " [3031 4675]]\n",
            "정확도 : 0.6155, 정밀도 : 0.6176, 재현율 : 0.6067, F1 : 0.6121\n"
          ]
        }
      ],
      "source": [
        "y_pred = xgb_grid.predict(X_test)\n",
        "get_clf_eval(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xODsjpDtte9",
        "outputId": "67500287-a196-494c-c618-cbf7ac7a3a9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.62      0.62      7706\n",
            "           1       0.62      0.61      0.61      7706\n",
            "\n",
            "    accuracy                           0.62     15412\n",
            "   macro avg       0.62      0.62      0.62     15412\n",
            "weighted avg       0.62      0.62      0.62     15412\n",
            "\n"
          ]
        }
      ],
      "source": [
        "xgb_grid_report = metrics.classification_report(y_test, y_pred, zero_division=1)\n",
        "print(xgb_grid_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBM"
      ],
      "metadata": {
        "id": "qWabhoRs_Cnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search = {'num_leaves': [30, 50, 70],\n",
        "               'min_child_samples': [20, 30, 40],\n",
        "               'learning_rate': [0.01, 0.05, 0.08],\n",
        "               'n_estimators': [200, 300, 400]\n",
        "                }"
      ],
      "metadata": {
        "id": "DLuCa_VH_F03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm = LGBMClassifier()"
      ],
      "metadata": {
        "id": "804AaD-2g5x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_grid = GridSearchCV(estimator=lgbm, param_grid=grid_search,\n",
        "                         cv=5, verbose= True, n_jobs=-1)\n",
        "\n",
        "lgbm_grid.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "PEUZ3aH__Fyr",
        "outputId": "f4d3028e-fc28-4e97-c8ab-3fcd1e706e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 27769, number of negative: 27712\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011794 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1738\n",
            "[LightGBM] [Info] Number of data points in the train set: 55481, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=LGBMClassifier(), n_jobs=-1,\n",
              "             param_grid={'learning_rate': [0.01, 0.05, 0.08],\n",
              "                         'min_child_samples': [20, 30, 40],\n",
              "                         'n_estimators': [200, 300, 400],\n",
              "                         'num_leaves': [30, 50, 70]},\n",
              "             verbose=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(), n_jobs=-1,\n",
              "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.05, 0.08],\n",
              "                         &#x27;min_child_samples&#x27;: [20, 30, 40],\n",
              "                         &#x27;n_estimators&#x27;: [200, 300, 400],\n",
              "                         &#x27;num_leaves&#x27;: [30, 50, 70]},\n",
              "             verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(), n_jobs=-1,\n",
              "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.05, 0.08],\n",
              "                         &#x27;min_child_samples&#x27;: [20, 30, 40],\n",
              "                         &#x27;n_estimators&#x27;: [200, 300, 400],\n",
              "                         &#x27;num_leaves&#x27;: [30, 50, 70]},\n",
              "             verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lgbm_grid.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAFmt5qe_Fwi",
        "outputId": "53025844-e1f6-4628-c461-b4a7562702aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'learning_rate': 0.05, 'min_child_samples': 40, 'n_estimators': 300, 'num_leaves': 50}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = lgbm_grid.predict(X_test)\n",
        "get_clf_eval(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSZpdpnZ_owW",
        "outputId": "d66558ad-04cf-411e-8542-00da3710133c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차 행렬\n",
            "[[4794 2912]\n",
            " [3039 4667]]\n",
            "정확도 : 0.6139, 정밀도 : 0.6158, 재현율 : 0.6056, F1 : 0.6107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_grid_report = metrics.classification_report(y_test, y_pred, zero_division=1)\n",
        "print(lgbm_grid_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CrcNAg1_orf",
        "outputId": "b3ad304f-3609-47cc-ad1a-43ca95ae5ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.62      0.62      7706\n",
            "           1       0.62      0.61      0.61      7706\n",
            "\n",
            "    accuracy                           0.61     15412\n",
            "   macro avg       0.61      0.61      0.61     15412\n",
            "weighted avg       0.61      0.61      0.61     15412\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IjHF_BWpMXz"
      },
      "source": [
        "# HyperOpt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "u1eElGcEADAl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYlx3EaHqGoo"
      },
      "outputs": [],
      "source": [
        "not_delayed_data = train[train['Delay'] == 0]\n",
        "delayed_data = train[train['Delay'] == 1]\n",
        "\n",
        "under_not_delayed = not_delayed_data.sample(n=len(delayed_data), random_state=42)\n",
        "under_data = pd.concat([delayed_data, under_not_delayed], axis=0)\n",
        "\n",
        "X = under_data.iloc[:,:-1]\n",
        "y = under_data.iloc[:,-1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8c-qfN0qx1T"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hytGNzVqsdz",
        "outputId": "c03b8261-c6ff-4ce1-ab20-5399861e8a1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(55481, 13) (55481,)\n",
            "(15412, 13) (15412,)\n",
            "(6165, 13) (6165,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)\n",
        "print(X_valid.shape, y_valid.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54u2VQ3kqCJI"
      },
      "outputs": [],
      "source": [
        "search_space = {'max_depth': hp.quniform('max_depth', 5, 20, 1),\n",
        "               'min_child_weight': hp.quniform('min_child_weight', 1, 2, 1),\n",
        "               'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
        "               'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImmCft9VrLcb"
      },
      "outputs": [],
      "source": [
        "def objective_func(search_space):\n",
        "  xgb_clf = XGBClassifier(\n",
        "      n_estimators = 100,\n",
        "      max_depth = int(search_space['max_depth']),\n",
        "      min_child_weight = int(search_space['min_child_weight']),\n",
        "      learning_rate = search_space['learning_rate'],\n",
        "      colsample_bytree = search_space['colsample_bytree'],\n",
        "      eval_metric = 'logloss'\n",
        "  )\n",
        "\n",
        "  accuracy = cross_val_score(xgb_clf, X_train, y_train, scoring='accuracy', cv=3)\n",
        "\n",
        "  return {\n",
        "      'loss':(-1) * np.mean(accuracy),\n",
        "      'status':STATUS_OK\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsNk9TijrS8J",
        "outputId": "e4f5d151-5f12-4fe9-f48c-c2f2c7570065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [06:46<00:00,  8.12s/trial, best loss: -0.6128223960488214]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'colsample_bytree': 0.6065789863309242,\n",
              " 'learning_rate': 0.1962378163977927,\n",
              " 'max_depth': 5.0,\n",
              " 'min_child_weight': 2.0}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trial_val = Trials()\n",
        "best = fmin(fn = objective_func,\n",
        "            space = search_space,\n",
        "            algo = tpe.suggest,\n",
        "            max_evals = 50,\n",
        "            trials = trial_val\n",
        "            )\n",
        "\n",
        "best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUSDKQIfrkyT"
      },
      "outputs": [],
      "source": [
        "xgb_opt = XGBClassifier(n_estimators = 400,\n",
        "                        learning_rate = round(best['learning_rate'], 5),\n",
        "                        max_depth = int(best['max_depth']),\n",
        "                        min_child_weight = int(best['min_child_weight']),\n",
        "                        colsample_bytree = round(best['colsample_bytree'], 5)\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QiPVKXkstUYO",
        "outputId": "6d88cab4-ffa7-4af6-b840-5b68af095ae8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-logloss:0.68503\tvalidation_1-logloss:0.68574\n",
            "[1]\tvalidation_0-logloss:0.67786\tvalidation_1-logloss:0.67925\n",
            "[2]\tvalidation_0-logloss:0.67278\tvalidation_1-logloss:0.67481\n",
            "[3]\tvalidation_0-logloss:0.66904\tvalidation_1-logloss:0.67178\n",
            "[4]\tvalidation_0-logloss:0.66769\tvalidation_1-logloss:0.67116\n",
            "[5]\tvalidation_0-logloss:0.66502\tvalidation_1-logloss:0.66921\n",
            "[6]\tvalidation_0-logloss:0.66341\tvalidation_1-logloss:0.66828\n",
            "[7]\tvalidation_0-logloss:0.66149\tvalidation_1-logloss:0.66689\n",
            "[8]\tvalidation_0-logloss:0.65964\tvalidation_1-logloss:0.66533\n",
            "[9]\tvalidation_0-logloss:0.65826\tvalidation_1-logloss:0.66431\n",
            "[10]\tvalidation_0-logloss:0.65691\tvalidation_1-logloss:0.66320\n",
            "[11]\tvalidation_0-logloss:0.65526\tvalidation_1-logloss:0.66210\n",
            "[12]\tvalidation_0-logloss:0.65418\tvalidation_1-logloss:0.66160\n",
            "[13]\tvalidation_0-logloss:0.65276\tvalidation_1-logloss:0.66042\n",
            "[14]\tvalidation_0-logloss:0.65175\tvalidation_1-logloss:0.65977\n",
            "[15]\tvalidation_0-logloss:0.65046\tvalidation_1-logloss:0.65875\n",
            "[16]\tvalidation_0-logloss:0.64952\tvalidation_1-logloss:0.65805\n",
            "[17]\tvalidation_0-logloss:0.64855\tvalidation_1-logloss:0.65715\n",
            "[18]\tvalidation_0-logloss:0.64772\tvalidation_1-logloss:0.65659\n",
            "[19]\tvalidation_0-logloss:0.64690\tvalidation_1-logloss:0.65620\n",
            "[20]\tvalidation_0-logloss:0.64618\tvalidation_1-logloss:0.65595\n",
            "[21]\tvalidation_0-logloss:0.64550\tvalidation_1-logloss:0.65581\n",
            "[22]\tvalidation_0-logloss:0.64496\tvalidation_1-logloss:0.65574\n",
            "[23]\tvalidation_0-logloss:0.64428\tvalidation_1-logloss:0.65567\n",
            "[24]\tvalidation_0-logloss:0.64355\tvalidation_1-logloss:0.65542\n",
            "[25]\tvalidation_0-logloss:0.64286\tvalidation_1-logloss:0.65530\n",
            "[26]\tvalidation_0-logloss:0.64219\tvalidation_1-logloss:0.65520\n",
            "[27]\tvalidation_0-logloss:0.64167\tvalidation_1-logloss:0.65518\n",
            "[28]\tvalidation_0-logloss:0.64121\tvalidation_1-logloss:0.65524\n",
            "[29]\tvalidation_0-logloss:0.64074\tvalidation_1-logloss:0.65525\n",
            "[30]\tvalidation_0-logloss:0.64006\tvalidation_1-logloss:0.65507\n",
            "[31]\tvalidation_0-logloss:0.63961\tvalidation_1-logloss:0.65501\n",
            "[32]\tvalidation_0-logloss:0.63915\tvalidation_1-logloss:0.65492\n",
            "[33]\tvalidation_0-logloss:0.63865\tvalidation_1-logloss:0.65491\n",
            "[34]\tvalidation_0-logloss:0.63816\tvalidation_1-logloss:0.65485\n",
            "[35]\tvalidation_0-logloss:0.63782\tvalidation_1-logloss:0.65482\n",
            "[36]\tvalidation_0-logloss:0.63743\tvalidation_1-logloss:0.65449\n",
            "[37]\tvalidation_0-logloss:0.63692\tvalidation_1-logloss:0.65447\n",
            "[38]\tvalidation_0-logloss:0.63646\tvalidation_1-logloss:0.65448\n",
            "[39]\tvalidation_0-logloss:0.63602\tvalidation_1-logloss:0.65450\n",
            "[40]\tvalidation_0-logloss:0.63570\tvalidation_1-logloss:0.65440\n",
            "[41]\tvalidation_0-logloss:0.63523\tvalidation_1-logloss:0.65430\n",
            "[42]\tvalidation_0-logloss:0.63465\tvalidation_1-logloss:0.65430\n",
            "[43]\tvalidation_0-logloss:0.63391\tvalidation_1-logloss:0.65388\n",
            "[44]\tvalidation_0-logloss:0.63352\tvalidation_1-logloss:0.65380\n",
            "[45]\tvalidation_0-logloss:0.63304\tvalidation_1-logloss:0.65343\n",
            "[46]\tvalidation_0-logloss:0.63240\tvalidation_1-logloss:0.65302\n",
            "[47]\tvalidation_0-logloss:0.63211\tvalidation_1-logloss:0.65292\n",
            "[48]\tvalidation_0-logloss:0.63182\tvalidation_1-logloss:0.65286\n",
            "[49]\tvalidation_0-logloss:0.63141\tvalidation_1-logloss:0.65281\n",
            "[50]\tvalidation_0-logloss:0.63097\tvalidation_1-logloss:0.65287\n",
            "[51]\tvalidation_0-logloss:0.63077\tvalidation_1-logloss:0.65283\n",
            "[52]\tvalidation_0-logloss:0.63055\tvalidation_1-logloss:0.65261\n",
            "[53]\tvalidation_0-logloss:0.63001\tvalidation_1-logloss:0.65267\n",
            "[54]\tvalidation_0-logloss:0.62974\tvalidation_1-logloss:0.65261\n",
            "[55]\tvalidation_0-logloss:0.62937\tvalidation_1-logloss:0.65270\n",
            "[56]\tvalidation_0-logloss:0.62907\tvalidation_1-logloss:0.65269\n",
            "[57]\tvalidation_0-logloss:0.62878\tvalidation_1-logloss:0.65269\n",
            "[58]\tvalidation_0-logloss:0.62857\tvalidation_1-logloss:0.65258\n",
            "[59]\tvalidation_0-logloss:0.62825\tvalidation_1-logloss:0.65247\n",
            "[60]\tvalidation_0-logloss:0.62791\tvalidation_1-logloss:0.65255\n",
            "[61]\tvalidation_0-logloss:0.62764\tvalidation_1-logloss:0.65254\n",
            "[62]\tvalidation_0-logloss:0.62719\tvalidation_1-logloss:0.65252\n",
            "[63]\tvalidation_0-logloss:0.62696\tvalidation_1-logloss:0.65247\n",
            "[64]\tvalidation_0-logloss:0.62654\tvalidation_1-logloss:0.65236\n",
            "[65]\tvalidation_0-logloss:0.62603\tvalidation_1-logloss:0.65211\n",
            "[66]\tvalidation_0-logloss:0.62560\tvalidation_1-logloss:0.65228\n",
            "[67]\tvalidation_0-logloss:0.62525\tvalidation_1-logloss:0.65240\n",
            "[68]\tvalidation_0-logloss:0.62497\tvalidation_1-logloss:0.65236\n",
            "[69]\tvalidation_0-logloss:0.62453\tvalidation_1-logloss:0.65242\n",
            "[70]\tvalidation_0-logloss:0.62417\tvalidation_1-logloss:0.65249\n",
            "[71]\tvalidation_0-logloss:0.62383\tvalidation_1-logloss:0.65239\n",
            "[72]\tvalidation_0-logloss:0.62353\tvalidation_1-logloss:0.65258\n",
            "[73]\tvalidation_0-logloss:0.62314\tvalidation_1-logloss:0.65249\n",
            "[74]\tvalidation_0-logloss:0.62290\tvalidation_1-logloss:0.65252\n",
            "[75]\tvalidation_0-logloss:0.62257\tvalidation_1-logloss:0.65257\n",
            "[76]\tvalidation_0-logloss:0.62239\tvalidation_1-logloss:0.65252\n",
            "[77]\tvalidation_0-logloss:0.62201\tvalidation_1-logloss:0.65250\n",
            "[78]\tvalidation_0-logloss:0.62174\tvalidation_1-logloss:0.65254\n",
            "[79]\tvalidation_0-logloss:0.62123\tvalidation_1-logloss:0.65235\n",
            "[80]\tvalidation_0-logloss:0.62090\tvalidation_1-logloss:0.65239\n",
            "[81]\tvalidation_0-logloss:0.62051\tvalidation_1-logloss:0.65240\n",
            "[82]\tvalidation_0-logloss:0.62012\tvalidation_1-logloss:0.65229\n",
            "[83]\tvalidation_0-logloss:0.61983\tvalidation_1-logloss:0.65237\n",
            "[84]\tvalidation_0-logloss:0.61958\tvalidation_1-logloss:0.65234\n",
            "[85]\tvalidation_0-logloss:0.61903\tvalidation_1-logloss:0.65210\n",
            "[86]\tvalidation_0-logloss:0.61865\tvalidation_1-logloss:0.65234\n",
            "[87]\tvalidation_0-logloss:0.61844\tvalidation_1-logloss:0.65222\n",
            "[88]\tvalidation_0-logloss:0.61805\tvalidation_1-logloss:0.65212\n",
            "[89]\tvalidation_0-logloss:0.61751\tvalidation_1-logloss:0.65214\n",
            "[90]\tvalidation_0-logloss:0.61724\tvalidation_1-logloss:0.65215\n",
            "[91]\tvalidation_0-logloss:0.61692\tvalidation_1-logloss:0.65217\n",
            "[92]\tvalidation_0-logloss:0.61663\tvalidation_1-logloss:0.65205\n",
            "[93]\tvalidation_0-logloss:0.61630\tvalidation_1-logloss:0.65210\n",
            "[94]\tvalidation_0-logloss:0.61600\tvalidation_1-logloss:0.65198\n",
            "[95]\tvalidation_0-logloss:0.61544\tvalidation_1-logloss:0.65160\n",
            "[96]\tvalidation_0-logloss:0.61514\tvalidation_1-logloss:0.65150\n",
            "[97]\tvalidation_0-logloss:0.61494\tvalidation_1-logloss:0.65142\n",
            "[98]\tvalidation_0-logloss:0.61466\tvalidation_1-logloss:0.65113\n",
            "[99]\tvalidation_0-logloss:0.61452\tvalidation_1-logloss:0.65121\n",
            "[100]\tvalidation_0-logloss:0.61426\tvalidation_1-logloss:0.65110\n",
            "[101]\tvalidation_0-logloss:0.61393\tvalidation_1-logloss:0.65116\n",
            "[102]\tvalidation_0-logloss:0.61371\tvalidation_1-logloss:0.65099\n",
            "[103]\tvalidation_0-logloss:0.61346\tvalidation_1-logloss:0.65106\n",
            "[104]\tvalidation_0-logloss:0.61318\tvalidation_1-logloss:0.65105\n",
            "[105]\tvalidation_0-logloss:0.61287\tvalidation_1-logloss:0.65117\n",
            "[106]\tvalidation_0-logloss:0.61259\tvalidation_1-logloss:0.65116\n",
            "[107]\tvalidation_0-logloss:0.61234\tvalidation_1-logloss:0.65116\n",
            "[108]\tvalidation_0-logloss:0.61201\tvalidation_1-logloss:0.65099\n",
            "[109]\tvalidation_0-logloss:0.61173\tvalidation_1-logloss:0.65102\n",
            "[110]\tvalidation_0-logloss:0.61148\tvalidation_1-logloss:0.65110\n",
            "[111]\tvalidation_0-logloss:0.61126\tvalidation_1-logloss:0.65118\n",
            "[112]\tvalidation_0-logloss:0.61100\tvalidation_1-logloss:0.65110\n",
            "[113]\tvalidation_0-logloss:0.61077\tvalidation_1-logloss:0.65110\n",
            "[114]\tvalidation_0-logloss:0.61037\tvalidation_1-logloss:0.65105\n",
            "[115]\tvalidation_0-logloss:0.60995\tvalidation_1-logloss:0.65123\n",
            "[116]\tvalidation_0-logloss:0.60966\tvalidation_1-logloss:0.65121\n",
            "[117]\tvalidation_0-logloss:0.60944\tvalidation_1-logloss:0.65119\n",
            "[118]\tvalidation_0-logloss:0.60926\tvalidation_1-logloss:0.65107\n",
            "[119]\tvalidation_0-logloss:0.60890\tvalidation_1-logloss:0.65106\n",
            "[120]\tvalidation_0-logloss:0.60876\tvalidation_1-logloss:0.65102\n",
            "[121]\tvalidation_0-logloss:0.60848\tvalidation_1-logloss:0.65115\n",
            "[122]\tvalidation_0-logloss:0.60825\tvalidation_1-logloss:0.65124\n",
            "[123]\tvalidation_0-logloss:0.60783\tvalidation_1-logloss:0.65140\n",
            "[124]\tvalidation_0-logloss:0.60759\tvalidation_1-logloss:0.65140\n",
            "[125]\tvalidation_0-logloss:0.60727\tvalidation_1-logloss:0.65152\n",
            "[126]\tvalidation_0-logloss:0.60691\tvalidation_1-logloss:0.65162\n",
            "[127]\tvalidation_0-logloss:0.60674\tvalidation_1-logloss:0.65164\n",
            "[128]\tvalidation_0-logloss:0.60663\tvalidation_1-logloss:0.65157\n",
            "[129]\tvalidation_0-logloss:0.60639\tvalidation_1-logloss:0.65162\n",
            "[130]\tvalidation_0-logloss:0.60615\tvalidation_1-logloss:0.65180\n",
            "[131]\tvalidation_0-logloss:0.60581\tvalidation_1-logloss:0.65166\n",
            "[132]\tvalidation_0-logloss:0.60557\tvalidation_1-logloss:0.65161\n",
            "[133]\tvalidation_0-logloss:0.60526\tvalidation_1-logloss:0.65143\n",
            "[134]\tvalidation_0-logloss:0.60498\tvalidation_1-logloss:0.65139\n",
            "[135]\tvalidation_0-logloss:0.60487\tvalidation_1-logloss:0.65138\n",
            "[136]\tvalidation_0-logloss:0.60464\tvalidation_1-logloss:0.65145\n",
            "[137]\tvalidation_0-logloss:0.60436\tvalidation_1-logloss:0.65154\n",
            "[138]\tvalidation_0-logloss:0.60409\tvalidation_1-logloss:0.65152\n",
            "[139]\tvalidation_0-logloss:0.60372\tvalidation_1-logloss:0.65140\n",
            "[140]\tvalidation_0-logloss:0.60338\tvalidation_1-logloss:0.65154\n",
            "[141]\tvalidation_0-logloss:0.60308\tvalidation_1-logloss:0.65153\n",
            "[142]\tvalidation_0-logloss:0.60275\tvalidation_1-logloss:0.65158\n",
            "[143]\tvalidation_0-logloss:0.60244\tvalidation_1-logloss:0.65150\n",
            "[144]\tvalidation_0-logloss:0.60226\tvalidation_1-logloss:0.65160\n",
            "[145]\tvalidation_0-logloss:0.60197\tvalidation_1-logloss:0.65147\n",
            "[146]\tvalidation_0-logloss:0.60181\tvalidation_1-logloss:0.65153\n",
            "[147]\tvalidation_0-logloss:0.60129\tvalidation_1-logloss:0.65171\n",
            "[148]\tvalidation_0-logloss:0.60104\tvalidation_1-logloss:0.65185\n",
            "[149]\tvalidation_0-logloss:0.60079\tvalidation_1-logloss:0.65184\n",
            "[150]\tvalidation_0-logloss:0.60055\tvalidation_1-logloss:0.65178\n",
            "[151]\tvalidation_0-logloss:0.60040\tvalidation_1-logloss:0.65186\n",
            "[152]\tvalidation_0-logloss:0.60001\tvalidation_1-logloss:0.65170\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.60658, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.19624, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=2, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=400, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.60658, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.19624, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=2, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=400, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.60658, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.19624, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=2, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=400, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evals = [(X_train, y_train), (X_valid, y_valid)]\n",
        "\n",
        "xgb_opt.fit(X_train, y_train,\n",
        "                early_stopping_rounds = 50,\n",
        "                eval_metric = 'logloss',\n",
        "                eval_set = evals,\n",
        "                verbose = True\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6K5hOhrNurq0"
      },
      "outputs": [],
      "source": [
        "def get_clf_eval(y_test, pred):\n",
        "    confusion= confusion_matrix(y_test, pred)\n",
        "    accuracy = accuracy_score(y_test, pred)\n",
        "    precision = precision_score(y_test, pred)\n",
        "    recall = recall_score(y_test, pred)\n",
        "    f1 = f1_score(y_test, pred)\n",
        "    print('오차 행렬')\n",
        "    print(confusion)\n",
        "    print(f'정확도 : {accuracy:.4f}, 정밀도 : {precision:.4f}, 재현율 : {recall:.4f}, F1 : {f1:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DGI3g_DuwIi",
        "outputId": "0be21d03-683b-4cb9-e39c-fa6950690ee1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "오차 행렬\n",
            "[[4762 2944]\n",
            " [2993 4713]]\n",
            "정확도 : 0.6148, 정밀도 : 0.6155, 재현율 : 0.6116, F1 : 0.6136\n"
          ]
        }
      ],
      "source": [
        "y_pred = xgb_opt.predict(X_test)\n",
        "get_clf_eval(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90nHe39wu01n",
        "outputId": "7212fc83-dbda-45db-80af-e5721d45c38e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.62      0.62      7706\n",
            "           1       0.62      0.61      0.61      7706\n",
            "\n",
            "    accuracy                           0.61     15412\n",
            "   macro avg       0.61      0.61      0.61     15412\n",
            "weighted avg       0.61      0.61      0.61     15412\n",
            "\n"
          ]
        }
      ],
      "source": [
        "xgb_opt_report = metrics.classification_report(y_test, y_pred, zero_division=1)\n",
        "print(xgb_opt_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBM"
      ],
      "metadata": {
        "id": "0ioD5U_bAGHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_space = {'max_depth': hp.quniform('max_depth', 5, 20, 1),\n",
        "               'min_child_weight': hp.quniform('min_child_weight', 1, 2, 1),\n",
        "               'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
        "               'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1)}"
      ],
      "metadata": {
        "id": "vVtBZsZDAHwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_func(search_space):\n",
        "  lgbm_clf = LGBMClassifier(\n",
        "      n_estimators = 100,\n",
        "      max_depth = int(search_space['max_depth']),\n",
        "      min_child_weight = int(search_space['min_child_weight']),\n",
        "      learning_rate = search_space['learning_rate'],\n",
        "      colsample_bytree = search_space['colsample_bytree'],\n",
        "      eval_metric = 'logloss'\n",
        "  )\n",
        "\n",
        "  accuracy = cross_val_score(lgbm_clf, X_train, y_train, scoring='accuracy', cv=3)\n",
        "\n",
        "  return {\n",
        "      'loss':(-1) * np.mean(accuracy),\n",
        "      'status':STATUS_OK\n",
        "  }"
      ],
      "metadata": {
        "id": "abKTUrMpAHuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trial_val = Trials()\n",
        "best = fmin(fn = objective_func,\n",
        "            space = search_space,\n",
        "            algo = tpe.suggest,\n",
        "            max_evals = 50,\n",
        "            trials = trial_val\n",
        "            )\n",
        "\n",
        "best"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRUeGCkEBlHo",
        "outputId": "6bc311b9-ade7-4d89-f3d5-beb9e35f1f07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015274 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005126 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005811 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015985 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009302 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007568 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009183 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004108 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002596 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006225 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006318 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011040 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007371 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013380 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003014 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006021 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010619 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007473 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013816 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011668 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002575 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010223 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007157 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007465 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006897 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010051 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009506 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010856 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009569 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011961 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010320 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006353 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001343 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007249 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007284 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008487 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010999 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007517 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007912 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011735 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007921 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005601 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010746 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006655 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018585 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008014 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008114 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009028 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012404 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008913 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008756 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006628 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003567 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006370 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006700 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006732 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006980 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005683 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009868 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005733 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009510 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011543 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007121 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005281 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011353 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019325 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013830 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006944 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007335 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007515 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013188 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014033 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001181 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010978 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003029 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007291 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011301 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009537 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010555 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007411 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010576 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007322 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010382 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007500 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007330 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008966 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010345 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006579 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001454 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010180 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006596 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006776 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007110 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010937 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009824 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013116 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005600 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006647 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006330 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007052 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012519 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012610 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001282 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006499 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006956 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008981 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015791 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008370 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005635 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007409 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007029 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004878 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007809 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004909 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005792 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016290 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001581 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006783 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006219 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007797 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008112 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007430 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008626 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016138 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007203 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010411 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012779 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011229 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007238 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007002 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007402 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011018 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013091 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007433 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006046 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008427 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010123 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005374 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006983 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012661 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011444 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007507 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012845 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006575 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006499 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18512, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010532 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1722\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500500 -> initscore=0.002001\n",
            "[LightGBM] [Info] Start training from score 0.002001\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18474\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006289 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1735\n",
            "[LightGBM] [Info] Number of data points in the train set: 36987, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500527 -> initscore=0.002109\n",
            "[LightGBM] [Info] Start training from score 0.002109\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 18513, number of negative: 18475\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009038 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1731\n",
            "[LightGBM] [Info] Number of data points in the train set: 36988, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "100%|██████████| 50/50 [02:43<00:00,  3.26s/trial, best loss: -0.6141922311239687]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bytree': 0.6366936129224374,\n",
              " 'learning_rate': 0.08533763078836704,\n",
              " 'max_depth': 5.0,\n",
              " 'min_child_weight': 2.0}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_opt = LGBMClassifier(n_estimators = 400,\n",
        "                        learning_rate = round(best['learning_rate'], 5),\n",
        "                        max_depth = int(best['max_depth']),\n",
        "                        min_child_weight = int(best['min_child_weight']),\n",
        "                        colsample_bytree = round(best['colsample_bytree'], 5)\n",
        "                        )"
      ],
      "metadata": {
        "id": "DZyfwafuAHoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evals = [(X_train, y_train), (X_valid, y_valid)]\n",
        "\n",
        "lgbm_opt.fit(X_train, y_train,\n",
        "                eval_metric = 'logloss',\n",
        "                eval_set = evals\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PLxn2IWFAHmO",
        "outputId": "14a20d08-4894-4697-b085-a6483788675c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 27769, number of negative: 27712\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004120 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1738\n",
            "[LightGBM] [Info] Number of data points in the train set: 55481, number of used features: 12\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500514 -> initscore=0.002055\n",
            "[LightGBM] [Info] Start training from score 0.002055\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(colsample_bytree=0.63669, learning_rate=0.08534, max_depth=5,\n",
              "               min_child_weight=2, n_estimators=400)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(colsample_bytree=0.63669, learning_rate=0.08534, max_depth=5,\n",
              "               min_child_weight=2, n_estimators=400)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.63669, learning_rate=0.08534, max_depth=5,\n",
              "               min_child_weight=2, n_estimators=400)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = lgbm_opt.predict(X_test)\n",
        "get_clf_eval(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujyv9-iYB2Y5",
        "outputId": "ccb4d34f-c389-497b-9f94-37d7c159d140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "오차 행렬\n",
            "[[4780 2926]\n",
            " [3006 4700]]\n",
            "정확도 : 0.6151, 정밀도 : 0.6163, 재현율 : 0.6099, F1 : 0.6131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_opt_report = metrics.classification_report(y_test, y_pred, zero_division=1)\n",
        "print(lgbm_opt_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bMw46UTAHj6",
        "outputId": "386f959a-42cd-4288-c77e-d2dd80fa876d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.62      0.62      7706\n",
            "           1       0.62      0.61      0.61      7706\n",
            "\n",
            "    accuracy                           0.62     15412\n",
            "   macro avg       0.62      0.62      0.62     15412\n",
            "weighted avg       0.62      0.62      0.62     15412\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKGXSi4bbRT5"
      },
      "source": [
        "# CatBoost\n",
        "- label이 없는 test data 사용으로 logloss만 구할 수 있었음\n",
        "- 모델 비교에서 제외"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EU45yZFj_6l"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/iitp_mid_flight/data/train_prep.csv\", index_col = 0)\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/iitp_mid_flight/data/test_prep.csv\", index_col = 0)\n",
        "\n",
        "train = train.drop(columns=['ID', 'Cancelled'], axis=1)\n",
        "test = test.drop(columns=['ID', 'Cancelled'], axis=1)\n",
        "\n",
        "train = train.dropna()\n",
        "test = test.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XU8mvDHSj_2A"
      },
      "outputs": [],
      "source": [
        "X_train = train.drop(['Delay'],axis=1)\n",
        "y_train = train['Delay']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEXl_7ROkz_4",
        "outputId": "017e58c2-1a47-464c-e3dc-86bd8b57996e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cat features are: ['Origin_Airport', 'Origin_State', 'Destination_Airport', 'Destination_State', 'Airline']\n",
            "[ 5  7  8 10 12]\n"
          ]
        }
      ],
      "source": [
        "# object형 변수는 cat_features에 추가\n",
        "cat_features = [f for f in X_train.columns if X_train[f].dtype == 'object']\n",
        "\n",
        "def column_index(df, cat_features):\n",
        "    cols = df.columns.values\n",
        "    sidx = np.argsort(cols)\n",
        "    return sidx[np.searchsorted(cols, cat_features, sorter=sidx)]\n",
        "\n",
        "cat_features_idx = column_index(X_train, cat_features)\n",
        "print(\"Cat features are: %s\" % [f for f in cat_features])\n",
        "print(cat_features_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgSTiqdLuOo1"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPHsWs2olFC-",
        "outputId": "6323dd3f-b059-4971-8fd4-b162c15fb3e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.6879052\ttotal: 108ms\tremaining: 1m 48s\n",
            "20:\tlearn: 0.6022691\ttotal: 5.89s\tremaining: 4m 34s\n",
            "40:\tlearn: 0.5483402\ttotal: 9.36s\tremaining: 3m 38s\n",
            "60:\tlearn: 0.5138663\ttotal: 13.1s\tremaining: 3m 21s\n",
            "80:\tlearn: 0.4914444\ttotal: 17s\tremaining: 3m 13s\n",
            "100:\tlearn: 0.4768733\ttotal: 22.3s\tremaining: 3m 18s\n",
            "120:\tlearn: 0.4671896\ttotal: 26.1s\tremaining: 3m 9s\n",
            "140:\tlearn: 0.4604680\ttotal: 30.2s\tremaining: 3m 4s\n",
            "160:\tlearn: 0.4560317\ttotal: 36.2s\tremaining: 3m 8s\n",
            "180:\tlearn: 0.4528324\ttotal: 40s\tremaining: 3m 1s\n",
            "200:\tlearn: 0.4503291\ttotal: 44s\tremaining: 2m 55s\n",
            "220:\tlearn: 0.4485374\ttotal: 49.8s\tremaining: 2m 55s\n",
            "240:\tlearn: 0.4471415\ttotal: 53.7s\tremaining: 2m 49s\n",
            "260:\tlearn: 0.4458552\ttotal: 58s\tremaining: 2m 44s\n",
            "280:\tlearn: 0.4448676\ttotal: 1m 4s\tremaining: 2m 44s\n",
            "300:\tlearn: 0.4439368\ttotal: 1m 9s\tremaining: 2m 40s\n",
            "320:\tlearn: 0.4431736\ttotal: 1m 13s\tremaining: 2m 35s\n",
            "340:\tlearn: 0.4425402\ttotal: 1m 20s\tremaining: 2m 34s\n",
            "360:\tlearn: 0.4419295\ttotal: 1m 24s\tremaining: 2m 29s\n",
            "380:\tlearn: 0.4414372\ttotal: 1m 29s\tremaining: 2m 25s\n",
            "400:\tlearn: 0.4409409\ttotal: 1m 36s\tremaining: 2m 23s\n",
            "420:\tlearn: 0.4405431\ttotal: 1m 40s\tremaining: 2m 18s\n",
            "440:\tlearn: 0.4400940\ttotal: 1m 46s\tremaining: 2m 14s\n",
            "460:\tlearn: 0.4396641\ttotal: 1m 51s\tremaining: 2m 10s\n",
            "480:\tlearn: 0.4392887\ttotal: 1m 56s\tremaining: 2m 5s\n",
            "500:\tlearn: 0.4389308\ttotal: 2m 2s\tremaining: 2m 1s\n",
            "520:\tlearn: 0.4385540\ttotal: 2m 7s\tremaining: 1m 56s\n",
            "540:\tlearn: 0.4382207\ttotal: 2m 11s\tremaining: 1m 51s\n",
            "560:\tlearn: 0.4378863\ttotal: 2m 18s\tremaining: 1m 48s\n",
            "580:\tlearn: 0.4375753\ttotal: 2m 22s\tremaining: 1m 42s\n",
            "600:\tlearn: 0.4372613\ttotal: 2m 27s\tremaining: 1m 37s\n",
            "620:\tlearn: 0.4369350\ttotal: 2m 33s\tremaining: 1m 33s\n",
            "640:\tlearn: 0.4366113\ttotal: 2m 38s\tremaining: 1m 28s\n",
            "660:\tlearn: 0.4363091\ttotal: 2m 43s\tremaining: 1m 23s\n",
            "680:\tlearn: 0.4360481\ttotal: 2m 49s\tremaining: 1m 19s\n",
            "700:\tlearn: 0.4358206\ttotal: 2m 53s\tremaining: 1m 14s\n",
            "720:\tlearn: 0.4355639\ttotal: 2m 58s\tremaining: 1m 9s\n",
            "740:\tlearn: 0.4352879\ttotal: 3m 4s\tremaining: 1m 4s\n",
            "760:\tlearn: 0.4350209\ttotal: 3m 8s\tremaining: 59.3s\n",
            "780:\tlearn: 0.4347714\ttotal: 3m 14s\tremaining: 54.4s\n",
            "800:\tlearn: 0.4345037\ttotal: 3m 19s\tremaining: 49.5s\n",
            "820:\tlearn: 0.4342467\ttotal: 3m 23s\tremaining: 44.4s\n",
            "840:\tlearn: 0.4340070\ttotal: 3m 29s\tremaining: 39.5s\n",
            "860:\tlearn: 0.4337694\ttotal: 3m 34s\tremaining: 34.6s\n",
            "880:\tlearn: 0.4335037\ttotal: 3m 38s\tremaining: 29.5s\n",
            "900:\tlearn: 0.4332251\ttotal: 3m 45s\tremaining: 24.7s\n",
            "920:\tlearn: 0.4329849\ttotal: 3m 49s\tremaining: 19.7s\n",
            "940:\tlearn: 0.4327211\ttotal: 3m 54s\tremaining: 14.7s\n",
            "960:\tlearn: 0.4325277\ttotal: 4m\tremaining: 9.77s\n",
            "980:\tlearn: 0.4323052\ttotal: 4m 5s\tremaining: 4.75s\n",
            "999:\tlearn: 0.4320764\ttotal: 4m 9s\tremaining: 0us\n"
          ]
        }
      ],
      "source": [
        "cat = CatBoostClassifier(n_estimators=1000, max_depth=8, random_seed=42, learning_rate =0.01, bootstrap_type ='Bayesian')\n",
        "cat.fit(X_train, y_train, cat_features=cat_features, verbose=20)\n",
        "test_predictions = cat.predict_proba(test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "sy7a75dFdSMP"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}